{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "collapsed_sections": [
        "U3gDH9fRhD9W"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c8c260a4e2fd418f91497ae432f79143": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd06f6317edc454481bc5ab9b6a0fad2",
              "IPY_MODEL_c85929ad613d47e4a6baefe9d41b70d7"
            ],
            "layout": "IPY_MODEL_0a8296450fe84a83a82c0a173c43e126"
          }
        },
        "bd06f6317edc454481bc5ab9b6a0fad2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b729a68ca66046e5a7417e13eeea459c",
            "placeholder": "​",
            "style": "IPY_MODEL_1a0a44351c0749b2a1c149afb300264c",
            "value": "0.118 MB of 0.118 MB uploaded\r"
          }
        },
        "c85929ad613d47e4a6baefe9d41b70d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62d92d4fe8564980989a04deb88e708c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8234959da35143a4b9326c32f58fc388",
            "value": 1
          }
        },
        "0a8296450fe84a83a82c0a173c43e126": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b729a68ca66046e5a7417e13eeea459c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a0a44351c0749b2a1c149afb300264c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62d92d4fe8564980989a04deb88e708c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8234959da35143a4b9326c32f58fc388": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "72736122fd5b46789d634bd90cc9c0ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f49f8c3994d242fa927a15190a5412db",
              "IPY_MODEL_e4481527804448f99b61685724093542",
              "IPY_MODEL_ff712eb961364ab79007b05ed4dd6e9a"
            ],
            "layout": "IPY_MODEL_ff54a3e00487420fa1411b4381136b3d"
          }
        },
        "f49f8c3994d242fa927a15190a5412db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e962b165f4b34b49b54b3a6d11a0df9c",
            "placeholder": "​",
            "style": "IPY_MODEL_c4a0b1ce06eb4b9dbd2a881758e3074d",
            "value": "config.json: 100%"
          }
        },
        "e4481527804448f99b61685724093542": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d93dfa59b0344b2e859be3b26945b207",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4cb1a1c6f9434372b3e45aec29a0a3f7",
            "value": 481
          }
        },
        "ff712eb961364ab79007b05ed4dd6e9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45132ae314a4453eb85a998009e03c2e",
            "placeholder": "​",
            "style": "IPY_MODEL_93ce9f0bbdaf474fbcaafc25f7e31619",
            "value": " 481/481 [00:00&lt;00:00, 40.6kB/s]"
          }
        },
        "ff54a3e00487420fa1411b4381136b3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e962b165f4b34b49b54b3a6d11a0df9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4a0b1ce06eb4b9dbd2a881758e3074d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d93dfa59b0344b2e859be3b26945b207": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cb1a1c6f9434372b3e45aec29a0a3f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "45132ae314a4453eb85a998009e03c2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93ce9f0bbdaf474fbcaafc25f7e31619": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85f870e3ff7d4bea87be6bd94546cd35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ae2884dfe8724283ba274a34cd3ef464",
              "IPY_MODEL_26469ad456f74840993d276d49e5a79a",
              "IPY_MODEL_117ee2af0b454c39b2ca359f93b0fbde"
            ],
            "layout": "IPY_MODEL_0082c4ad324a4a41a3986871802f46d8"
          }
        },
        "ae2884dfe8724283ba274a34cd3ef464": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91c4ea0785e0446082c2d736b5147395",
            "placeholder": "​",
            "style": "IPY_MODEL_a25f003fe0fd491f960362fd431661ec",
            "value": "model.safetensors: 100%"
          }
        },
        "26469ad456f74840993d276d49e5a79a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2539cf528af14ee0af8f75cd4e193d21",
            "max": 498818054,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_30b3be9e432d43aba53e799fe91b28df",
            "value": 498818054
          }
        },
        "117ee2af0b454c39b2ca359f93b0fbde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c66973ba587b419f816b6d9cefe92c67",
            "placeholder": "​",
            "style": "IPY_MODEL_948d439799fe4ea1a48840ad6c09bec3",
            "value": " 499M/499M [00:01&lt;00:00, 309MB/s]"
          }
        },
        "0082c4ad324a4a41a3986871802f46d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91c4ea0785e0446082c2d736b5147395": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a25f003fe0fd491f960362fd431661ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2539cf528af14ee0af8f75cd4e193d21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30b3be9e432d43aba53e799fe91b28df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c66973ba587b419f816b6d9cefe92c67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "948d439799fe4ea1a48840ad6c09bec3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa32faced41946fca0353911fa433036": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3454ac027de04504be85bb8b72d6bdff",
              "IPY_MODEL_1021a36cce3143ebb773a5d145c8bbcf",
              "IPY_MODEL_e7aca08d33bd4379b6e17ab03c3215c6"
            ],
            "layout": "IPY_MODEL_620b6876608d45ef852c12c59dcf769e"
          }
        },
        "3454ac027de04504be85bb8b72d6bdff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a3d83fe39c5456992e487bb8fb19294",
            "placeholder": "​",
            "style": "IPY_MODEL_74afb5ac63c840de93468ec995afc24a",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "1021a36cce3143ebb773a5d145c8bbcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bb992c6c5e845a782076cd48b4a20f8",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8f59c2150a1f4a4b9964cf420f1c98b2",
            "value": 25
          }
        },
        "e7aca08d33bd4379b6e17ab03c3215c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69edf76758e4480f893c59e489c3b8fa",
            "placeholder": "​",
            "style": "IPY_MODEL_2876c155cc7649338ce0517865629253",
            "value": " 25.0/25.0 [00:00&lt;00:00, 2.44kB/s]"
          }
        },
        "620b6876608d45ef852c12c59dcf769e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a3d83fe39c5456992e487bb8fb19294": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74afb5ac63c840de93468ec995afc24a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6bb992c6c5e845a782076cd48b4a20f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f59c2150a1f4a4b9964cf420f1c98b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "69edf76758e4480f893c59e489c3b8fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2876c155cc7649338ce0517865629253": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f6e55aa377847c288e4064be14caec3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee0dac6b00d54cf8bd93ebd8cede9cbf",
              "IPY_MODEL_62b99c624a474c85ab7ec8985c069367",
              "IPY_MODEL_85243ea33055456192eb814e22cb66ac"
            ],
            "layout": "IPY_MODEL_abc212e9ab22457ba7dae88c39c4199e"
          }
        },
        "ee0dac6b00d54cf8bd93ebd8cede9cbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d71dd738298447ab8e1a9b2856be2b8",
            "placeholder": "​",
            "style": "IPY_MODEL_3df91f2ae2144332abd8716777dceacd",
            "value": "vocab.json: 100%"
          }
        },
        "62b99c624a474c85ab7ec8985c069367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4580bb966ff2458e92a7719127299c6c",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_124420bb726347228513afc2c673533d",
            "value": 898823
          }
        },
        "85243ea33055456192eb814e22cb66ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a14fec6c7f5c4475af60091c36e367c0",
            "placeholder": "​",
            "style": "IPY_MODEL_69d62cfca9204012985efff40cb0eeb9",
            "value": " 899k/899k [00:00&lt;00:00, 7.60MB/s]"
          }
        },
        "abc212e9ab22457ba7dae88c39c4199e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d71dd738298447ab8e1a9b2856be2b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3df91f2ae2144332abd8716777dceacd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4580bb966ff2458e92a7719127299c6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "124420bb726347228513afc2c673533d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a14fec6c7f5c4475af60091c36e367c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69d62cfca9204012985efff40cb0eeb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63cc4522caf9460e82cc1803d96f75d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_52a70ad9f5044a39ad83a745e8f7c88f",
              "IPY_MODEL_9430c6e0410d436194fa835cd06e045e",
              "IPY_MODEL_b110255209d842ca8cfa039ff231b86b"
            ],
            "layout": "IPY_MODEL_e1306a0556e94825b82375e700859f0d"
          }
        },
        "52a70ad9f5044a39ad83a745e8f7c88f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b123b95ffc2474b85be0c08b80ac01d",
            "placeholder": "​",
            "style": "IPY_MODEL_955d1101e18f4dba815a94e4d211edc9",
            "value": "merges.txt: 100%"
          }
        },
        "9430c6e0410d436194fa835cd06e045e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60536469eccf41518bed401f9353d1c1",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c4e6438b8494db39a664deed4382131",
            "value": 456318
          }
        },
        "b110255209d842ca8cfa039ff231b86b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5e6befbc39a4fa8b733c09f6961fac8",
            "placeholder": "​",
            "style": "IPY_MODEL_b04608ae81134942b5bc9e06d3f8b6fd",
            "value": " 456k/456k [00:00&lt;00:00, 7.07MB/s]"
          }
        },
        "e1306a0556e94825b82375e700859f0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b123b95ffc2474b85be0c08b80ac01d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "955d1101e18f4dba815a94e4d211edc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60536469eccf41518bed401f9353d1c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c4e6438b8494db39a664deed4382131": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e5e6befbc39a4fa8b733c09f6961fac8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b04608ae81134942b5bc9e06d3f8b6fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "208f77a0b4aa4db795c69d08d171c62c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c47526d6d7f046439a36f212327603ea",
              "IPY_MODEL_db2ba81eb56e46ed8bb721cf2386ed73",
              "IPY_MODEL_7fe1a144cb8c4695b346c0818d23f516"
            ],
            "layout": "IPY_MODEL_7280798edbff40bd959c9b1b7fe6ddbf"
          }
        },
        "c47526d6d7f046439a36f212327603ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70a7b9a6420d470fadc10474a921a802",
            "placeholder": "​",
            "style": "IPY_MODEL_def59e4a90e24d32ab78238a6292755b",
            "value": "tokenizer.json: 100%"
          }
        },
        "db2ba81eb56e46ed8bb721cf2386ed73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2c1951a5ccf46319eb9f087feea8e80",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1757e46331d049ffa7045bb9e0577c81",
            "value": 1355863
          }
        },
        "7fe1a144cb8c4695b346c0818d23f516": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1880c414af4148719667ea589b4dfb4c",
            "placeholder": "​",
            "style": "IPY_MODEL_d76ac4024079401787b42a8df60f1a73",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 42.9MB/s]"
          }
        },
        "7280798edbff40bd959c9b1b7fe6ddbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70a7b9a6420d470fadc10474a921a802": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "def59e4a90e24d32ab78238a6292755b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2c1951a5ccf46319eb9f087feea8e80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1757e46331d049ffa7045bb9e0577c81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1880c414af4148719667ea589b4dfb4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d76ac4024079401787b42a8df60f1a73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f24917236f3b48c592a82055283b62dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7942385da3f45c8a6dc8a6547a1ccd1",
              "IPY_MODEL_bad783f389324d969cb76504950cab28"
            ],
            "layout": "IPY_MODEL_8f40931465d54b0aa893d4ca76a34879"
          }
        },
        "e7942385da3f45c8a6dc8a6547a1ccd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99449b211c95496cbcecead7209133ab",
            "placeholder": "​",
            "style": "IPY_MODEL_1720c4e46d7f4b53bb7ebda155c3936e",
            "value": "0.027 MB of 0.027 MB uploaded\r"
          }
        },
        "bad783f389324d969cb76504950cab28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82fe2ff36a39463c9fe43775a8219f95",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fa6992b6fd874ebe976a94259e700330",
            "value": 1
          }
        },
        "8f40931465d54b0aa893d4ca76a34879": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99449b211c95496cbcecead7209133ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1720c4e46d7f4b53bb7ebda155c3936e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82fe2ff36a39463c9fe43775a8219f95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa6992b6fd874ebe976a94259e700330": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch-geometric tqdm\n",
        "!pip install Pillow==9.4.0\n",
        "!pip install fastai==2.7.14\n",
        "# !pip install fastbook==0.0.29"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GzEe6KCjA7z",
        "outputId": "307a6be8-9836-4442-ddfd-4acb4410e273"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.2)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.5.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n",
            "Requirement already satisfied: Pillow==9.4.0 in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: fastai==2.7.14 in /usr/local/lib/python3.10/dist-packages (2.7.14)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from fastai==2.7.14) (23.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastai==2.7.14) (24.0)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from fastai==2.7.14) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.6,>=1.5.29 in /usr/local/lib/python3.10/dist-packages (from fastai==2.7.14) (1.5.33)\n",
            "Requirement already satisfied: torchvision>=0.11 in /usr/local/lib/python3.10/dist-packages (from fastai==2.7.14) (0.17.1+cu121)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from fastai==2.7.14) (3.7.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fastai==2.7.14) (2.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fastai==2.7.14) (2.31.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from fastai==2.7.14) (6.0.1)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.10/dist-packages (from fastai==2.7.14) (1.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from fastai==2.7.14) (9.4.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from fastai==2.7.14) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from fastai==2.7.14) (1.11.4)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.10/dist-packages (from fastai==2.7.14) (3.7.4)\n",
            "Requirement already satisfied: torch<2.3,>=1.10 in /usr/local/lib/python3.10/dist-packages (from fastai==2.7.14) (2.2.1+cu121)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai==2.7.14) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai==2.7.14) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai==2.7.14) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai==2.7.14) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai==2.7.14) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai==2.7.14) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai==2.7.14) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai==2.7.14) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai==2.7.14) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai==2.7.14) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai==2.7.14) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai==2.7.14) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai==2.7.14) (4.66.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai==2.7.14) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai==2.7.14) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai==2.7.14) (67.7.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai==2.7.14) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai==2.7.14) (1.25.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->fastai==2.7.14) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fastai==2.7.14) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fastai==2.7.14) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fastai==2.7.14) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=1.10->fastai==2.7.14) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=1.10->fastai==2.7.14) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=1.10->fastai==2.7.14) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=1.10->fastai==2.7.14) (3.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=1.10->fastai==2.7.14) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=1.10->fastai==2.7.14) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=1.10->fastai==2.7.14) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=1.10->fastai==2.7.14) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=1.10->fastai==2.7.14) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=1.10->fastai==2.7.14) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=1.10->fastai==2.7.14) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=1.10->fastai==2.7.14) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=1.10->fastai==2.7.14) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=1.10->fastai==2.7.14) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=1.10->fastai==2.7.14) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=1.10->fastai==2.7.14) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=1.10->fastai==2.7.14) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<2.3,>=1.10->fastai==2.7.14) (12.4.127)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai==2.7.14) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai==2.7.14) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai==2.7.14) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai==2.7.14) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai==2.7.14) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai==2.7.14) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fastai==2.7.14) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fastai==2.7.14) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fastai==2.7.14) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fastai==2.7.14) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<4->fastai==2.7.14) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4->fastai==2.7.14) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4->fastai==2.7.14) (2.18.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->fastai==2.7.14) (1.16.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai==2.7.14) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai==2.7.14) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<4->fastai==2.7.14) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<4->fastai==2.7.14) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<4->fastai==2.7.14) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.3,>=1.10->fastai==2.7.14) (1.3.0)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4->fastai==2.7.14) (1.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVGdikzUxv5N",
        "outputId": "7d0bd9a2-f338-4499-9b05-4a0bb7ab2603"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.17.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.1.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hUuankpf0Lf",
        "outputId": "2e457d2e-d8e3-46b1-93e9-f63276f79e7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import wandb\n",
        "import random\n",
        "import time\n",
        "import argparse\n",
        "import torch\n",
        "import pickle\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from transformers import get_constant_schedule, get_constant_schedule_with_warmup\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDRi_Ox1BZeO",
        "outputId": "98011d25-1226-485e-f0e2-194a6cdb39da"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mraj8lm\u001b[0m (\u001b[33mmh_detection\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/gdrive/My Drive/MTech_Thesis/SKAIG_ERC/SKAIG-ERC')"
      ],
      "metadata": {
        "id": "J99O5CVRBTje"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.insert(0,'/content/gdrive/My Drive/MTech_Thesis/SKAIG_ERC/SKAIG-ERC')"
      ],
      "metadata": {
        "id": "fSq7kSW2ijLe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os, re, csv\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "import importlib\n",
        "# importlib.reload(importlib.import_module('gnn_dataset'))\n",
        "\n",
        "from gnn_dataset import BaseDataset, collate_fn, collate_fn_batch\n",
        "# from gnn import *\n",
        "from gnn import MentalModel, BatchMentalModel, MentalModelWithSpectrogram, EmotionDetectionUsingSpectrogram\n",
        "\n",
        "# from fastai.vision.models import resnet34\n",
        "# from fastai.vision.all import *\n",
        "# from fastai.vision.all import PILImage, tensor\n",
        "\n",
        "from gnn_for_meld_emorynlp import BatchMentalModelResidual\n",
        "from fastai.vision.all import PILImage, tensor\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "hsH1ZkhqylQd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IEMOCAP\n",
        "The Data below is the Test Data that we tried to print here. The first item is the \"utt\", which is \"UTTERANCES\" in short. This is the words that is actually spoken in the sentence.\n",
        "\n",
        "The next section is the label for the sentence. Each label identifies a sentiment:     label index mapping = {'hap':0, 'sad':1, 'neu':2, 'ang':3, 'exc':4, 'fru':5}\n",
        "\n",
        "The next section is the \"spk\", i.e., the SPEAKERS that are part of the conversation - like M for male and F for Female. This is a conversation between 2 people.\n",
        "\n",
        "The final section is the \"graph\", where the graph's edge indices and the edge values are mentioned.\n",
        "\n",
        "Eg for understanding:\n",
        "\n",
        "```\n",
        "'Why does that bother you?',  2,  M\n",
        "'Well, maybe maybe he just wanted to see her again.',   2,  M\n",
        "'Nobody comes seven hundred miles just to see.',  2,  F\n",
        "\"What are you talking about?  He grew up next to the girl his whole life, why wouldn't he want to see her again?  Don't look at me like that.  He hasn't told me anything he didn't told you.\",   5,  M\n",
        "\"Why do you think he's even thinking that?\",  2,  M\n",
        "\"He's got that about it.\",  2,  F\n",
        "'Well, so what?',  5,   M\n",
        "\"What's going on here, Joe?\",   3,  F\n",
        "'Now listen.',  5,  M\n",
        "\"How do you know why she's waited?\",  5,  M\n",
        "\"Look, it's a beautiful day outside, why are we arguing?\",  5,  M\n",
        "'Well, what do you want me to do about it?  What do you want?',   5,  M\n",
        "\"I want you to pretend like he's coming back.  Both of you, don't think I haven't noticed you and Chris since she's gotten here.  I don't want any nonsense.\",  5,  F\n",
        "'But Kate?',  5,  M\n",
        "\"No, because if she- he's not coming back then I'll kill myself. Laugh!  Laugh at me!\",   5,  F\n",
        "'Calm yourself.',   5,  M\n",
        "'Calm yourself.',   5,  M\n",
        "'Only last week a man turned up in Detroit missing longer than Larry.  You read it yourself.',  5,  F\n",
        "'All right.  All right.',   5,  M\n",
        "'You above all have got to believe.',   3,  F\n",
        "\"What's that suppose to mean, me above all?  Look at you, you're shaking.\",   3,  M\n",
        "\"I can't help it.\",   3,  F\n",
        "'What have I got to hide, Kate?  What the hell is the matter with you?',   3,   M\n",
        "```\n",
        "\n",
        "\n",
        "Labels\n",
        "[2, 2, 2, 5, 2, 2, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 3, 3, 3]\n",
        "\n",
        "Speakers\n",
        "['M', 'M', 'F', 'M', 'M', 'F', 'M', 'F', 'M', 'M', 'M', 'M', 'F', 'M', 'F', 'M', 'M', 'F', 'M', 'F', 'M', 'F', 'M']"
      ],
      "metadata": {
        "id": "awOfjaEBn6wU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OPTIONAL: BREAKING THE DATA TO UNDERSTAND THE STRUCTURE OF PICKER FILE"
      ],
      "metadata": {
        "id": "U3gDH9fRhD9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_data(dataset_name, hip):\n",
        "    print(dataset_name)\n",
        "    dataset_path = 'bert_data/' + dataset_name + '/' + dataset_name + '_graph_hip' + str(hip) + '_new.pkl'\n",
        "    data_utf = pickle.load(open(dataset_path, 'rb'), encoding='utf-8')\n",
        "\n",
        "    # users should use these instructions to load pkl dataset. \\\n",
        "    # videoIDs, videoSpeakers, videoLabels, videoText,\\\n",
        "    # videoAudio, videoVisual, videoSentence, trainVid,\\\n",
        "    # testVid = pickle.load(open(dataset_path, 'rb'), encoding='latin1')\n",
        "\n",
        "    # data = data_utf['test']\n",
        "\n",
        "    '''\n",
        "        label index mapping = {'hap':0, 'sad':1, 'neu':2, 'ang':3, 'exc':4, 'fru':5}\n",
        "    '''\n",
        "    # utt = data[0]\n",
        "    # label = data[1]\n",
        "    # spk = data[2]\n",
        "    # graph = data[3]\n",
        "\n",
        "    # print(f\"UTTERANCE: {np.matrix(utt)}\")\n",
        "    # print(f\"LABEL: {np.matrix(label)}\")\n",
        "    # print(f\"SPEAKER GENDER: {np.matrix(spk)}\")\n",
        "    # print(f\"GRAPH DATA: {np.matrix(graph)}\")\n",
        "\n",
        "    # Loading the pickle file to a dataframe\n",
        "    unpickled_df = pd.read_pickle(dataset_path)\n",
        "\n",
        "    df = pd.DataFrame(unpickled_df.items())\n",
        "    # Getting the Train Data\n",
        "    train_val = df[[1]].iloc[0]\n",
        "    val_arr = train_val.to_numpy()\n",
        "\n",
        "    train_df=pd.DataFrame()\n",
        "    train_df[\"UTTERANCE\"] = pd.DataFrame([' '.join(str(j) for j in i) for i in val_arr[0][0]])\n",
        "    train_df[\"LABEL\"] = pd.DataFrame([' '.join(str(j) for j in i) for i in val_arr[0][1]])\n",
        "    train_df[\"SPEAKER GENDER\"] = pd.DataFrame([' '.join(str(j) for j in i) for i in val_arr[0][2]])\n",
        "    # Graph Data is again a Dict\n",
        "    train_df[\"GRAPH DATA_EDGE_INDEX\"] = pd.DataFrame([' '.join(str(j) for j in i) for i in val_arr[0][3]['edge_index']])\n",
        "    train_df[\"GRAPH DATA_EDGE_TYPE\"] = pd.DataFrame([' '.join(str(j) for j in i) for i in val_arr[0][3]['edge_type']])\n",
        "    print(train_df.shape)\n",
        "\n",
        "    test_val = df[[1]].iloc[1]\n",
        "    val_arr = test_val.to_numpy()\n",
        "\n",
        "    test_df=pd.DataFrame()\n",
        "    test_df[\"UTTERANCE\"] = pd.DataFrame([' '.join(str(j) for j in i) for i in val_arr[0][0]])\n",
        "    test_df[\"LABEL\"] = pd.DataFrame([' '.join(str(j) for j in i) for i in val_arr[0][1]])\n",
        "    test_df[\"SPEAKER GENDER\"] = pd.DataFrame([' '.join(str(j) for j in i) for i in val_arr[0][2]])\n",
        "    # Graph Data is again a Dict\n",
        "    test_df[\"GRAPH DATA_EDGE_INDEX\"] = pd.DataFrame([' '.join(str(j) for j in i) for i in val_arr[0][3]['edge_index']])\n",
        "    test_df[\"GRAPH DATA_EDGE_TYPE\"] = pd.DataFrame([' '.join(str(j) for j in i) for i in val_arr[0][3]['edge_type']])\n",
        "    print(test_df.shape)\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "\n",
        "train_df, test_df = show_data(\"IEMOCAP\", 7)\n",
        "train_df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "3uHEg7pWOpMX",
        "outputId": "f73ddae3-b650-4109-efd0-fa502201949a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IEMOCAP\n",
            "(120, 5)\n",
            "(31, 5)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           UTTERANCE  \\\n",
              "0  Hey, Isabella. Hey, how's it going, Joe? I'm a...   \n",
              "1  Oh, you're never going to believe it. What? Wh...   \n",
              "2  Oh, man, I just -- I don't know what to do.  I...   \n",
              "3  What time is it?  They're supposed to run arou...   \n",
              "4  We'll be alright, darling.  Whatever happens, ...   \n",
              "5  I'm just so tired all the time. Well have you ...   \n",
              "6  Hello.  Thank you for calling Dell Taco Corpor...   \n",
              "7  Kathy died last night. yeah, I mean, you know,...   \n",
              "8  As a matter of fact, the real cause of that ro...   \n",
              "9  Hello? Oh God I finally got...you know how lon...   \n",
              "\n",
              "                                               LABEL  \\\n",
              "0  2 0 2 0 0 2 2 0 0 0 4 4 4 4 4 4 2 0 4 0 4 4 4 ...   \n",
              "1  4 4 4 4 4 4 4 4 4 4 4 4 0 0 0 4 0 4 4 0 0 4 4 ...   \n",
              "2  5 5 2 5 5 2 2 2 5 2 2 5 5 5 2 5 2 5 2 5 5 2 5 ...   \n",
              "3  0 2 4 5 5 5 5 5 4 2 0 3 5 3 5 5 2 5 5 5 3 5 4 ...   \n",
              "4  2 4 4 4 4 4 4 4 4 2 2 4 3 2 4 4 1 4 4 4 4 4 4 ...   \n",
              "5  1 2 5 5 5 2 2 3 5 5 1 1 3 5 4 5 5 5 5 2 2 2 5 ...   \n",
              "6  0 5 2 5 2 5 2 5 5 2 2 5 5 2 5 2 2 2 3 3 3 5 3 ...   \n",
              "7  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...   \n",
              "8  2 4 3 4 2 3 2 3 2 2 3 2 5 2 2 2 2 2 2 3 5 2 2 ...   \n",
              "9  2 5 2 5 2 5 2 5 2 3 3 5 2 5 2 5 2 5 2 2 5 2 5 ...   \n",
              "\n",
              "                                      SPEAKER GENDER  \\\n",
              "0  M F M F F M M F F F M F F M F F M F M F M F M ...   \n",
              "1  M F M F F F M F F F M M F M M F M F F M M M F ...   \n",
              "2  M M F M M F F M M F F M M M F M F M F M M F M ...   \n",
              "3  M F M M M F M M M M M F M F M F M F M F F M M ...   \n",
              "4  M M F M F M F F F M M F M F F F M F F M F F F ...   \n",
              "5  M F M F M F F M M M F F M M F M M M M M F F M ...   \n",
              "6  F M M M F M F M F F F M M F F F M F M M M F M ...   \n",
              "7  M M M F M F M F M M F M F M F M F M F M M F M ...   \n",
              "8  M F M F F M F M F F M F F F M M F M F F M F M ...   \n",
              "9  M F M F M F M F M F F F M F M F M F M M F M F ...   \n",
              "\n",
              "                               GRAPH DATA_EDGE_INDEX  \\\n",
              "0    [ 0  0  0 ... 55 55 55] [ 0  1  2 ... 51 53 55]   \n",
              "1  [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...   \n",
              "2  [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...   \n",
              "3  [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...   \n",
              "4  [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...   \n",
              "5  [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...   \n",
              "6  [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...   \n",
              "7  [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...   \n",
              "8    [ 0  0  0 ... 56 56 56] [ 0  1  2 ... 50 52 56]   \n",
              "9  [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...   \n",
              "\n",
              "                                GRAPH DATA_EDGE_TYPE  \n",
              "0  xEffect oWant xWant oWant oWant xWant xWant oW...  \n",
              "1  xEffect oWant xWant oWant oWant oWant xWant oW...  \n",
              "2  xEffect xWant oWant xWant xWant oWant oWant xW...  \n",
              "3  xEffect oWant xWant xWant xWant oWant xWant xW...  \n",
              "4  xEffect xWant oWant xWant oWant xWant oWant oW...  \n",
              "5  xEffect oWant xWant oWant xWant oWant oWant xW...  \n",
              "6  xEffect oWant oWant oWant xWant oWant xWant oW...  \n",
              "7  xEffect xWant xWant oWant xWant oWant xWant oW...  \n",
              "8  xEffect oWant xWant oWant oWant xWant oWant xW...  \n",
              "9  xEffect oWant xWant oWant xWant oWant xWant oW...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0cc79d9f-446a-4706-9487-0ae8bde98170\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UTTERANCE</th>\n",
              "      <th>LABEL</th>\n",
              "      <th>SPEAKER GENDER</th>\n",
              "      <th>GRAPH DATA_EDGE_INDEX</th>\n",
              "      <th>GRAPH DATA_EDGE_TYPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hey, Isabella. Hey, how's it going, Joe? I'm a...</td>\n",
              "      <td>2 0 2 0 0 2 2 0 0 0 4 4 4 4 4 4 2 0 4 0 4 4 4 ...</td>\n",
              "      <td>M F M F F M M F F F M F F M F F M F M F M F M ...</td>\n",
              "      <td>[ 0  0  0 ... 55 55 55] [ 0  1  2 ... 51 53 55]</td>\n",
              "      <td>xEffect oWant xWant oWant oWant xWant xWant oW...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Oh, you're never going to believe it. What? Wh...</td>\n",
              "      <td>4 4 4 4 4 4 4 4 4 4 4 4 0 0 0 4 0 4 4 0 0 4 4 ...</td>\n",
              "      <td>M F M F F F M F F F M M F M M F M F F M M M F ...</td>\n",
              "      <td>[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...</td>\n",
              "      <td>xEffect oWant xWant oWant oWant oWant xWant oW...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Oh, man, I just -- I don't know what to do.  I...</td>\n",
              "      <td>5 5 2 5 5 2 2 2 5 2 2 5 5 5 2 5 2 5 2 5 5 2 5 ...</td>\n",
              "      <td>M M F M M F F M M F F M M M F M F M F M M F M ...</td>\n",
              "      <td>[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...</td>\n",
              "      <td>xEffect xWant oWant xWant xWant oWant oWant xW...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What time is it?  They're supposed to run arou...</td>\n",
              "      <td>0 2 4 5 5 5 5 5 4 2 0 3 5 3 5 5 2 5 5 5 3 5 4 ...</td>\n",
              "      <td>M F M M M F M M M M M F M F M F M F M F F M M ...</td>\n",
              "      <td>[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...</td>\n",
              "      <td>xEffect oWant xWant xWant xWant oWant xWant xW...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>We'll be alright, darling.  Whatever happens, ...</td>\n",
              "      <td>2 4 4 4 4 4 4 4 4 2 2 4 3 2 4 4 1 4 4 4 4 4 4 ...</td>\n",
              "      <td>M M F M F M F F F M M F M F F F M F F M F F F ...</td>\n",
              "      <td>[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...</td>\n",
              "      <td>xEffect xWant oWant xWant oWant xWant oWant oW...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>I'm just so tired all the time. Well have you ...</td>\n",
              "      <td>1 2 5 5 5 2 2 3 5 5 1 1 3 5 4 5 5 5 5 2 2 2 5 ...</td>\n",
              "      <td>M F M F M F F M M M F F M M F M M M M M F F M ...</td>\n",
              "      <td>[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...</td>\n",
              "      <td>xEffect oWant xWant oWant xWant oWant oWant xW...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Hello.  Thank you for calling Dell Taco Corpor...</td>\n",
              "      <td>0 5 2 5 2 5 2 5 5 2 2 5 5 2 5 2 2 2 3 3 3 5 3 ...</td>\n",
              "      <td>F M M M F M F M F F F M M F F F M F M M M F M ...</td>\n",
              "      <td>[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...</td>\n",
              "      <td>xEffect oWant oWant oWant xWant oWant xWant oW...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Kathy died last night. yeah, I mean, you know,...</td>\n",
              "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
              "      <td>M M M F M F M F M M F M F M F M F M F M M F M ...</td>\n",
              "      <td>[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...</td>\n",
              "      <td>xEffect xWant xWant oWant xWant oWant xWant oW...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>As a matter of fact, the real cause of that ro...</td>\n",
              "      <td>2 4 3 4 2 3 2 3 2 2 3 2 5 2 2 2 2 2 2 3 5 2 2 ...</td>\n",
              "      <td>M F M F F M F M F F M F F F M M F M F F M F M ...</td>\n",
              "      <td>[ 0  0  0 ... 56 56 56] [ 0  1  2 ... 50 52 56]</td>\n",
              "      <td>xEffect oWant xWant oWant oWant xWant oWant xW...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Hello? Oh God I finally got...you know how lon...</td>\n",
              "      <td>2 5 2 5 2 5 2 5 2 3 3 5 2 5 2 5 2 5 2 2 5 2 5 ...</td>\n",
              "      <td>M F M F M F M F M F F F M F M F M F M M F M F ...</td>\n",
              "      <td>[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...</td>\n",
              "      <td>xEffect oWant xWant oWant xWant oWant xWant oW...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0cc79d9f-446a-4706-9487-0ae8bde98170')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0cc79d9f-446a-4706-9487-0ae8bde98170 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0cc79d9f-446a-4706-9487-0ae8bde98170');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6cfea3ce-cd81-4a7c-9464-946bb2b0b6ea\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6cfea3ce-cd81-4a7c-9464-946bb2b0b6ea')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6cfea3ce-cd81-4a7c-9464-946bb2b0b6ea button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 120,\n  \"fields\": [\n    {\n      \"column\": \"UTTERANCE\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 120,\n        \"samples\": [\n          \"All right. Customer service this is Steve. Hi. Thank you so much, you're a real person, right, you're not like a recording? Okay. Before I get into it, um your menu or whatever like where you choose the different thing depending on the- it leads you around in circles, you can't, there is no way to like get to a real person if you don't already know how to get to there. Right. No, yes I know. It is-It is a little frustrating. So is there any way to like bypass that because that is so, like I've been going around in circles like press nine, press zero, press back to the menu, like I can't get through to what I'm supposed to get through to. I- I'll give you a little hint, next time if it asks if you're on a rotary phone you know, just stay on the line instead of - instead of hitting one or two to say if you're like on a touch tone pretend like your on a rotary phone, goes straight through to a person. Okay. Oh, that would just make it so much better, 'cause I cannot handle it's just like oh, my God I can't sit here any longer and talk to this lady with this pleasant voice. I know they don't tell you that kind of thing. Sorry. Okay. Um-, yes Thank you very much. Um  So I have a charge on my credit card that, um, isn't mine. Uh, I don't know where it came from and it's actually quite large, and I don't have the money for it so it really freaks me out when I got my bill because it was like I don't -- I didn't spend this. This is not my charge. Yea. All right. Well, let me-let me look it up here for a second. Uh, so i think Okay, it was um- at the [GARBAGE] sorry, it was at a department store, I think it was Macy's or something Okay, Alright, yeah. I- I see it on here. and it was like something like eight hundred dollars. I don't remember. It was just a lot and I have thing in front of me right now, but- All right. Well, you know that's, that's what we have all of our protection plans for and everything like that so I mean it's it- it'll work out fine. Yes, we'll get- we'll get rid of it right now. I mean just we're going to have to have you, um, submit something you know, we're going to have to have you mail something in for us, okay. So- So you can um find that application. You have the Internet, you can go to our website. Yeah. Yeah. You get the form right now. and- yeah We could mail it to you as well, but- Right. You can go online, print it out, and just fill out the form and um- send it to us um- you know,  regarding the grievance and- and it'll get taken off um- no problem you know 'Cause I-I just don't know how someone could have gotten my charge information Right. I mean we might Okay. Uh, I mean have you been shopping around on the Internet and stuff? I mean that you gave- I did buy one thing on ebay I don't know that might- Uh-ha, I mean usually sites are pretty well protected but sometimes I mean information gets out, so so it is a little a little hard in that situation if you want -- you know you can -um- we can- we can issue another credit card. Yeah, yeah. Maybe we'll, uh- it's a different number and everything Yeah. yeah. Yes, um but  for- for that- for that charge we will need you to send something in but we can get you processed immediately for this, for this, for this new card. It still goes to the same address, right? Okay. All right. Then we'll get it sent out there. And Great. And you know just I mean be careful in the future if um Yeah. if you're ever online or anything like that I mean just make sure it's a secure site and and never you know, give it to anyone out, never even give out your number to any like unreliable company that you haven't heard of or anything like that, all right? Because, um, we want to- we definitely want to help you out, but- Right, right. Okay, great. Yeah, totally. you know it gets- it gets difficult you know so Alright. Well thank you so much. You've been very helpful. I really appreciate it. Alright Yes, I'm sorry for all the inconvenience but we'll get it taken care of. Thank you very much bye.\",\n          \"And very much sillier. However I believe the real cause of that row was Peter Burden. Oh.  You knew there was nothing in that. I knew nothing of the sort.  You took presents from him. Presents?  It was only a trivial, little brooch. You went out of your way to torture me over Peter Burden. I did not.  You worked that whole thing up in your jealous imagination. Well, you let him kiss you, huh?  You said you did. Well, what of it? What about me? Oh dear.  I'm bored with this conversation. So am I.  I'm bored stiff. [GARBAGE]  Do you want some brandy? I'll have a little, I think. No particular reason.  Anyhow, they are very small ones. You can hardly call three glasses of liquor a whole evening long, going on and on and on. Oh.  Don't be so grand.  Just because you don't happen to want one at the moment. Don't be stupid. Really, Amanda. What? Nothing. you going out somewhere, dear? No.  I am just making myself fascinating for you. Oh.  It's a woman's duty to allure the man. Well as a matter of fact, yes, that's perfectly true. No it isn't. Yes it is. You shut up. Oh really.  It's a pity you didn't have any brandy, it would have made you a little less disagreeable. Snap, snap, snap.  You know you are like a little adder. Nonsense.  They have a bag of venom behind their fangs and they snap. They snap. They sting. I don't care.  Do you understand?  I don't care if they bark and they roll about like hoops. Did you see much of Peter Burden after our divorce? Yes I did, quite a lot. And I suppose you let him kiss you a good deal more than, too. Yes.  I suppose you guys had a riotous time, huh?  All out, no restraint at all.  Well, you never really had much anyhow. Mind your own business. You're quite insufferable, I expect it's because you are drunk. I think I am not in the least bit drunk. You've always had a weak head. I think I mentioned once before that I've had three minute liquor glasses the whole evening long.  A child of two cannot get drunk on that. On the contrary, a child of two can get violently drunk on only one glass of brandy. That's very interesting Amanda. How about a child of four?  Or a child of six?  Or a child of nine? We can get a good little conversation going on about this, you know, intemperate tots. Oh shut up. Shut up. Not very funny, darling.  Why don't you have some more brandy. Look, you better turn that off. I don't want to wake up the people upstairs. Why? There are no people upstairs; it's a photographer's studio. Well then you'll wake up the people downstairs. They are away in Tunis. This is no time of year for Tunis. I will do no such thing. Fine if you insist on being boorish and idiotic. Will you turn that off, it's driving me mad. You are far too temperamental, try to control yourself. Turn it off. I won't.  Let go, let go of me. Listen, listen?  I'm sick and tired of listening to you, you sadistic bully. Amanda, listen, listen. Oh.  That's very amusing indeed. Oh shut up.  Let go.  I hate you, I hate you.  Do you hear?  You are a conceited and overbearing and utterly impossible. You are a vile, ill-tempered, loose living, wicked little beast and I never want to see you again as long as I live. This is the end.  Do you hear me?  Finally and forever. You're not going like this. Oh.  Yes I am. You're not. Yes I am.   Stop it. Stop it.  Let go of me. Oh.  You're a cruel fiend.  I loathe and I hate you. Marry you again?  Never, never, never. I hope you die in torment, you brute beast cad. Shut up. Shut up. God, I wouldn't marry you again if you came crawling back to me on a bended knee.  You are a vile, ill-tempered, mean little wench and I never want to see you again as long as I live.\",\n          \"We'll be alright, darling.  Whatever happens, aren't we? I don't care, then. Oh, it sent shivers up my spine. What shall we do if they suddenly walk in on us? Behave exquisitely. With the mo- with the most perfect poise? Certainly.  I shall probably do a court curtsey. But what's so horrible is that one can't stay happy. It's true.  The whole business is a very poor joke. Meaning that sacred and beautiful thing, love? You mustn't be serious, my dear.  That's just what they want. Who's they? All the futile moralists who try to make life unbearable.  Laugh at them.  Be flippant.  Laugh at everything.  All their sacred shibboleths.  Flippancy brings out the acid- acid in their damn sweetness and light. If I laugh at everything, I must laugh at us, too. How long will it last, this ludicrous and overbearing love of ours? Shall we always want to bicker and fight? No.  That fire will fade along with our passion. What happens if one of us dies?  Does the one that's left, still laugh? Well that's serious enough, isn't it? Let's savor the delight of the moment.  Come and kiss me, darling, before your body rots and worms pop in and out of your eye sockets. Thank you, dear.  The same applies to you, except that if I catch you so much as looking at another woman, I will kill you. Which particular one? Oh, Charles; that was his name, Charles.  Oh, he did wriggle so beautifully. Horrible thing.  I hated it. I know you did.  You threw it out of the window into the Grand Canal.  I don't think I'll ever forgive you for that. It went on intermittently for days. It burnt my comb, too, and all the towels in the bathroom. Line? How -- that was a rouser wasn't it? That was the first time you ever hit me. The manager came in and found is rolling about on the floor, biting and scratching like panthers.  Oh, dear. How ridiculous. How utterly, utterly ridiculous. And very much sillier. As a matter of fact, the real cause of that row was Peter Burden.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LABEL\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 120,\n        \"samples\": [\n          \"2 4 4 4 2 5 5 2 2 5 2 2 2 2 5 2 2 2 5 2 2 2 2 2 2 2 2 5 2 2 2 2 2 2 2 2 2 2 2 0 2 0 2 2 2 2 2 2 0 2 0\",\n          \"0 2 0 2 0 2 2 5 2 3 5 5 2 2 5 5 3 3 3 5 2 3 3 2 3 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 3 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\",\n          \"2 4 4 4 4 4 4 4 4 2 2 4 3 2 4 4 1 4 4 4 4 4 4 3 4 4 4 2 4 4 4 4 4 2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SPEAKER GENDER\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 120,\n        \"samples\": [\n          \"M F F F M F F M M F M F F F F M F M F M M M M M M M M F M M M F M M M M M M M F M F M M F F F M F M F\",\n          \"F M F M F M F M F M F M M M M M F M F M M F F M F M F M M M F M F M F F M F M F M F F F M F F M F M M F M F M F M M F M F M F M F M\",\n          \"M M F M F M F F F M M F M F F F M F F M F F F M F F F M M F F F F M\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GRAPH DATA_EDGE_INDEX\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 117,\n        \"samples\": [\n          \"[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  1  1  1  1\\n  1  1  1  1  1  1  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  3  3\\n  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  4  4  4  4  4  4  4  4  4\\n  4  4  4  4  4  4  4  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\\n  5  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  7  7  7  7\\n  7  7  7  7  7  7  7  7  7  7  7  7  7  8  8  8  8  8  8  8  8  8  8  8\\n  8  8  8  8  8  8  8  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\\n  9  9  9 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 11 11\\n 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 12 12 12 12 12\\n 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 13 13 13 13 13 13 13\\n 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 14 14 14 14 14 14 14 14 14\\n 14 14 14 14 14 14 14 14 14 14 14 14 14 15 15 15 15 15 15 15 15 15 15 15\\n 15 15 15 15 15 15 15 15 15 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16\\n 16 16 16 16 16 16 16 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17\\n 17 17 17 17 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18\\n 18 18 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19\\n 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 21 21\\n 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 22 22 22 22\\n 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 23 23 23 23 23 23\\n 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 24 24 24 24 24 24 24 24\\n 24 24 24 24 24 24 24 24 24 24 24 24 24 24 25 25 25 25 25 25 25 25 25 25\\n 25 25 25 25 25 25 25 25 25 25 25 25 26 26 26 26 26 26 26 26 26 26 26 26\\n 26 26 26 26 26 26 26 26 26 26 27 27 27 27 27 27 27 27 27 27 27 27 27 27\\n 27 27 27 27 27 27 27 27 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\\n 28 28 28 28 28 28 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\\n 29 29 29 29 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\\n 30 30 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\\n 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 33 33\\n 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 34 34 34 34\\n 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 35 35 35 35 35 35\\n 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 36 36 36 36 36 36 36 36\\n 36 36 36 36 36 36 36 36 36 36 36 36 36 36 37 37 37 37 37 37 37 37 37 37\\n 37 37 37 37 37 37 37 37 37 37 37 38 38 38 38 38 38 38 38 38 38 38 38 38\\n 38 38 38 38 38 38 38 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\\n 39 39 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 41 41 41 41\\n 41 41 41 41 41 41 41 41 41 41 41 41 41 42 42 42 42 42 42 42 42 42 42 42\\n 42 42 42 42 42 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 44 44 44 44\\n 44 44 44 44 44 44 44 44 44 44 45 45 45 45 45 45 45 45 45 45 45 45 45 46\\n 46 46 46 46 46 46 46 46 46 46 46 47 47 47 47 47 47 47 47 47 47 47 48 48\\n 48 48 48 48 48 48 48 48 49 49 49 49 49 49 49 49 49 50 50 50 50 50 50 50\\n 50] [ 0  1  2  3  4  5  6  7  8  9 10 11 15 17 19  1  2  3  4  5  6  7  8  9\\n 10 11 12 15 17 19  1  2  3  4  5  6  7  8  9 10 11 12 13 15 17 19  1  2\\n  3  4  5  6  7  8  9 10 11 12 13 14 15 17 19  0  4  5  6  7  8  9 10 11\\n 12 13 14 15 17 19 20  1  2  3  5  6  7  8  9 10 11 12 13 14 15 16 17 19\\n 20  1  2  3  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20  0  4  7  8\\n  9 10 11 12 13 14 15 16 17 18 19 20 21  0  4  7  8  9 10 11 12 13 14 15\\n 16 17 18 19 20 21 22  1  2  3  5  6  9 10 11 12 13 14 15 16 17 18 19 20\\n 21 22 27  0  4  7  8 10 11 12 13 14 15 16 17 18 19 20 21 22 23 27  1  2\\n  3  5  6  9 11 12 13 14 15 16 17 18 19 20 21 22 23 27 31  1  2  3  5  6\\n  9 11 12 13 14 15 16 17 18 19 20 21 22 23 27 31 39  2  3  5  6  9 11 12\\n 13 14 15 16 17 18 19 20 21 22 23 27 31 39 41  3  5  6  9 11 12 13 14 15\\n 16 17 18 19 20 21 22 23 27 31 39 41 44  0  4  7  8 10 15 16 17 18 19 20\\n 21 22 23 24 27 31 39 41 44  5  6  9 11 12 13 14 16 17 18 19 20 21 22 23\\n 24 27 31 39 41 44 45  0  4  7  8 10 15 17 18 19 20 21 22 23 24 25 27 31\\n 39 41 44 45  6  9 11 12 13 14 16 18 19 20 21 22 23 24 25 27 31 39 41 44\\n 45 46  0  4  7  8 10 15 17 19 20 21 22 23 24 25 26 27 31 39 41 44 45 46\\n  4  7  8 10 15 17 19 20 21 22 23 24 25 26 27 28 31 39 41 44 45 46  7  8\\n 10 15 17 19 20 21 22 23 24 25 26 27 28 29 31 39 41 44 45 46  8 10 15 17\\n 19 20 21 22 23 24 25 26 27 28 29 30 31 39 41 44 45 46 10 15 17 19 20 21\\n 22 23 24 25 26 27 28 29 30 31 32 39 41 44 45 46 15 17 19 20 21 22 23 24\\n 25 26 27 28 29 30 31 32 33 39 41 44 45 46 17 19 20 21 22 23 24 25 26 27\\n 28 29 30 31 32 33 34 39 41 44 45 46 19 20 21 22 23 24 25 26 27 28 29 30\\n 31 32 33 34 35 39 41 44 45 46  9 11 12 13 14 16 18 27 28 29 30 31 32 33\\n 34 35 39 41 44 45 46 48 20 21 22 23 24 25 26 28 29 30 31 32 33 34 35 36\\n 39 41 44 45 46 48 21 22 23 24 25 26 28 29 30 31 32 33 34 35 36 37 39 41\\n 44 45 46 48 22 23 24 25 26 28 29 30 31 32 33 34 35 36 37 38 39 41 44 45\\n 46 48 11 12 13 14 16 18 27 31 32 33 34 35 36 37 38 39 41 44 45 46 48 50\\n 23 24 25 26 28 29 30 32 33 34 35 36 37 38 39 40 41 44 45 46 48 50 24 25\\n 26 28 29 30 32 33 34 35 36 37 38 39 40 41 42 44 45 46 48 50 25 26 28 29\\n 30 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 48 50 26 28 29 30 32 33\\n 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 50 28 29 30 32 33 34 35 36\\n 37 38 39 40 41 42 43 44 45 46 47 48 49 50 29 30 32 33 34 35 36 37 38 39\\n 40 41 42 43 44 45 46 47 48 49 50 30 32 33 34 35 36 37 38 39 40 41 42 43\\n 44 45 46 47 48 49 50 12 13 14 16 18 27 31 39 40 41 42 43 44 45 46 47 48\\n 49 50 32 33 34 35 36 37 38 40 41 42 43 44 45 46 47 48 49 50 13 14 16 18\\n 27 31 39 41 42 43 44 45 46 47 48 49 50 33 34 35 36 37 38 40 42 43 44 45\\n 46 47 48 49 50 34 35 36 37 38 40 42 43 44 45 46 47 48 49 50 14 16 18 27\\n 31 39 41 44 45 46 47 48 49 50 16 18 27 31 39 41 44 45 46 47 48 49 50 18\\n 27 31 39 41 44 45 46 47 48 49 50 35 36 37 38 40 42 43 47 48 49 50 27 31\\n 39 41 44 45 46 48 49 50 36 37 38 40 42 43 47 49 50 31 39 41 44 45 46 48\\n 50]\",\n          \"[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  1  1  1  1\\n  1  1  1  1  1  1  1  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  3  3\\n  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  4  4  4  4  4  4  4  4  4\\n  4  4  4  4  4  4  4  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\\n  5  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  7  7  7  7  7  7\\n  7  7  7  7  7  7  7  7  7  7  7  7  8  8  8  8  8  8  8  8  8  8  8  8\\n  8  8  8  8  8  8  8  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\\n  9  9 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 11 11\\n 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 12 12 12 12 12 12\\n 12 12 12 12 12 12 12 12 12 12 12 12 12 12 13 13 13 13 13 13 13 13 13 13\\n 13 13 13 13 13 13 13 13 13 13 14 14 14 14 14 14 14 14 14 14 14 14 14 14\\n 14 14 14 14 14 14 14 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\\n 15 15 15 15 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16\\n 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 18 18 18 18\\n 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 19 19 19 19 19 19 19 19\\n 19 19 19 19 19 19 19 19 19 19 19 20 20 20 20 20 20 20 20 20 20 20 20 20\\n 20 20 20 20 20 20 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21\\n 21 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 23 23 23 23\\n 23 23 23 23 23 23 23 23 23 23 23 23 23 23 24 24 24 24 24 24 24 24 24 24\\n 24 24 24 24 24 24 24 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 26\\n 26 26 26 26 26 26 26 26 26 26 26 26 26 26 27 27 27 27 27 27 27 27 27 27\\n 27 27 27 27 28 28 28 28 28 28 28 28 28 28 28 28 28 29 29 29 29 29 29 29\\n 29 29 29 29 29 30 30 30 30 30 30 30 30 30 30 30 31 31 31 31 31 31 31 31\\n 31 31 32 32 32 32 32 32 32 32 32 33 33 33 33 33 33 33 33] [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 16  0  1  2  3  4  5  6  7  8\\n  9 10 11 12 13 16 19  2  3  4  5  6  7  8  9 10 11 12 13 14 16 19  0  1\\n  3  4  5  6  7  8  9 10 11 12 13 14 16 19 23  2  4  5  6  7  8  9 10 11\\n 12 13 14 15 16 19 23  0  1  3  5  6  7  8  9 10 11 12 13 14 15 16 19 23\\n 27  2  4  6  7  8  9 10 11 12 13 14 15 16 17 19 23 27  2  4  6  7  8  9\\n 10 11 12 13 14 15 16 17 18 19 23 27  2  4  6  7  8  9 10 11 12 13 14 15\\n 16 17 18 19 20 23 27  0  1  3  5  9 10 11 12 13 14 15 16 17 18 19 20 23\\n 27 28  0  1  3  5  9 10 11 12 13 14 15 16 17 18 19 20 23 27 28 33  2  4\\n  6  7  8 11 12 13 14 15 16 17 18 19 20 21 23 27 28 33  0  1  3  5  9 10\\n 12 13 14 15 16 17 18 19 20 21 23 27 28 33  2  4  6  7  8 11 13 14 15 16\\n 17 18 19 20 21 22 23 27 28 33  2  4  6  7  8 11 13 14 15 16 17 18 19 20\\n 21 22 23 24 27 28 33  4  6  7  8 11 13 14 15 16 17 18 19 20 21 22 23 24\\n 25 27 28 33  0  1  3  5  9 10 12 16 17 18 19 20 21 22 23 24 25 27 28 33\\n  6  7  8 11 13 14 15 17 18 19 20 21 22 23 24 25 26 27 28 33  7  8 11 13\\n 14 15 17 18 19 20 21 22 23 24 25 26 27 28 29 33  1  3  5  9 10 12 16 19\\n 20 21 22 23 24 25 26 27 28 29 33  8 11 13 14 15 17 18 20 21 22 23 24 25\\n 26 27 28 29 30 33 11 13 14 15 17 18 20 21 22 23 24 25 26 27 28 29 30 31\\n 33 13 14 15 17 18 20 21 22 23 24 25 26 27 28 29 30 31 32 33  3  5  9 10\\n 12 16 19 23 24 25 26 27 28 29 30 31 32 33 14 15 17 18 20 21 22 24 25 26\\n 27 28 29 30 31 32 33 15 17 18 20 21 22 24 25 26 27 28 29 30 31 32 33 17\\n 18 20 21 22 24 25 26 27 28 29 30 31 32 33  5  9 10 12 16 19 23 27 28 29\\n 30 31 32 33  9 10 12 16 19 23 27 28 29 30 31 32 33 18 20 21 22 24 25 26\\n 29 30 31 32 33 20 21 22 24 25 26 29 30 31 32 33 21 22 24 25 26 29 30 31\\n 32 33 22 24 25 26 29 30 31 32 33 10 12 16 19 23 27 28 33]\",\n          \"[ 0  0  0 ... 63 63 63] [ 0  1  2 ... 58 60 63]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GRAPH DATA_EDGE_TYPE\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 120,\n        \"samples\": [\n          \"xEffect oWant oWant oWant xWant oWant oWant xWant xWant oWant xWant oWant xWant xWant xWant xEffect xWant xWant oWant xWant xWant oWant oWant xWant oWant xWant xWant oWant oWant oWant xIntent xEffect xWant oWant xWant xWant oWant oWant xWant oWant xWant xWant xWant oWant oWant oWant xIntent xIntent xEffect oWant xWant xWant oWant oWant xWant oWant xWant xWant xWant xWant oWant oWant oWant xIntent xEffect oWant oWant xWant xWant oWant xWant oWant oWant oWant oWant xWant xWant xWant xWant xIntent xIntent xIntent xEffect xWant oWant oWant xWant oWant xWant xWant xWant xWant oWant xWant oWant oWant oWant xIntent xIntent xIntent xIntent xEffect oWant oWant xWant oWant xWant xWant xWant xWant oWant xWant oWant xWant oWant oWant xIntent xIntent xEffect xWant oWant xWant oWant oWant oWant oWant xWant oWant xWant oWant xWant xWant xWant xIntent xIntent xIntent xEffect oWant xWant oWant oWant oWant oWant xWant oWant xWant oWant xWant xWant xWant xWant xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant xWant xWant xWant oWant xWant oWant xWant oWant oWant oWant oWant xWant xIntent xIntent xIntent xIntent xEffect oWant oWant oWant oWant xWant oWant xWant oWant xWant xWant xWant xWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant xWant oWant xWant oWant xWant oWant oWant oWant oWant oWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant oWant xWant oWant xWant oWant oWant oWant oWant oWant xWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant xWant oWant xWant oWant oWant oWant oWant oWant xWant xWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant xWant oWant oWant oWant oWant oWant xWant xWant xWant xWant xWant xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant xWant xWant xWant xWant xWant xWant oWant oWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant oWant oWant oWant oWant oWant xWant xWant xWant xWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant xWant xWant xWant xWant xWant xWant oWant oWant oWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant oWant oWant oWant oWant oWant xWant xWant xWant xWant xWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant xWant xWant xWant xWant xWant oWant oWant oWant oWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant xWant xWant xWant xWant oWant xWant oWant oWant oWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant xWant xWant xWant oWant xWant xWant oWant oWant oWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant xWant xWant oWant xWant xWant xWant oWant oWant oWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant xWant oWant xWant xWant xWant oWant xWant oWant oWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant oWant xWant xWant xWant oWant xWant xWant oWant oWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant xWant xWant xWant oWant xWant xWant xWant oWant oWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant xWant xWant oWant xWant xWant xWant xWant oWant oWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant oWant xWant oWant oWant oWant oWant xWant xWant xWant xWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant oWant xWant xWant xWant xWant xWant oWant oWant oWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant xWant xWant xWant xWant xWant xWant oWant oWant oWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant xWant xWant xWant xWant xWant xWant oWant oWant oWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant oWant oWant oWant oWant oWant xWant xWant xWant xWant xWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant xWant xWant xWant xWant oWant xWant oWant oWant oWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant xWant xWant xWant oWant xWant oWant xWant oWant oWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant xWant xWant oWant xWant oWant xWant xWant oWant oWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant xWant oWant xWant oWant xWant xWant oWant oWant oWant xWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant oWant xWant oWant xWant xWant oWant oWant oWant xWant oWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant xWant oWant xWant xWant oWant oWant oWant xWant oWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant xWant xWant oWant oWant oWant xWant oWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant oWant xWant xWant xWant oWant xWant oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant xWant oWant oWant oWant xWant oWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant xWant xWant xWant oWant xWant oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant oWant oWant xWant oWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant oWant xWant oWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant oWant xWant oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant xWant oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect\",\n          \"xEffect oWant xWant oWant xWant oWant xWant oWant xWant oWant xWant oWant oWant xWant xWant xEffect oWant xWant oWant xWant oWant xWant oWant xWant oWant xWant xWant xWant oWant oWant xIntent xEffect oWant xWant oWant xWant oWant xWant oWant xWant oWant oWant oWant xWant xWant xWant xIntent xEffect oWant xWant oWant xWant oWant xWant oWant xWant xWant xWant xWant oWant oWant oWant xIntent xIntent xEffect oWant xWant oWant xWant oWant xWant oWant oWant oWant oWant xWant xWant xWant xWant xIntent xIntent xEffect oWant xWant oWant xWant oWant xWant xWant xWant xWant xWant oWant oWant oWant oWant xIntent xIntent xIntent xEffect oWant xWant oWant xWant oWant oWant oWant oWant oWant xWant xWant xWant xWant xWant xIntent xIntent xIntent xEffect oWant xWant oWant xWant xWant xWant xWant xWant oWant xWant oWant oWant oWant oWant xIntent xIntent xIntent xIntent xEffect oWant xWant oWant oWant oWant oWant oWant xWant oWant xWant xWant xWant xWant xWant xIntent xIntent xIntent xIntent xEffect oWant xWant xWant xWant xWant xWant oWant xWant oWant xWant oWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant oWant oWant oWant xWant oWant xWant oWant xWant xWant xWant xWant xWant xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant xWant xWant oWant xWant oWant xWant xWant oWant oWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant xWant oWant xWant oWant xWant xWant oWant oWant xWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant oWant xWant oWant xWant xWant oWant oWant xWant oWant xWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant xWant oWant xWant xWant oWant oWant xWant oWant xWant oWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant xWant xWant oWant oWant xWant oWant xWant oWant xWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant oWant xWant xWant oWant xWant oWant xWant oWant oWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant xWant oWant oWant xWant oWant xWant oWant xWant xWant xWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant xWant xWant oWant xWant oWant xWant oWant oWant oWant xWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant oWant xWant oWant xWant oWant xWant xWant xWant oWant xWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant xWant oWant xWant oWant xWant xWant xWant oWant xWant oWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant xWant oWant xWant oWant oWant oWant xWant oWant xWant oWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant xWant oWant oWant oWant xWant oWant xWant oWant xWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant xWant xWant xWant oWant xWant oWant xWant oWant oWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant oWant oWant xWant oWant xWant oWant xWant xWant oWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant xWant xWant oWant xWant oWant xWant oWant oWant xWant oWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant oWant xWant oWant xWant oWant xWant xWant oWant xWant oWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant oWant xWant oWant xWant oWant oWant xWant oWant xWant oWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant xWant oWant xWant oWant oWant xWant oWant xWant oWant xWant oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant xWant oWant oWant xWant oWant xWant oWant xWant oWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant xWant xWant oWant xWant oWant xWant oWant xWant xWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant oWant xWant oWant xWant oWant xWant oWant oWant xWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant xWant oWant xWant oWant xWant oWant xWant xWant xWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant xWant oWant xWant oWant xWant oWant oWant oWant xWant xWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant xWant oWant xWant oWant xWant xWant xWant oWant xWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant xWant oWant xWant xWant xWant oWant xWant xWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant xWant oWant oWant oWant xWant oWant oWant xWant xWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant xWant xWant xWant oWant xWant xWant oWant xWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant oWant oWant xWant oWant oWant xWant oWant xWant xWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant xWant xWant oWant xWant xWant oWant xWant oWant oWant xWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant oWant xWant oWant oWant xWant oWant xWant xWant oWant xWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant oWant xWant xWant oWant xWant oWant oWant xWant oWant xWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant xWant xWant oWant xWant oWant oWant xWant oWant xWant oWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant xWant oWant xWant oWant oWant xWant oWant xWant oWant xWant oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant xWant oWant xWant xWant oWant xWant oWant xWant oWant xWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant xWant oWant oWant xWant oWant xWant oWant xWant oWant oWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant oWant xWant oWant xWant oWant xWant oWant oWant xWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant xWant oWant xWant oWant xWant oWant xWant xWant oWant xWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant xWant oWant xWant oWant xWant oWant oWant xWant oWant xWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant xWant oWant xWant oWant xWant xWant oWant xWant oWant xWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant xWant oWant xWant xWant oWant xWant oWant xWant oWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant xWant oWant oWant xWant oWant xWant oWant xWant oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant xWant xWant oWant xWant oWant xWant oWant xWant oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant oWant xWant oWant xWant oWant xWant oWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant xWant oWant xWant oWant xWant oWant xWant oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant xWant oWant xWant oWant xWant oWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant xWant oWant xWant oWant xWant oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant xWant oWant xWant oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant xWant oWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant xWant oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect\",\n          \"xEffect xWant oWant xWant oWant xWant oWant oWant oWant xWant xWant oWant xWant oWant xWant xIntent xEffect oWant xWant oWant xWant oWant oWant oWant xWant xWant oWant xWant oWant xWant xWant xEffect oWant xWant oWant xWant xWant xWant oWant oWant xWant oWant xWant xWant oWant oWant xIntent xIntent xEffect oWant xWant oWant oWant oWant xWant xWant oWant xWant oWant oWant xWant xWant xWant xIntent xEffect oWant xWant xWant xWant oWant oWant xWant oWant xWant xWant xWant oWant oWant oWant xIntent xIntent xIntent xEffect oWant oWant oWant xWant xWant oWant xWant oWant oWant oWant xWant xWant xWant xWant xIntent xIntent xEffect xWant xWant oWant oWant xWant oWant xWant xWant xWant oWant xWant oWant oWant oWant xIntent xIntent xIntent xEffect xWant oWant oWant xWant oWant xWant xWant xWant oWant xWant xWant oWant oWant oWant xIntent xIntent xIntent xIntent xEffect oWant oWant xWant oWant xWant xWant xWant oWant xWant xWant oWant xWant oWant oWant xIntent xIntent xIntent xIntent xEffect xWant oWant xWant oWant oWant oWant xWant oWant oWant xWant oWant xWant xWant xWant xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant oWant oWant xWant oWant oWant xWant oWant xWant xWant xWant xWant xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant xWant xWant oWant xWant xWant oWant xWant xWant oWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant oWant xWant oWant oWant xWant oWant oWant xWant xWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant oWant xWant xWant oWant xWant xWant xWant oWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant xWant xWant oWant xWant xWant xWant oWant xWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant xWant oWant xWant xWant xWant oWant xWant xWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant xWant oWant oWant oWant xWant oWant oWant xWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant xWant xWant xWant oWant xWant xWant xWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant xWant xWant oWant xWant xWant xWant oWant oWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant oWant xWant oWant oWant oWant xWant xWant oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant oWant xWant xWant xWant oWant oWant xWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant xWant xWant xWant oWant oWant xWant xWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant xWant xWant oWant oWant xWant xWant xWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant oWant xWant xWant oWant oWant oWant oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant oWant oWant xWant xWant xWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant oWant xWant xWant xWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant xWant xWant xWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant oWant oWant oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant oWant oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "3kjdseROi3ro",
        "outputId": "3237d963-0e15-41a0-9b9a-ca74c5c7e129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           UTTERANCE  \\\n",
              "0  Why does that bother you? Well, maybe maybe he...   \n",
              "1  What is it? um. I'm sorry.  It's just a lot ah...   \n",
              "2  Hi. Um-  My luggage didn't come out of the con...   \n",
              "3  Can I help you? Oh, this- this form that you h...   \n",
              "4  Hi,um- I think my baggage was lost, and I need...   \n",
              "5  What time is it?  They're supposed to run arou...   \n",
              "6  You're the only one I know who loves his paren...   \n",
              "7  What's he going to say? Maybe we should tell h...   \n",
              "8  Hi, I need an ID. ahh Yeah, this is the wrong ...   \n",
              "9  Why does that bother you? She's been in New Yo...   \n",
              "\n",
              "                                               LABEL  \\\n",
              "0      2 2 2 5 2 2 5 3 5 5 5 5 5 5 5 5 5 5 5 3 3 3 3   \n",
              "1  2 1 1 1 1 3 3 5 1 5 1 1 3 1 1 5 3 5 3 5 5 5 5 ...   \n",
              "2  2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 5 2 ...   \n",
              "3  2 2 2 2 2 5 5 3 2 5 5 5 5 2 5 5 5 2 5 5 5 5 5 ...   \n",
              "4  2 2 2 2 2 2 5 2 2 2 2 2 2 2 2 2 2 5 2 5 2 2 5 ...   \n",
              "5  4 1 4 4 2 4 4 4 4 4 4 4 5 4 4 5 4 4 4 5 5 5 4 ...   \n",
              "6  0 0 0 0 0 2 1 0 2 2 0 0 4 4 4 0 4 0 0 1 1 1 1 ...   \n",
              "7  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 5 5 3 5 5 5 ...   \n",
              "8  2 2 5 5 5 2 5 5 5 5 5 5 5 5 2 5 5 5 5 5 5 5 5 ...   \n",
              "9  2 2 2 2 5 5 5 5 3 5 5 5 5 5 5 3 5 3 5 3 5 5 3 ...   \n",
              "\n",
              "                                      SPEAKER GENDER  \\\n",
              "0      M M F M M F M F M M M M F M F M M F M F M F M   \n",
              "1  M F F F F M M M F M F F M F F F M F M M F F F ...   \n",
              "2  M F M F M F M F M F M F M F M F M F M F F M F ...   \n",
              "3  F F F F F M F M F M F M F F F M F F M F M F F ...   \n",
              "4  F M F M F M F M F F M M F M M F M F M F M F M ...   \n",
              "5  M F M M F M M M M M M M M M M F M M M F M F M ...   \n",
              "6  F M F F F M F M M F F M M M M F M F F M F M M ...   \n",
              "7  F M M M M F M F M F F M F M M M M M M M F M M ...   \n",
              "8  F M F F F M F M F M F M F M F M F M F M F M F ...   \n",
              "9  M F M M M M F M F F M F M F M F M F M F M M F ...   \n",
              "\n",
              "                               GRAPH DATA_EDGE_INDEX  \\\n",
              "0  [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...   \n",
              "1  [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...   \n",
              "2  [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...   \n",
              "3  [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...   \n",
              "4    [ 0  0  0 ... 90 90 90] [ 0  1  2 ... 86 88 90]   \n",
              "5  [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...   \n",
              "6  [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...   \n",
              "7    [ 0  0  0 ... 52 52 52] [ 0  1  2 ... 50 51 52]   \n",
              "8  [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...   \n",
              "9  [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...   \n",
              "\n",
              "                                GRAPH DATA_EDGE_TYPE  \n",
              "0  xEffect xWant oWant xWant xWant oWant xWant oW...  \n",
              "1  xEffect oWant oWant oWant oWant xWant xWant xW...  \n",
              "2  xEffect oWant xWant oWant xWant oWant xWant oW...  \n",
              "3  xEffect xWant xWant xWant xWant oWant xWant oW...  \n",
              "4  xEffect oWant xWant oWant xWant oWant xWant oW...  \n",
              "5  xEffect oWant xWant xWant oWant xWant xWant xW...  \n",
              "6  xEffect oWant xWant xWant xWant oWant xWant oW...  \n",
              "7  xEffect oWant oWant oWant oWant xWant oWant xW...  \n",
              "8  xEffect oWant xWant xWant xWant oWant xWant oW...  \n",
              "9  xEffect oWant xWant xWant xWant xWant oWant xW...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9bf4e27c-ce35-48b1-b172-21670bee705d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UTTERANCE</th>\n",
              "      <th>LABEL</th>\n",
              "      <th>SPEAKER GENDER</th>\n",
              "      <th>GRAPH DATA_EDGE_INDEX</th>\n",
              "      <th>GRAPH DATA_EDGE_TYPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Why does that bother you? Well, maybe maybe he...</td>\n",
              "      <td>2 2 2 5 2 2 5 3 5 5 5 5 5 5 5 5 5 5 5 3 3 3 3</td>\n",
              "      <td>M M F M M F M F M M M M F M F M M F M F M F M</td>\n",
              "      <td>[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...</td>\n",
              "      <td>xEffect xWant oWant xWant xWant oWant xWant oW...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is it? um. I'm sorry.  It's just a lot ah...</td>\n",
              "      <td>2 1 1 1 1 3 3 5 1 5 1 1 3 1 1 5 3 5 3 5 5 5 5 ...</td>\n",
              "      <td>M F F F F M M M F M F F M F F F M F M M F F F ...</td>\n",
              "      <td>[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...</td>\n",
              "      <td>xEffect oWant oWant oWant oWant xWant xWant xW...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hi. Um-  My luggage didn't come out of the con...</td>\n",
              "      <td>2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 5 2 ...</td>\n",
              "      <td>M F M F M F M F M F M F M F M F M F M F F M F ...</td>\n",
              "      <td>[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...</td>\n",
              "      <td>xEffect oWant xWant oWant xWant oWant xWant oW...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Can I help you? Oh, this- this form that you h...</td>\n",
              "      <td>2 2 2 2 2 5 5 3 2 5 5 5 5 2 5 5 5 2 5 5 5 5 5 ...</td>\n",
              "      <td>F F F F F M F M F M F M F F F M F F M F M F F ...</td>\n",
              "      <td>[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...</td>\n",
              "      <td>xEffect xWant xWant xWant xWant oWant xWant oW...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hi,um- I think my baggage was lost, and I need...</td>\n",
              "      <td>2 2 2 2 2 2 5 2 2 2 2 2 2 2 2 2 2 5 2 5 2 2 5 ...</td>\n",
              "      <td>F M F M F M F M F F M M F M M F M F M F M F M ...</td>\n",
              "      <td>[ 0  0  0 ... 90 90 90] [ 0  1  2 ... 86 88 90]</td>\n",
              "      <td>xEffect oWant xWant oWant xWant oWant xWant oW...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>What time is it?  They're supposed to run arou...</td>\n",
              "      <td>4 1 4 4 2 4 4 4 4 4 4 4 5 4 4 5 4 4 4 5 5 5 4 ...</td>\n",
              "      <td>M F M M F M M M M M M M M M M F M M M F M F M ...</td>\n",
              "      <td>[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...</td>\n",
              "      <td>xEffect oWant xWant xWant oWant xWant xWant xW...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>You're the only one I know who loves his paren...</td>\n",
              "      <td>0 0 0 0 0 2 1 0 2 2 0 0 4 4 4 0 4 0 0 1 1 1 1 ...</td>\n",
              "      <td>F M F F F M F M M F F M M M M F M F F M F M M ...</td>\n",
              "      <td>[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...</td>\n",
              "      <td>xEffect oWant xWant xWant xWant oWant xWant oW...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>What's he going to say? Maybe we should tell h...</td>\n",
              "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 5 5 3 5 5 5 ...</td>\n",
              "      <td>F M M M M F M F M F F M F M M M M M M M F M M ...</td>\n",
              "      <td>[ 0  0  0 ... 52 52 52] [ 0  1  2 ... 50 51 52]</td>\n",
              "      <td>xEffect oWant oWant oWant oWant xWant oWant xW...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Hi, I need an ID. ahh Yeah, this is the wrong ...</td>\n",
              "      <td>2 2 5 5 5 2 5 5 5 5 5 5 5 5 2 5 5 5 5 5 5 5 5 ...</td>\n",
              "      <td>F M F F F M F M F M F M F M F M F M F M F M F ...</td>\n",
              "      <td>[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...</td>\n",
              "      <td>xEffect oWant xWant xWant xWant oWant xWant oW...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Why does that bother you? She's been in New Yo...</td>\n",
              "      <td>2 2 2 2 5 5 5 5 3 5 5 5 5 5 5 3 5 3 5 3 5 5 3 ...</td>\n",
              "      <td>M F M M M M F M F F M F M F M F M F M F M M F ...</td>\n",
              "      <td>[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...</td>\n",
              "      <td>xEffect oWant xWant xWant xWant xWant oWant xW...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9bf4e27c-ce35-48b1-b172-21670bee705d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9bf4e27c-ce35-48b1-b172-21670bee705d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9bf4e27c-ce35-48b1-b172-21670bee705d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f8ca394c-1d49-453a-823a-6aa760f716f2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f8ca394c-1d49-453a-823a-6aa760f716f2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f8ca394c-1d49-453a-823a-6aa760f716f2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_df",
              "summary": "{\n  \"name\": \"test_df\",\n  \"rows\": 31,\n  \"fields\": [\n    {\n      \"column\": \"UTTERANCE\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 31,\n        \"samples\": [\n          \"You knew there was nothing in that. Only a trivial little broach. You worked the whole thing up in your jealous imagination. You must admit that he was in love with you, wasn't he? maybe just a little, but-- You let him kiss you.  You said you did. And what of it? What of it? Well, I- he got a lot of pleasure out of it and it didn't hurt me. Well, that's a nice point of view I must say. I'm growing quite tired and bored of this conversation. So am I, bored stiff.  Would you like some brandy? I'll have a little I think. I don't see why you want any.  You've already had three glasses. Well, it seems silly to go on and on in such a thing. It's becoming a habit with you. You needn't be so grand simply because you don't happen to want any at the moment. Really, Amanda. Just making myself fascinating for you. Oh, that reply has broken my heart. Oh, yes it is. It's a pity you didn't take a little more brandy.  It might have made you a little less disagreeable. Um, It doesn't seem to have worked such wonders with you. adder don't snap, they sting. They sting. They snap. I don't care if they bark and roll around like hoops, okay. [BREATHING] Did you see much of Peter Burden after the divorce? Yes, I did quite a bit. I suppose you let him kiss you a good deal more then. Mind your own business. You must have a riotous time, no restraint at all, very enjoyable.  I mean, you never had much anyway. Oh dear, you really are becoming quite insufferable.  I would imagine it's because you're drunk. Oh, You are so insufferable.  Do you stop. Oh, This is very interesting.  We- we might get a splendid debate going about this intemperate tots. Not very funny, dear, you better have some more brandy. Ugh. You better turn that off I think. Why? There aren't any people upstairs; it's a photographer's studio. They're away in Tunis. Turn it on again. Fine, if you insist on being completely insolent. Turn it off.  It is driving me mad. Well, do try to control yourself darling. Turn it off. You really do need to develop uh a clearer head. Turn it off. I- I hate you. Amanda-- Listen- Listen- I hate you. No, no.  I'm tired of listening to you.  You're boorish and idiotic and completely overbearing. Very music- amusing indeed. Yeah, very amusing.  Let me go.  I'm getting out of here.  I can't believe I intended to marry you. You are a vile tempered, loose living, wicked little beast, and I never want to set eyes on you again. Oh, marry you again?  I must have been insane.  What was I thinking?  I mean, you're completely outrageous. Shut up, shut up.  I wouldn't marry you again if you came crawling to me on bended knee. You're a mean, evil-minded little vampire and I hope to God I never set eyes on you again. Beast; brute; cad; whore\",\n          \"What's he going to say?  Maybe we ought to tell him before he sees it. He was out here when it broke. About four this morning.  I heard it crack and I looked out the window and he was standing right there when it cracked. I don't know.  But after he saw it, he ran back into the house and started crying in the kitchen. No.  I figured it was best to leave him alone. Yes, yes he is.  I don't know the meaning in it.  But I know one thing, mom, we made a terrible mistake with Dad. I don't want to argue with him.  But it's time that he knows that nobody else believes that Larry's alive. I mean Why shouldn't he dream about him, walk the nights waiting for him?  Do we contradict him?  Do we say outright that we don't have any hope anymore?  That we haven't had any hope for a long time? For Gods sake, three years!  Nobody comes back after three years.  It's insane! The trouble is the God damn newspapers, I mean, ea- each week a new boy turns up out of nowhere.  So the next one is gonna be Larry.  So you-- All right.  All right, just listen. You know it's not just my business. What do you want me to do?  I mean, You're old enough to know your own mind. So it's all right then?  I should just go ahead with it? Isn't it your business, too, if I tell dad and he throws a fit about it?  You have such a talent for ignoring things. I ignore what I got to ignore.  I mean, the girl is Larry's girl. She's not Larry's girl. I don't know why it is but every time I reach out for something that I want, I have to pull back because it might hurt somebody else, my whole bloody life, time after time, after time. what to hell with that! Have you asked Annie yet? Well, how do you know she'll marry you?  Maybe she feels like your father does. I'll find out and then we'll thrash it out with dad, all right?  Mom, don't avoid me. The trouble is you don't see enough women.  You never did. So what, I'm not fast with women? Because it is. Well, that's a good reason.  But it don't mean a thing. I mean, You haven't seen her since you went to war.  It's been five years. [garbage] I don't know.  It's just, she's who I know best. I know her since I- I was a kid I grew up with her.  When I think of somebody for my wife these days, I I think of Annie.  What do you want, a diagram? No I don't want a-  Your father thinks he's coming back, Chris.  If you marry that girl, you're pronouncing him dead. Now, what's going to happen to your father, do you know?  I don't. All right then, mom. I've given it three years of thought.  I had hoped if I waited, dad would've forgotten him by now and we could have a- a regular wedding and everybody happy. But if that can't happen then I'll just get out. I'll get out.  I'll go get married someplace else, I- I'll live someplace else, maybe New York. Are you crazy? The business?  The business doesn't inspire me. Must you be inspired? Yeah, I'd like one hour a day.  If I have to grub for money all day long, I'd like to go home to something beautiful.  I'd like a family.  I'd like some kids. You don't want to think like that. All right.  But don't think like that because what the hell did we work for, Chris?  All of this, all of it, it's all just for you. I know that, mom.  Just you help me stay here. Well, I am thinking like that. I don't understand you, do I? No, you don't.  I'm a pretty tough guy.\",\n          \"I wonder. what, Nobody knows we are here except Freda and she wouldn't ring up. What do we do? We're all right, aren't we, darling, whatever happens? Now and always, my sweet. I don't care then. It was bound to happen sooner or later. Oh, it sent shivers up my spine. Oh, what shall we do if they suddenly walk in on us. With the worst- with the most perfect poise? Uhh, It's amazing how once you feel-- things that ought to matter most dreadfully don't matter at all when one's happy, do they? Uhh, You mustn't say that, my darling. Being that sacred and wonderful thing, love. Um What does it all mean?  That's what I ask myself in my endless quest for ultimate truth.  Dear God, what does it all mean? Don't laugh at me.  I'm serious. You mustn't be serious, darling.  That's just what they want. Who's they? All the futile mortals who try to make life unbearable.  Laugh at them, Be flippant.  Laugh at everything, all their sacred shibboleths. uh- the- Being flippant brings out the acid in their damned beauty and light. If I laugh at everything, then I must laugh at us too. Certainly you must.  We are figures of fun all right. Well, will we always bicker and fight? No.  That fire will fade along with our passion. What if one of us dies, does the other one laugh then? Yes, yes, with all his might. No, no that is quit laughable.  The cutting little mystery all done with mirrors. So is everyone else in the long run.  Let's be superficial and pity the poor philosophers.  Let's blow trumpets and squeakers and enjoy the party as long as we can, like little quiet idiotic school children. [garbage] Darling, kiss me before your body rots and worms start popping in and out of your eye sockets. Elliott, worms don't pop. I don't care what you do.  See, you could paint your body bright green and and run naked through the Place Vendome and run with every man in the world and I shan't say a word.  As long as I know that you love me best. Do you remember that awful scene we had in Venice? The one where you bought that little painted wooden stake and you put it on my bed. Horrible thing.  I hated it. I know you did.  You threw it out the window into the Canal below.  I don't think I'll ever forgive you for that. How long did that roue last? Oh, The worst one was in Cannes when your curling iron burnt a hole in my new dressing gown? Oh, It burnt my comb and all the towels in the bathroom. [LAUGHTER] That was quit a rouser, wasn't it? Oh, I didn't hit you very hard. I should never forget his face. [LAUGHTER] We were very much younger then. You knew there was nothing in that.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LABEL\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 31,\n        \"samples\": [\n          \"2 2 2 3 2 3 2 5 2 3 5 2 2 2 2 2 3 3 2 3 5 3 3 3 3 3 3 5 3 2 3 3 3 3 5 5 3 5 5 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\",\n          \"1 1 1 1 1 1 5 5 5 5 5 5 5 5 3 5 3 5 3 2 2 5 2 5 5 2 5 5 5 1 5 3 3 3 3 3 3 3 3 5 5 3 5 3\",\n          \"4 4 4 2 4 4 4 4 4 4 4 4 4 4 4 2 4 2 4 4 2 4 2 4 2 4 4 4 4 2 4 4 4 4 4 4 4 4 4 4 4 4 2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SPEAKER GENDER\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 31,\n        \"samples\": [\n          \"F F F M F M F M F M F M M F F F M M F M M M F F F M F M M F M F M F F M F F M F F F F F M F M F M F M F F M F M F M F\",\n          \"F M M M M M M M M F M M F M M F M M M F F M F M M F M M F F M M M M F M F M F F M M F M\",\n          \"M F F M F M F F M M M M M M M F M F M M F M F M F M M M M F M M M M F M M F M M M M F\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GRAPH DATA_EDGE_INDEX\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"[ 0  0  0 ... 58 58 58] [ 0  1  2 ... 55 57 58]\",\n          \"[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  1  1  1  1\\n  1  1  1  1  1  1  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  3  3\\n  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  4  4  4  4  4  4  4  4  4\\n  4  4  4  4  4  4  4  4  4  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\\n  5  5  5  5  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\\n  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  8  8  8\\n  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  9  9  9  9  9\\n  9  9  9  9  9  9  9  9  9  9  9 10 10 10 10 10 10 10 10 10 10 10 10 10\\n 10 10 10 10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\\n 11 11 11 11 11 11 11 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\\n 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 14 14\\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 15 15 15 15\\n 15 15 15 15 15 15 15 15 15 15 15 15 15 15 16 16 16 16 16 16 16 16 16 16\\n 16 16 16 16 16 16 16 16 16 16 16 16 17 17 17 17 17 17 17 17 17 17 17 17\\n 17 17 17 17 17 17 17 17 17 17 18 18 18 18 18 18 18 18 18 18 18 18 18 18\\n 18 18 18 18 18 18 18 18 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19\\n 19 19 19 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 21\\n 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 22 22 22\\n 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 23 23 23 23 23 23\\n 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 24 24 24 24 24 24 24 24\\n 24 24 24 24 24 24 24 24 24 24 24 24 24 24 25 25 25 25 25 25 25 25 25 25\\n 25 25 25 25 25 25 25 25 25 25 25 25 26 26 26 26 26 26 26 26 26 26 26 26\\n 26 26 26 26 26 26 26 26 26 26 27 27 27 27 27 27 27 27 27 27 27 27 27 27\\n 27 27 27 27 27 27 27 27 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\\n 28 28 28 28 28 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\\n 29 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 31 31 31\\n 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 32 32 32 32 32 32 32\\n 32 32 32 32 32 32 32 32 32 32 32 32 33 33 33 33 33 33 33 33 33 33 33 33\\n 33 33 33 33 33 33 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 35\\n 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 36 36 36 36 36 36 36 36 36\\n 36 36 36 36 36 36 37 37 37 37 37 37 37 37 37 37 37 37 37 37 38 38 38 38\\n 38 38 38 38 38 38 38 38 38 39 39 39 39 39 39 39 39 39 39 39 39 40 40 40\\n 40 40 40 40 40 40 40 40 41 41 41 41 41 41 41 41 41 41 42 42 42 42 42 42\\n 42 42 42 43 43 43 43 43 43 43 43] [ 0  1  2  3  4  5  6  7  9 12 15 19 20 22 25  1  2  3  4  5  6  7  8  9\\n 12 15 19 20 22 25  1  2  3  4  5  6  7  8  9 10 12 15 19 20 22 25  1  2\\n  3  4  5  6  7  8  9 10 11 12 15 19 20 22 25  1  2  3  4  5  6  7  8  9\\n 10 11 12 13 15 19 20 22 25  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15\\n 19 20 22 25  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 19 20 22 25\\n  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 19 20 22 25  1  2  3\\n  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 22 25  0  9 10 11 12\\n 13 14 15 16 17 18 19 20 22 25 28  2  3  4  5  6  7  8 10 11 12 13 14 15\\n 16 17 18 19 20 21 22 25 28  3  4  5  6  7  8 10 11 12 13 14 15 16 17 18\\n 19 20 21 22 23 25 28  0  9 12 13 14 15 16 17 18 19 20 21 22 23 25 28 29\\n  4  5  6  7  8 10 11 13 14 15 16 17 18 19 20 21 22 23 24 25 28 29  5  6\\n  7  8 10 11 13 14 15 16 17 18 19 20 21 22 23 24 25 26 28 29  0  9 12 15\\n 16 17 18 19 20 21 22 23 24 25 26 28 29 34  6  7  8 10 11 13 14 16 17 18\\n 19 20 21 22 23 24 25 26 27 28 29 34  7  8 10 11 13 14 16 17 18 19 20 21\\n 22 23 24 25 26 27 28 29 30 34  8 10 11 13 14 16 17 18 19 20 21 22 23 24\\n 25 26 27 28 29 30 31 34  0  9 12 15 19 20 21 22 23 24 25 26 27 28 29 30\\n 31 34 36  0  9 12 15 19 20 21 22 23 24 25 26 27 28 29 30 31 34 36 38 10\\n 11 13 14 16 17 18 21 22 23 24 25 26 27 28 29 30 31 32 34 36 38  0  9 12\\n 15 19 20 22 23 24 25 26 27 28 29 30 31 32 34 36 38 39 11 13 14 16 17 18\\n 21 23 24 25 26 27 28 29 30 31 32 33 34 36 38 39 13 14 16 17 18 21 23 24\\n 25 26 27 28 29 30 31 32 33 34 35 36 38 39  0  9 12 15 19 20 22 25 26 27\\n 28 29 30 31 32 33 34 35 36 38 39 42 14 16 17 18 21 23 24 26 27 28 29 30\\n 31 32 33 34 35 36 37 38 39 42 16 17 18 21 23 24 26 27 28 29 30 31 32 33\\n 34 35 36 37 38 39 40 42  9 12 15 19 20 22 25 28 29 30 31 32 33 34 35 36\\n 37 38 39 40 42 12 15 19 20 22 25 28 29 30 31 32 33 34 35 36 37 38 39 40\\n 42 17 18 21 23 24 26 27 30 31 32 33 34 35 36 37 38 39 40 41 42 18 21 23\\n 24 26 27 30 31 32 33 34 35 36 37 38 39 40 41 42 43 21 23 24 26 27 30 31\\n 32 33 34 35 36 37 38 39 40 41 42 43 23 24 26 27 30 31 32 33 34 35 36 37\\n 38 39 40 41 42 43 15 19 20 22 25 28 29 34 35 36 37 38 39 40 41 42 43 24\\n 26 27 30 31 32 33 35 36 37 38 39 40 41 42 43 19 20 22 25 28 29 34 36 37\\n 38 39 40 41 42 43 26 27 30 31 32 33 35 37 38 39 40 41 42 43 20 22 25 28\\n 29 34 36 38 39 40 41 42 43 22 25 28 29 34 36 38 39 40 41 42 43 27 30 31\\n 32 33 35 37 40 41 42 43 30 31 32 33 35 37 40 41 42 43 25 28 29 34 36 38\\n 39 42 43 31 32 33 35 37 40 41 43]\",\n          \"[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  1  1  1  1\\n  1  1  1  1  1  1  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  3  3\\n  3  3  3  3  3  3  3  3  3  3  3  3  3  3  4  4  4  4  4  4  4  4  4  4\\n  4  4  4  4  4  4  4  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\\n  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  7  7  7  7  7  7\\n  7  7  7  7  7  7  7  7  7  7  7  7  7  8  8  8  8  8  8  8  8  8  8  8\\n  8  8  8  8  8  8  8  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\\n  9  9 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 11 11\\n 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 12 12 12 12 12\\n 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 13 13 13 13 13 13 13\\n 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 14 14 14 14 14 14 14 14 14\\n 14 14 14 14 14 14 14 14 14 14 14 14 14 15 15 15 15 15 15 15 15 15 15 15\\n 15 15 15 15 15 15 15 15 15 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16\\n 16 16 16 16 16 16 16 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17\\n 17 17 17 17 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18\\n 18 18 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19\\n 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 21 21 21\\n 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 22 22 22 22 22 22\\n 22 22 22 22 22 22 22 22 22 22 22 22 22 22 23 23 23 23 23 23 23 23 23 23\\n 23 23 23 23 23 23 23 23 23 23 24 24 24 24 24 24 24 24 24 24 24 24 24 24\\n 24 24 24 24 24 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\\n 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 27 27 27 27 27\\n 27 27 27 27 27 27 27 27 27 27 27 27 27 27 28 28 28 28 28 28 28 28 28 28\\n 28 28 28 28 28 28 28 28 28 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\\n 29 29 29 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 31 31 31\\n 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 32 32 32 32 32 32 32 32 32\\n 32 32 32 32 32 32 32 32 32 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\\n 33 33 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 35 35 35 35 35 35\\n 35 35 35 35 35 35 35 35 35 36 36 36 36 36 36 36 36 36 36 36 36 36 36 37\\n 37 37 37 37 37 37 37 37 37 37 37 37 38 38 38 38 38 38 38 38 38 38 38 38\\n 39 39 39 39 39 39 39 39 39 39 39 40 40 40 40 40 40 40 40 40 40 41 41 41\\n 41 41 41 41 41 41 42 42 42 42 42 42 42 42] [ 0  1  2  3  4  5  6  7  8  9 10 11 12 15 17  1  2  3  4  5  6  7  8  9\\n 10 11 12 15 17 20  1  2  3  4  5  6  7  8  9 10 11 12 15 17 20 22  0  3\\n  4  5  6  7  8  9 10 11 12 13 15 17 20 22  1  2  4  5  6  7  8  9 10 11\\n 12 13 15 17 20 22 24  0  3  5  6  7  8  9 10 11 12 13 14 15 17 20 22 24\\n  1  2  4  6  7  8  9 10 11 12 13 14 15 17 20 22 24 29  1  2  4  6  7  8\\n  9 10 11 12 13 14 15 17 20 22 24 29 34  0  3  5  8  9 10 11 12 13 14 15\\n 16 17 20 22 24 29 34  0  3  5  8  9 10 11 12 13 14 15 16 17 18 20 22 24\\n 29 34  0  3  5  8  9 10 11 12 13 14 15 16 17 18 19 20 22 24 29 34  0  3\\n  5  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 24 29 34  0  3  5  8  9\\n 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 29 34  3  5  8  9 10 11 12\\n 13 14 15 16 17 18 19 20 21 22 23 24 25 29 34  5  8  9 10 11 12 13 14 15\\n 16 17 18 19 20 21 22 23 24 25 26 29 34  1  2  4  6  7 15 16 17 18 19 20\\n 21 22 23 24 25 26 29 34 37  8  9 10 11 12 13 14 16 17 18 19 20 21 22 23\\n 24 25 26 27 29 34 37  1  2  4  6  7 15 17 18 19 20 21 22 23 24 25 26 27\\n 29 34 37 42  9 10 11 12 13 14 16 18 19 20 21 22 23 24 25 26 27 28 29 34\\n 37 42 10 11 12 13 14 16 18 19 20 21 22 23 24 25 26 27 28 29 30 34 37 42\\n  1  2  4  6  7 15 17 20 21 22 23 24 25 26 27 28 29 30 34 37 42 11 12 13\\n 14 16 18 19 21 22 23 24 25 26 27 28 29 30 31 34 37 42  2  4  6  7 15 17\\n 20 22 23 24 25 26 27 28 29 30 31 34 37 42 12 13 14 16 18 19 21 23 24 25\\n 26 27 28 29 30 31 32 34 37 42  4  6  7 15 17 20 22 24 25 26 27 28 29 30\\n 31 32 34 37 42 13 14 16 18 19 21 23 25 26 27 28 29 30 31 32 33 34 37 42\\n 14 16 18 19 21 23 25 26 27 28 29 30 31 32 33 34 35 37 42 16 18 19 21 23\\n 25 26 27 28 29 30 31 32 33 34 35 36 37 42 18 19 21 23 25 26 27 28 29 30\\n 31 32 33 34 35 36 37 38 42  6  7 15 17 20 22 24 29 30 31 32 33 34 35 36\\n 37 38 42 19 21 23 25 26 27 28 30 31 32 33 34 35 36 37 38 39 42 21 23 25\\n 26 27 28 30 31 32 33 34 35 36 37 38 39 40 42 23 25 26 27 28 30 31 32 33\\n 34 35 36 37 38 39 40 41 42 25 26 27 28 30 31 32 33 34 35 36 37 38 39 40\\n 41 42  7 15 17 20 22 24 29 34 35 36 37 38 39 40 41 42 26 27 28 30 31 32\\n 33 35 36 37 38 39 40 41 42 27 28 30 31 32 33 35 36 37 38 39 40 41 42 15\\n 17 20 22 24 29 34 37 38 39 40 41 42 28 30 31 32 33 35 36 38 39 40 41 42\\n 30 31 32 33 35 36 38 39 40 41 42 31 32 33 35 36 38 39 40 41 42 32 33 35\\n 36 38 39 40 41 42 17 20 22 24 29 34 37 42]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GRAPH DATA_EDGE_TYPE\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 31,\n        \"samples\": [\n          \"xEffect xWant xWant oWant xWant oWant xWant oWant xWant oWant xWant oWant oWant xWant oWant xIntent xEffect xWant oWant xWant oWant xWant oWant xWant oWant xWant oWant oWant xWant xWant oWant xIntent xIntent xEffect oWant xWant oWant xWant oWant xWant oWant xWant oWant oWant xWant xWant xWant oWant xEffect oWant xWant oWant xWant oWant xWant oWant xWant xWant oWant oWant oWant xWant xWant xIntent xIntent xIntent xEffect oWant xWant oWant xWant oWant xWant oWant oWant xWant xWant xWant oWant oWant xWant xIntent xEffect oWant xWant oWant xWant oWant xWant xWant oWant oWant oWant xWant xWant oWant xWant xIntent xIntent xIntent xIntent xEffect oWant xWant oWant xWant oWant oWant xWant xWant xWant oWant oWant xWant oWant xWant xIntent xIntent xEffect oWant xWant oWant xWant xWant oWant oWant oWant xWant xWant oWant xWant xWant oWant xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant oWant xWant xWant xWant oWant oWant xWant oWant oWant xWant xWant xIntent xIntent xIntent xEffect oWant xWant xWant oWant oWant oWant xWant xWant oWant xWant xWant xWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant xWant xWant xWant oWant oWant xWant oWant oWant oWant xWant xWant xWant xIntent xIntent xIntent xIntent xEffect xWant oWant oWant oWant xWant xWant oWant xWant xWant xWant oWant oWant oWant xWant xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant oWant xWant xWant oWant xWant xWant xWant oWant oWant oWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant oWant oWant xWant oWant oWant oWant xWant xWant xWant oWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant oWant xWant oWant oWant oWant xWant xWant xWant oWant xWant oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant xWant oWant oWant oWant xWant xWant xWant oWant xWant oWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant xWant xWant xWant oWant oWant oWant xWant oWant xWant xWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant xWant xWant oWant oWant oWant xWant oWant xWant xWant oWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant oWant xWant xWant xWant oWant xWant oWant oWant xWant oWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant oWant oWant oWant xWant oWant xWant xWant oWant xWant oWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant oWant oWant xWant oWant xWant xWant oWant xWant oWant xWant oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant oWant xWant oWant xWant xWant oWant xWant oWant xWant oWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant oWant xWant oWant oWant xWant oWant xWant oWant xWant xWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant xWant oWant oWant xWant oWant xWant oWant xWant xWant oWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant oWant xWant oWant xWant oWant xWant xWant oWant xWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant xWant oWant xWant oWant xWant oWant oWant xWant oWant oWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant xWant oWant xWant oWant xWant xWant oWant xWant xWant oWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant xWant oWant xWant oWant oWant xWant oWant oWant xWant oWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant xWant oWant oWant xWant oWant oWant xWant oWant xWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant xWant xWant oWant xWant xWant oWant xWant xWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant oWant xWant oWant oWant xWant oWant oWant xWant xWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant xWant oWant xWant xWant oWant xWant xWant xWant oWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant xWant oWant oWant xWant oWant oWant oWant xWant xWant xWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant xWant xWant oWant xWant xWant xWant xWant oWant oWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant xWant oWant xWant xWant xWant xWant xWant oWant oWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant xWant oWant oWant oWant oWant oWant xWant xWant xWant xWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant xWant xWant xWant xWant xWant oWant xWant oWant oWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant xWant xWant xWant xWant oWant xWant oWant xWant oWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant oWant oWant oWant xWant oWant xWant oWant xWant xWant xWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant xWant xWant oWant xWant oWant xWant oWant xWant oWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant xWant oWant xWant oWant xWant oWant xWant oWant xWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant oWant xWant oWant xWant oWant xWant oWant xWant xWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant xWant oWant xWant oWant xWant oWant xWant xWant oWant xWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant xWant oWant xWant oWant xWant xWant oWant xWant oWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant xWant oWant xWant oWant oWant xWant oWant xWant oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant xWant oWant xWant xWant oWant xWant oWant xWant oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant xWant oWant oWant xWant oWant xWant oWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant xWant xWant oWant xWant oWant xWant oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant oWant xWant oWant xWant oWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant xWant oWant xWant oWant xWant oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant xWant oWant xWant oWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant xWant oWant xWant oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant xWant oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect\",\n          \"xEffect oWant oWant oWant oWant oWant oWant oWant xWant xWant xWant xWant xWant xWant xWant xEffect xWant xWant xWant xWant xWant xWant xWant oWant oWant oWant oWant oWant oWant oWant xIntent xEffect xWant xWant xWant xWant xWant xWant oWant xWant oWant oWant oWant oWant oWant oWant xIntent xIntent xEffect xWant xWant xWant xWant xWant oWant xWant xWant oWant oWant oWant oWant oWant oWant xIntent xIntent xIntent xEffect xWant xWant xWant xWant oWant xWant xWant oWant xWant oWant oWant oWant oWant oWant xIntent xIntent xIntent xIntent xEffect xWant xWant xWant oWant xWant xWant oWant xWant xWant oWant oWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant oWant xWant xWant oWant xWant xWant oWant xWant oWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant xWant xWant oWant xWant xWant oWant xWant xWant oWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant xWant oWant xWant xWant oWant xWant xWant xWant oWant oWant oWant oWant xIntent xEffect oWant oWant xWant oWant oWant xWant oWant oWant oWant xWant xWant xWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant xWant xWant oWant xWant xWant xWant oWant oWant xWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant xWant oWant xWant xWant xWant oWant oWant xWant oWant xWant oWant oWant xIntent xIntent xEffect oWant oWant xWant oWant oWant oWant xWant xWant oWant xWant oWant xWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant xWant xWant xWant oWant oWant xWant oWant xWant xWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant xWant xWant oWant oWant xWant oWant xWant xWant oWant xWant oWant oWant xIntent xIntent xIntent xEffect oWant oWant oWant xWant xWant oWant xWant oWant oWant xWant oWant xWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant oWant oWant xWant oWant xWant xWant oWant xWant xWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant oWant xWant oWant xWant xWant oWant xWant xWant oWant oWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant xWant oWant xWant xWant oWant xWant xWant oWant oWant xWant xWant oWant xIntent xIntent xIntent xIntent xEffect xWant oWant xWant oWant oWant xWant oWant oWant xWant xWant oWant oWant xWant xWant xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant oWant xWant oWant oWant xWant xWant oWant oWant xWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant xWant oWant xWant xWant oWant oWant xWant xWant xWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant xWant oWant oWant xWant xWant oWant oWant oWant xWant xWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant xWant xWant oWant oWant xWant xWant xWant xWant oWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant xWant oWant oWant xWant xWant xWant xWant oWant xWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant xWant xWant oWant oWant oWant oWant xWant oWant xWant xWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant oWant xWant xWant xWant xWant oWant xWant oWant xWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant xWant xWant xWant xWant oWant xWant oWant xWant oWant oWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant oWant oWant oWant xWant oWant xWant oWant xWant xWant oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant oWant oWant xWant oWant xWant oWant xWant xWant oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant xWant oWant xWant oWant xWant oWant oWant xWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant oWant xWant oWant xWant oWant oWant xWant xWant oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant xWant oWant xWant oWant oWant xWant xWant oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant xWant oWant oWant xWant xWant oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant xWant xWant oWant oWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant oWant xWant xWant oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant xWant oWant oWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant xWant xWant oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant oWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect\",\n          \"xEffect oWant oWant xWant oWant xWant oWant oWant xWant xWant xWant xWant xWant oWant oWant xEffect xWant oWant xWant oWant xWant xWant oWant oWant oWant oWant oWant xWant xWant xWant xIntent xEffect oWant xWant oWant xWant xWant oWant oWant oWant oWant oWant xWant xWant xWant xWant xIntent xEffect oWant xWant oWant oWant xWant xWant xWant xWant xWant xWant oWant oWant oWant oWant xIntent xIntent xEffect oWant xWant xWant oWant oWant oWant oWant oWant oWant xWant xWant xWant xWant xWant xIntent xIntent xEffect oWant oWant xWant xWant xWant xWant xWant xWant xWant oWant oWant oWant oWant oWant xIntent xIntent xIntent xEffect xWant oWant oWant oWant oWant oWant oWant oWant xWant xWant xWant xWant xWant xWant xIntent xIntent xIntent xIntent xEffect oWant oWant oWant oWant oWant oWant oWant xWant xWant xWant xWant xWant xWant xWant xIntent xIntent xIntent xEffect xWant xWant xWant xWant xWant xWant oWant xWant oWant oWant oWant oWant oWant oWant xIntent xIntent xIntent xIntent xEffect xWant xWant xWant xWant xWant oWant xWant oWant xWant oWant oWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant xWant xWant oWant xWant oWant xWant xWant oWant oWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant xWant oWant xWant oWant xWant xWant oWant xWant oWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant oWant xWant oWant xWant xWant oWant xWant oWant xWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant xWant oWant xWant xWant oWant xWant oWant xWant oWant xWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant xWant xWant oWant xWant oWant xWant oWant xWant xWant oWant oWant xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant oWant xWant oWant xWant oWant xWant oWant oWant xWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant xWant oWant xWant oWant xWant oWant xWant xWant xWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant xWant oWant xWant oWant xWant oWant oWant oWant xWant xWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant xWant oWant xWant oWant xWant xWant xWant xWant oWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant xWant oWant xWant xWant xWant xWant oWant xWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant xWant oWant oWant oWant oWant xWant oWant xWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant xWant xWant xWant xWant oWant xWant xWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant oWant oWant oWant oWant xWant oWant oWant xWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant xWant xWant xWant oWant xWant xWant xWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant oWant oWant xWant oWant oWant oWant xWant xWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant xWant oWant xWant xWant xWant xWant oWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant oWant xWant xWant xWant xWant oWant xWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant xWant xWant xWant xWant oWant xWant xWant oWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant xWant xWant xWant oWant xWant xWant oWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant oWant oWant xWant oWant oWant xWant oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant xWant oWant xWant xWant oWant xWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant oWant xWant xWant oWant xWant xWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant xWant xWant oWant xWant xWant xWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant xWant oWant xWant xWant xWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant xWant oWant oWant oWant oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant xWant xWant xWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xWant xWant xWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant oWant oWant oWant xWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect xWant oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect oWant xIntent xIntent xIntent xIntent xIntent xIntent xIntent xEffect\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DATA-LOADING"
      ],
      "metadata": {
        "id": "fc2_zzQN-n6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_valid_sampler(trainset, valid=0.1):\n",
        "    size = len(trainset)\n",
        "    idx = list(range(size))\n",
        "    split = int(valid * size)\n",
        "    return SubsetRandomSampler(idx[split:]), SubsetRandomSampler(idx[:split])\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2 ** 32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "def get_loaders(dataset_name, hip, batch_size=8, pretrained_model='bert-base-uncased', valid=0.1, shuffle=True):\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(pretrained_model)\n",
        "    trainset = BaseDataset(dataset_name, hip, 'train', tokenizer)\n",
        "    testset = BaseDataset(dataset_name, hip, 'test', tokenizer)\n",
        "    # Optional printing of dataset_name's test part to understand the data. \\\n",
        "    # The understanding of IEMOCAP is mentioned in a comment above.\n",
        "    # show_data(dataset_name, hip)\n",
        "\n",
        "    if dataset_name == 'IEMOCAP':\n",
        "        train_sampler, valid_sampler = get_train_valid_sampler(trainset, valid)\n",
        "        train_loader = DataLoader(trainset,\n",
        "                                  batch_size=8,\n",
        "                                  sampler=train_sampler,\n",
        "                                  num_workers=0,\n",
        "                                  collate_fn=collate_fn,\n",
        "                                  worker_init_fn=seed_worker)\n",
        "        dev_loader = DataLoader(trainset,\n",
        "                                batch_size=1,\n",
        "                                sampler=valid_sampler,\n",
        "                                num_workers=0,\n",
        "                                collate_fn=collate_fn,\n",
        "                                worker_init_fn=seed_worker)\n",
        "        test_loader = DataLoader(testset,\n",
        "                                 batch_size=1,\n",
        "                                 shuffle=shuffle,\n",
        "                                 num_workers=0,\n",
        "                                 collate_fn=collate_fn,\n",
        "                                 worker_init_fn=seed_worker)\n",
        "    else:\n",
        "        devset = BaseDataset(dataset_name, hip, 'dev', tokenizer)\n",
        "        train_loader = DataLoader(trainset,\n",
        "                                  batch_size=batch_size,\n",
        "                                  shuffle=shuffle,\n",
        "                                  num_workers=0,\n",
        "                                  collate_fn=collate_fn_batch,\n",
        "                                  worker_init_fn=seed_worker)\n",
        "        dev_loader = DataLoader(devset,\n",
        "                                batch_size=batch_size,\n",
        "                                shuffle=shuffle,\n",
        "                                num_workers=0,\n",
        "                                collate_fn=collate_fn_batch,\n",
        "                                worker_init_fn=seed_worker)\n",
        "        test_loader = DataLoader(testset,\n",
        "                                 batch_size=batch_size,\n",
        "                                 shuffle=shuffle,\n",
        "                                 num_workers=0,\n",
        "                                 collate_fn=collate_fn_batch,\n",
        "                                 worker_init_fn=seed_worker)\n",
        "    return train_loader, dev_loader, test_loader"
      ],
      "metadata": {
        "id": "cvqYzey6-jY0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### STARTING WITH TRAINING - WITHOUT SPECTROGRAM"
      ],
      "metadata": {
        "id": "gauiAvBAu6PA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataset_name, model, loss_func, trainloader, devloader, testloader,\n",
        "          n_epochs, optimizer, scheduler, training_step, model_path, log_path,\n",
        "          metric_path, use_gpu, window, mode):\n",
        "\n",
        "    model = model.to('cuda:0')\n",
        "    model.train()\n",
        "\n",
        "    f = open(log_path, 'a+', encoding='utf-8')\n",
        "\n",
        "    train_loss_list = []\n",
        "    train_f1_list = []\n",
        "    dev_f1_list = []\n",
        "    test_f1_list = []\n",
        "\n",
        "    best_fscore = 0\n",
        "    best_mf1 = 0\n",
        "    best_accuracy = 0\n",
        "    best_report = None\n",
        "\n",
        "    best_test_fscore = 0\n",
        "    best_test_mf1 = 0\n",
        "    best_test_accuracy = 0\n",
        "    best_test_report = None\n",
        "\n",
        "    step = 0\n",
        "    early_stopping_step = 0\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        losses = []\n",
        "        preds = []\n",
        "        labels = []\n",
        "        masks = []\n",
        "        num_utt = 0\n",
        "        print('Epoch {} start: '.format(epoch + 1))\n",
        "        if step > training_step:\n",
        "            break\n",
        "        start_time = time.time()\n",
        "        for data in trainloader:\n",
        "            # (clen, slen), (clen)\n",
        "            # Each data that is coming our way - But the entire data is encoded here.\n",
        "            textf, wrdm, label, uttm, spkm, edge_index, edge_attr, _, _, conv = data\n",
        "            if dataset_name == 'IEMOCAP':\n",
        "                if use_gpu:\n",
        "                    textf = textf.cuda()\n",
        "                    wrdm = wrdm.cuda()\n",
        "                    uttm = uttm.cuda()\n",
        "                    spkm = spkm.cuda()\n",
        "                    edge_index = edge_index.cuda()\n",
        "                    edge_attr = edge_attr.cuda()\n",
        "                logits = model(textf, wrdm, uttm, spkm, window, mode, edge_index, edge_attr, residual=False)\n",
        "            else:\n",
        "                conv_len = [int(torch.sum(um).item()) for um in uttm]  # torch.sum(uttm, dim=1).numpy().tolist()\n",
        "                if dataset_name == 'DailyDialog':\n",
        "                    logits = model(textf, wrdm, conv_len, uttm, spkm, window, mode, edge_index, edge_attr, use_gpu, residual=False)\n",
        "                else:\n",
        "                    logits = model(textf, wrdm, conv_len, edge_index, edge_attr, use_gpu)\n",
        "                label = torch.cat(label, dim=0)\n",
        "            if use_gpu:\n",
        "                label = label.cuda()\n",
        "            # loss = loss_func(torch.log_softmax(logits, dim=-1), label)\n",
        "            # print(f\"LOGITS WITHOUT SPECTROGRAM: {logits} | LABELS: {label}\")\n",
        "            loss = loss_func(logits, label)\n",
        "\n",
        "            model.zero_grad()\n",
        "            loss.backward()\n",
        "            clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            pred_ = torch.argmax(torch.softmax(logits, dim=-1), dim=1)\n",
        "            preds.append(pred_.cpu().numpy())\n",
        "            labels.append(label.data.cpu().numpy())\n",
        "            losses.append(loss.item() * label.size(0))\n",
        "            num_utt += label.size(0)\n",
        "            step += 1\n",
        "            if step > training_step:\n",
        "                break\n",
        "\n",
        "        preds = np.concatenate(preds)\n",
        "        labels = np.concatenate(labels)\n",
        "\n",
        "        avg_loss = np.round(np.sum(losses) / num_utt, 4)\n",
        "        avg_accuracy = round(accuracy_score(labels, preds) * 100, 5)\n",
        "        if dataset_name == 'DailyDialog':\n",
        "            avg_fscore = round(f1_score(labels, preds, labels=[0, 2, 3, 4, 5, 6], average='micro') * 100, 5)\n",
        "        else:\n",
        "            avg_fscore = round(f1_score(labels, preds, average='weighted') * 100, 5)\n",
        "        train_mf1 = round(f1_score(labels, preds, average='macro') * 100, 5)\n",
        "        dev_accuracy, dev_fscore, dev_mf, dev_reports = evaluate(dataset_name, model, devloader, use_gpu, window=window, mode=mode)\n",
        "        test_accuracy, test_fscore, test_mf, test_reports = evaluate(dataset_name, model, testloader, use_gpu, window=window, mode=mode)\n",
        "\n",
        "        print(f\"DEV-ACCURACY: {dev_accuracy} || BEST=ACCURACY: {best_accuracy}\")\n",
        "        # Log the Avg. Train Accuracy\n",
        "        wandb.log({'avg_train_accuracy':avg_accuracy})\n",
        "        # Log the Train Macro F1 Score\n",
        "        wandb.log({'train_macro_f1_score':train_mf1})\n",
        "        # Log the Dev Accuracy\n",
        "        wandb.log({'dev_accuracy':dev_accuracy})\n",
        "        # Log the Test Accuracy\n",
        "        wandb.log({'test_accuracy':test_accuracy})\n",
        "\n",
        "        if dev_accuracy > best_accuracy:\n",
        "        # if dev_fscore > best_fscore:\n",
        "            best_fscore = dev_fscore\n",
        "            best_mf1 = dev_mf\n",
        "            best_accuracy = dev_accuracy\n",
        "            best_report = dev_reports\n",
        "\n",
        "            best_test_fscore = test_fscore\n",
        "            best_test_mf1 = test_mf\n",
        "            best_test_accuracy = test_accuracy\n",
        "            best_test_report = test_reports\n",
        "\n",
        "            early_stopping_step = 0\n",
        "            print(\"Best Accuracy Till thie Epoch:\", best_accuracy)\n",
        "            # Saving the model\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "        else:\n",
        "            early_stopping_step += 1\n",
        "\n",
        "        print(f\"CURRENT VALUE OF STOPPING: {early_stopping_step}\")\n",
        "        train_loss_list.append(avg_loss)\n",
        "        # Log the Avg. train loss\n",
        "        wandb.log({'avg_train_loss':avg_loss})\n",
        "        train_f1_list.append(avg_fscore)\n",
        "        # Log the Avg. train f1 score\n",
        "        wandb.log({'avg_train_fscore':avg_fscore})\n",
        "        dev_f1_list.append(dev_fscore)\n",
        "        # Log the Avg. dev f1 score\n",
        "        wandb.log({'avg_dev_fscore':dev_fscore})\n",
        "        test_f1_list.append(test_fscore)\n",
        "        # Log the Avg. test f1 score\n",
        "        wandb.log({'avg_test_fscore':test_fscore})\n",
        "\n",
        "        log = 'Train: Epoch {} Loss {}, ACC {}, F1 {}, mF {}'.format(epoch + 1, avg_loss,\n",
        "                                                                     avg_accuracy, avg_fscore, train_mf1)\n",
        "        print(log)\n",
        "        f.write(log + '\\n')\n",
        "        log = 'Validation: ACC {}, F1 {}, mF {}'.format(dev_accuracy, dev_fscore, dev_mf)\n",
        "        print(log)\n",
        "        f.write(log + '\\n')\n",
        "        log = 'Test: ACC {}, F1 {}, mF {}'.format(test_accuracy, test_fscore, test_mf)\n",
        "        print(log)\n",
        "        f.write(log + '\\n')\n",
        "        print('Epoch {} finished. Elapse {}'.format(epoch + 1, round(time.time() - start_time, 4)))\n",
        "        if early_stopping_step == 50:\n",
        "            break\n",
        "    print('----------------------------------------------')\n",
        "    f.write('----------------------------------------------')\n",
        "    log = '\\n\\n[DEV] best ACC {}, F1 {}, mF {}'.format(best_accuracy, best_fscore, best_mf1)\n",
        "    f.write(log + '\\n')\n",
        "    print(log)\n",
        "    f.write(best_report)\n",
        "    log = '[TEST] best ACC {}, F1 {}, mF {}'.format(best_test_accuracy, best_test_fscore, best_test_mf1)\n",
        "    f.write(log + '\\n')\n",
        "    print(log)\n",
        "    f.write(best_test_report)\n",
        "    f.write('----------------------------------------------\\n')\n",
        "    f.close()\n",
        "    dump_data = [train_loss_list, train_f1_list, dev_f1_list, test_f1_list]\n",
        "    pickle.dump(dump_data, open(metric_path, 'wb'))\n",
        "\n",
        "\n",
        "def evaluate(dataset_name, model, dataloader, use_gpu, window, mode):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in dataloader:\n",
        "            textf, wrdm, label, uttm, spkm, edge_index, edge_attr, _, _, conv  = data\n",
        "            if dataset_name == 'IEMOCAP':\n",
        "                if use_gpu:\n",
        "                    textf = textf.cuda()\n",
        "                    wrdm = wrdm.cuda()\n",
        "                    uttm = uttm.cuda()\n",
        "                    spkm = spkm.cuda()\n",
        "                    edge_index = edge_index.cuda()\n",
        "                    edge_attr = edge_attr.cuda()\n",
        "                logits = model(textf, wrdm, uttm, spkm, window, mode, edge_index, edge_attr, residual=False)\n",
        "            else:\n",
        "                conv_len = [int(torch.sum(um).item()) for um in uttm]  # torch.sum(uttm, dim=1).numpy().tolist()\n",
        "                if dataset_name == 'DailyDialog':\n",
        "                    logits = model(textf, wrdm, conv_len, uttm, spkm, window, mode, edge_index, edge_attr, use_gpu, residual=False)\n",
        "                else:\n",
        "                    logits = model(textf, wrdm, conv_len, edge_index, edge_attr, use_gpu)\n",
        "                # logits = model(textf, wrdm, conv_len, edge_index, edge_attr, use_gpu)\n",
        "                label = torch.cat(label, dim=0)\n",
        "            pred_ = torch.argmax(torch.softmax(logits, dim=1), dim=1)\n",
        "            preds.append(pred_.cpu().numpy())\n",
        "            labels.append(label.data.numpy())\n",
        "    preds = np.concatenate(preds)\n",
        "    labels = np.concatenate(labels)\n",
        "\n",
        "    avg_accuracy = round(accuracy_score(labels, preds) * 100, 5)\n",
        "\n",
        "    if dataset_name == 'DailyDialog':\n",
        "        avg_fscore = round(f1_score(labels, preds, labels=[0, 2, 3, 4, 5, 6], average='micro') * 100, 5)\n",
        "        report_classes = classification_report(labels, preds, labels=[0, 2, 3, 4, 5, 6], digits=4)\n",
        "    else:\n",
        "        avg_fscore = round(f1_score(labels, preds, average='weighted') * 100, 5)\n",
        "        report_classes = classification_report(labels, preds, digits=4)\n",
        "    mf1 = round(f1_score(labels, preds, average='macro') * 100, 5)\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    return avg_accuracy, avg_fscore, mf1, report_classes\n"
      ],
      "metadata": {
        "id": "STk0coHVhDf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beta=True\n",
        "batch_size=20\n",
        "bias=False\n",
        "dataset_name='IEMOCAP'\n",
        "# dataset_name='DailyDialog'\n",
        "encoder_mode='maxpooling'\n",
        "tr_nhead=6\n",
        "tr_ff_dim=300\n",
        "tr_dropout=0.1\n",
        "attn_mask=True\n",
        "tr_num_layer=6\n",
        "max_len=120\n",
        "bidirectional=True\n",
        "num_block = 3\n",
        "cn_nhead=6\n",
        "cn_ff_dim=600\n",
        "cn_dropout=0.1\n",
        "edge_dim=300\n",
        "cn_num_layer=5\n",
        "edge_mapping=True\n",
        "root_weight=True\n",
        "# choice='cn'\n",
        "choice='both'\n",
        "valid=0.1\n",
        "warmup_step=1000\n",
        "schedule='linear'\n",
        "training_step=10000\n",
        "seed=7\n",
        "n_epochs=150\n",
        "lr=1e-5\n",
        "l2=0\n",
        "use_gpu=True\n",
        "window=10\n",
        "mode='uso'\n",
        "\n",
        "if dataset_name == 'IEMOCAP':\n",
        "    num_class = 6\n",
        "else:\n",
        "    num_class = 7\n",
        "\n",
        "model_index = str(29)\n",
        "model_dir = dataset_name + '_C/model'\n",
        "log_dir = dataset_name + '_C/logs/log'\n",
        "metric_dir = dataset_name + '_C/logs/metric'\n",
        "\n",
        "model_path = model_dir + model_index + '.pth'\n",
        "log_path = log_dir + model_index + '.txt'\n",
        "metric_path = metric_dir + model_index + '.pkl'\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "if dataset_name == 'IEMOCAP':\n",
        "  pretrain='roberta-base'\n",
        "  sent_dim=300\n",
        "  hip=7\n",
        "  print(f\"The model getting trained is=> DATASET: {dataset_name}, pretrain: {pretrain}\")\n",
        "  model = MentalModel(encoder_type=pretrain, encoder_mode=encoder_mode, sent_dim=sent_dim, tr_nhead=tr_nhead,\n",
        "                      tr_ff_dim=tr_ff_dim, tr_dropout=tr_dropout, attn_mask=attn_mask, tr_num_layer=tr_num_layer,\n",
        "                      max_len=max_len, num_class=num_class, bidirectional=bidirectional, num_block=num_block,\n",
        "                      cn_nhead=cn_nhead, cn_ff_dim=cn_ff_dim, cn_dropout=cn_dropout, edge_dim=edge_dim, bias=bias,\n",
        "                      cn_num_layer=cn_num_layer, edge_mapping=edge_mapping, beta=beta, root_weight=root_weight, choice=choice)\n",
        "\n",
        "elif dataset_name == 'DailyDialog':\n",
        "  pretrain='roberta-large'\n",
        "  sent_dim=300\n",
        "  hip=2\n",
        "  print(f\"The model getting trained is=> DATASET: {dataset_name}, pretrain: {pretrain}\")\n",
        "  model = BatchMentalModel(pretrain, encoder_mode, sent_dim, tr_nhead,\n",
        "                      tr_ff_dim, tr_dropout, attn_mask, tr_num_layer,\n",
        "                      max_len, num_class, bidirectional, num_block,\n",
        "                      cn_nhead, cn_ff_dim, cn_dropout, edge_dim, bias,\n",
        "                      cn_num_layer, edge_mapping, beta, root_weight, choice)\n",
        "else:\n",
        "  print(f\"The model getting trained is=> DATASET: {dataset_name}, pretrain: {pretrain}\")\n",
        "  model = BatchMentalModelResidual(args.pretrain, args.encoder_mode, args.sent_dim,\n",
        "                                    args.cn_ff_dim, args.cn_nhead, args.cn_dropout,\n",
        "                                    args.edge_dim, num_class, bias, args.cn_num_layer,\n",
        "                                    edge_mapping, beta, root_weight, args.residual_type)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133,
          "referenced_widgets": [
            "72736122fd5b46789d634bd90cc9c0ff",
            "f49f8c3994d242fa927a15190a5412db",
            "e4481527804448f99b61685724093542",
            "ff712eb961364ab79007b05ed4dd6e9a",
            "ff54a3e00487420fa1411b4381136b3d",
            "e962b165f4b34b49b54b3a6d11a0df9c",
            "c4a0b1ce06eb4b9dbd2a881758e3074d",
            "d93dfa59b0344b2e859be3b26945b207",
            "4cb1a1c6f9434372b3e45aec29a0a3f7",
            "45132ae314a4453eb85a998009e03c2e",
            "93ce9f0bbdaf474fbcaafc25f7e31619",
            "85f870e3ff7d4bea87be6bd94546cd35",
            "ae2884dfe8724283ba274a34cd3ef464",
            "26469ad456f74840993d276d49e5a79a",
            "117ee2af0b454c39b2ca359f93b0fbde",
            "0082c4ad324a4a41a3986871802f46d8",
            "91c4ea0785e0446082c2d736b5147395",
            "a25f003fe0fd491f960362fd431661ec",
            "2539cf528af14ee0af8f75cd4e193d21",
            "30b3be9e432d43aba53e799fe91b28df",
            "c66973ba587b419f816b6d9cefe92c67",
            "948d439799fe4ea1a48840ad6c09bec3"
          ]
        },
        "id": "EnIoF_7yAQ50",
        "outputId": "edada8af-7c3e-41dd-f07f-b846540bd662"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model getting trained is=> DATASET: IEMOCAP, pretrain: roberta-base\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "72736122fd5b46789d634bd90cc9c0ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "85f870e3ff7d4bea87be6bd94546cd35"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "train_loader, dev_loader, test_loader = get_loaders(dataset_name, hip, batch_size, pretrain, valid, True)\n",
        "loss_func = nn.CrossEntropyLoss(reduction='mean')\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=l2)\n",
        "\n",
        "if schedule == 'linear':\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, warmup_step, training_step)\n",
        "elif schedule == 'warmup':\n",
        "    scheduler = get_constant_schedule_with_warmup(optimizer, warmup_step)\n",
        "else:\n",
        "    scheduler = get_constant_schedule(optimizer)\n"
      ],
      "metadata": {
        "id": "ZsjYU7urhlR8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "aa32faced41946fca0353911fa433036",
            "3454ac027de04504be85bb8b72d6bdff",
            "1021a36cce3143ebb773a5d145c8bbcf",
            "e7aca08d33bd4379b6e17ab03c3215c6",
            "620b6876608d45ef852c12c59dcf769e",
            "0a3d83fe39c5456992e487bb8fb19294",
            "74afb5ac63c840de93468ec995afc24a",
            "6bb992c6c5e845a782076cd48b4a20f8",
            "8f59c2150a1f4a4b9964cf420f1c98b2",
            "69edf76758e4480f893c59e489c3b8fa",
            "2876c155cc7649338ce0517865629253",
            "9f6e55aa377847c288e4064be14caec3",
            "ee0dac6b00d54cf8bd93ebd8cede9cbf",
            "62b99c624a474c85ab7ec8985c069367",
            "85243ea33055456192eb814e22cb66ac",
            "abc212e9ab22457ba7dae88c39c4199e",
            "1d71dd738298447ab8e1a9b2856be2b8",
            "3df91f2ae2144332abd8716777dceacd",
            "4580bb966ff2458e92a7719127299c6c",
            "124420bb726347228513afc2c673533d",
            "a14fec6c7f5c4475af60091c36e367c0",
            "69d62cfca9204012985efff40cb0eeb9",
            "63cc4522caf9460e82cc1803d96f75d8",
            "52a70ad9f5044a39ad83a745e8f7c88f",
            "9430c6e0410d436194fa835cd06e045e",
            "b110255209d842ca8cfa039ff231b86b",
            "e1306a0556e94825b82375e700859f0d",
            "0b123b95ffc2474b85be0c08b80ac01d",
            "955d1101e18f4dba815a94e4d211edc9",
            "60536469eccf41518bed401f9353d1c1",
            "0c4e6438b8494db39a664deed4382131",
            "e5e6befbc39a4fa8b733c09f6961fac8",
            "b04608ae81134942b5bc9e06d3f8b6fd",
            "208f77a0b4aa4db795c69d08d171c62c",
            "c47526d6d7f046439a36f212327603ea",
            "db2ba81eb56e46ed8bb721cf2386ed73",
            "7fe1a144cb8c4695b346c0818d23f516",
            "7280798edbff40bd959c9b1b7fe6ddbf",
            "70a7b9a6420d470fadc10474a921a802",
            "def59e4a90e24d32ab78238a6292755b",
            "a2c1951a5ccf46319eb9f087feea8e80",
            "1757e46331d049ffa7045bb9e0577c81",
            "1880c414af4148719667ea589b4dfb4c",
            "d76ac4024079401787b42a8df60f1a73"
          ]
        },
        "outputId": "ad5c21d9-0a79-4140-c1c1-9cbe6e0887e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa32faced41946fca0353911fa433036"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f6e55aa377847c288e4064be14caec3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "63cc4522caf9460e82cc1803d96f75d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "208f77a0b4aa4db795c69d08d171c62c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TRAINING WITHOUT SPECTROGRAM"
      ],
      "metadata": {
        "id": "dg7jei-lgdt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# start a new wandb run to track this script\n",
        "wandb.init(\n",
        "    # set the wandb project where this run will be logged\n",
        "    project=\"SKAIG\",\n",
        "    name=\"SKAIG-Without-Emotion-Detection-Using-Sound-With-both-encoding\",\n",
        "    # track hyperparameters and run metadata\n",
        "    config={\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"architecture\": \"ROBERTA And Graph Neural\",\n",
        "    \"dataset\": \"IEMOCAP\",\n",
        "    \"epochs\": 150,\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "GIInNOrnDff9",
        "outputId": "b8dfec97-2bfe-4dee-b53c-c44e65ab0bdc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mraj8lm\u001b[0m (\u001b[33mmh_detection\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/gdrive/MyDrive/MTech_Thesis/SKAIG_ERC/SKAIG-ERC/wandb/run-20240510_151503-t0g01qem</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mh_detection/SKAIG/runs/t0g01qem' target=\"_blank\">SKAIG-Without-Emotion-Detection-Using-Sound-With-both-encoding-batch-size-1</a></strong> to <a href='https://wandb.ai/mh_detection/SKAIG' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mh_detection/SKAIG' target=\"_blank\">https://wandb.ai/mh_detection/SKAIG</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mh_detection/SKAIG/runs/t0g01qem' target=\"_blank\">https://wandb.ai/mh_detection/SKAIG/runs/t0g01qem</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/mh_detection/SKAIG/runs/t0g01qem?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7c25be4e1e40>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IEMOCAP\n",
        "train(dataset_name, model, loss_func, train_loader, dev_loader, test_loader, n_epochs, optimizer, scheduler,\n",
        "            training_step, model_path, log_path, metric_path, use_gpu, window=window, mode=mode)\n",
        "\n",
        "# # DAILY DIALOG\n",
        "# train(dataset_name, model, loss_func, train_loader, dev_loader, test_loader, n_epochs, optimizer, scheduler,\n",
        "#             training_step, model_path, log_path, metric_path, use_gpu, window=window, mode=mode)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PKt_L4NUoIa",
        "outputId": "985c4248-50dd-4da1-cd7a-0bfb93cf2f27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 start: \n",
            "DEV-ACCURACY: 24.58101 || BEST=ACCURACY: 0\n",
            "Best Accuracy Till thie Epoch: 24.58101\n",
            "CURRENT VALUE OF STOPPING: 0\n",
            "Train: Epoch 1 Loss 1.854, ACC 26.39456, F1 11.04756, mF 6.97591\n",
            "Validation: ACC 24.58101, F1 9.70013, mF 6.57698\n",
            "Test: ACC 23.65989, F1 9.05371, mF 6.37768\n",
            "Epoch 1 finished. Elapse 15.5971\n",
            "Epoch 2 start: \n",
            "DEV-ACCURACY: 24.58101 || BEST=ACCURACY: 24.58101\n",
            "CURRENT VALUE OF STOPPING: 1\n",
            "Train: Epoch 2 Loss 1.9437, ACC 25.12019, F1 10.2487, mF 6.85523\n",
            "Validation: ACC 24.58101, F1 9.70013, mF 6.57698\n",
            "Test: ACC 23.65989, F1 9.05371, mF 6.37768\n",
            "Epoch 2 finished. Elapse 13.8798\n",
            "Epoch 3 start: \n",
            "DEV-ACCURACY: 24.58101 || BEST=ACCURACY: 24.58101\n",
            "CURRENT VALUE OF STOPPING: 2\n",
            "Train: Epoch 3 Loss 1.8743, ACC 26.65563, F1 11.79389, mF 7.40941\n",
            "Validation: ACC 24.58101, F1 9.70013, mF 6.57698\n",
            "Test: ACC 23.65989, F1 9.05371, mF 6.37768\n",
            "Epoch 3 finished. Elapse 12.1956\n",
            "Epoch 4 start: \n",
            "DEV-ACCURACY: 24.58101 || BEST=ACCURACY: 24.58101\n",
            "CURRENT VALUE OF STOPPING: 3\n",
            "Train: Epoch 4 Loss 1.8119, ACC 22.54902, F1 8.99508, mF 6.57369\n",
            "Validation: ACC 24.58101, F1 9.70013, mF 6.57698\n",
            "Test: ACC 23.65989, F1 9.05371, mF 6.37768\n",
            "Epoch 4 finished. Elapse 12.6116\n",
            "Epoch 5 start: \n",
            "DEV-ACCURACY: 24.58101 || BEST=ACCURACY: 24.58101\n",
            "CURRENT VALUE OF STOPPING: 4\n",
            "Train: Epoch 5 Loss 1.8956, ACC 24.93298, F1 11.69483, mF 7.86008\n",
            "Validation: ACC 24.58101, F1 9.70013, mF 6.57698\n",
            "Test: ACC 23.65989, F1 9.05371, mF 6.37768\n",
            "Epoch 5 finished. Elapse 13.9565\n",
            "Epoch 6 start: \n",
            "DEV-ACCURACY: 24.58101 || BEST=ACCURACY: 24.58101\n",
            "CURRENT VALUE OF STOPPING: 5\n",
            "Train: Epoch 6 Loss 1.8607, ACC 19.30295, F1 8.85733, mF 7.1541\n",
            "Validation: ACC 24.58101, F1 9.70013, mF 6.57698\n",
            "Test: ACC 23.65989, F1 9.05371, mF 6.37768\n",
            "Epoch 6 finished. Elapse 14.2016\n",
            "Epoch 7 start: \n",
            "DEV-ACCURACY: 24.58101 || BEST=ACCURACY: 24.58101\n",
            "CURRENT VALUE OF STOPPING: 6\n",
            "Train: Epoch 7 Loss 1.7611, ACC 24.40056, F1 15.32949, mF 10.59719\n",
            "Validation: ACC 24.58101, F1 9.70013, mF 6.57698\n",
            "Test: ACC 23.35182, F1 9.03486, mF 6.3644\n",
            "Epoch 7 finished. Elapse 14.5383\n",
            "Epoch 8 start: \n",
            "DEV-ACCURACY: 24.58101 || BEST=ACCURACY: 24.58101\n",
            "CURRENT VALUE OF STOPPING: 7\n",
            "Train: Epoch 8 Loss 1.6732, ACC 30.22901, F1 22.33141, mF 12.97004\n",
            "Validation: ACC 24.58101, F1 15.83692, mF 10.19996\n",
            "Test: ACC 23.7215, F1 14.21995, mF 10.04792\n",
            "Epoch 8 finished. Elapse 13.8098\n",
            "Epoch 9 start: \n",
            "DEV-ACCURACY: 27.74674 || BEST=ACCURACY: 24.58101\n",
            "Best Accuracy Till thie Epoch: 27.74674\n",
            "CURRENT VALUE OF STOPPING: 0\n",
            "Train: Epoch 9 Loss 1.7919, ACC 20.77922, F1 12.36849, mF 9.31504\n",
            "Validation: ACC 27.74674, F1 19.09005, mF 12.12475\n",
            "Test: ACC 25.13863, F1 15.90524, mF 11.24431\n",
            "Epoch 9 finished. Elapse 15.1712\n",
            "Epoch 10 start: \n",
            "DEV-ACCURACY: 24.76723 || BEST=ACCURACY: 27.74674\n",
            "CURRENT VALUE OF STOPPING: 1\n",
            "Train: Epoch 10 Loss 1.9024, ACC 18.37017, F1 10.50246, mF 9.37674\n",
            "Validation: ACC 24.76723, F1 16.20957, mF 10.42692\n",
            "Test: ACC 24.09119, F1 14.60429, mF 10.32041\n",
            "Epoch 10 finished. Elapse 14.1433\n",
            "Epoch 11 start: \n",
            "DEV-ACCURACY: 24.95345 || BEST=ACCURACY: 27.74674\n",
            "CURRENT VALUE OF STOPPING: 2\n",
            "Train: Epoch 11 Loss 1.6196, ACC 32.62987, F1 25.15859, mF 13.00461\n",
            "Validation: ACC 24.95345, F1 14.33083, mF 9.33443\n",
            "Test: ACC 23.7215, F1 12.52297, mF 8.84118\n",
            "Epoch 11 finished. Elapse 13.1791\n",
            "Epoch 12 start: \n",
            "DEV-ACCURACY: 25.32588 || BEST=ACCURACY: 27.74674\n",
            "CURRENT VALUE OF STOPPING: 3\n",
            "Train: Epoch 12 Loss 1.7789, ACC 22.32877, F1 14.46552, mF 9.67065\n",
            "Validation: ACC 25.32588, F1 16.57531, mF 10.65446\n",
            "Test: ACC 24.1528, F1 14.52767, mF 10.26559\n",
            "Epoch 12 finished. Elapse 14.0737\n",
            "Epoch 13 start: \n",
            "DEV-ACCURACY: 26.25698 || BEST=ACCURACY: 27.74674\n",
            "CURRENT VALUE OF STOPPING: 4\n",
            "Train: Epoch 13 Loss 1.7765, ACC 21.64502, F1 13.34199, mF 9.62052\n",
            "Validation: ACC 26.25698, F1 17.71074, mF 11.32299\n",
            "Test: ACC 24.95379, F1 15.54338, mF 10.98646\n",
            "Epoch 13 finished. Elapse 14.1554\n",
            "Epoch 14 start: \n",
            "DEV-ACCURACY: 25.32588 || BEST=ACCURACY: 27.74674\n",
            "CURRENT VALUE OF STOPPING: 5\n",
            "Train: Epoch 14 Loss 1.745, ACC 18.28909, F1 13.21894, mF 8.3604\n",
            "Validation: ACC 25.32588, F1 11.25089, mF 7.50998\n",
            "Test: ACC 23.35182, F1 9.88491, mF 6.96786\n",
            "Epoch 14 finished. Elapse 14.0269\n",
            "Epoch 15 start: \n",
            "DEV-ACCURACY: 24.58101 || BEST=ACCURACY: 27.74674\n",
            "CURRENT VALUE OF STOPPING: 6\n",
            "Train: Epoch 15 Loss 1.7246, ACC 26.96456, F1 17.32523, mF 11.41456\n",
            "Validation: ACC 24.58101, F1 9.70013, mF 6.57698\n",
            "Test: ACC 23.65989, F1 9.05371, mF 6.37768\n",
            "Epoch 15 finished. Elapse 13.6099\n",
            "Epoch 16 start: \n",
            "DEV-ACCURACY: 24.58101 || BEST=ACCURACY: 27.74674\n",
            "CURRENT VALUE OF STOPPING: 7\n",
            "Train: Epoch 16 Loss 1.7069, ACC 24.40633, F1 14.16179, mF 9.29166\n",
            "Validation: ACC 24.58101, F1 9.70013, mF 6.57698\n",
            "Test: ACC 23.53666, F1 9.03356, mF 6.36348\n",
            "Epoch 16 finished. Elapse 14.056\n",
            "Epoch 17 start: \n",
            "DEV-ACCURACY: 26.25698 || BEST=ACCURACY: 27.74674\n",
            "CURRENT VALUE OF STOPPING: 8\n",
            "Train: Epoch 17 Loss 1.7874, ACC 18.2598, F1 12.66629, mF 9.88632\n",
            "Validation: ACC 26.25698, F1 14.80146, mF 9.64626\n",
            "Test: ACC 24.27603, F1 12.17426, mF 8.59227\n",
            "Epoch 17 finished. Elapse 14.3134\n",
            "Epoch 18 start: \n",
            "DEV-ACCURACY: 25.32588 || BEST=ACCURACY: 27.74674\n",
            "CURRENT VALUE OF STOPPING: 9\n",
            "Train: Epoch 18 Loss 1.8885, ACC 16.9279, F1 10.46421, mF 11.93903\n",
            "Validation: ACC 25.32588, F1 12.09969, mF 8.0184\n",
            "Test: ACC 23.59827, F1 10.58382, mF 7.46377\n",
            "Epoch 18 finished. Elapse 13.3893\n",
            "Epoch 19 start: \n",
            "DEV-ACCURACY: 24.58101 || BEST=ACCURACY: 27.74674\n",
            "CURRENT VALUE OF STOPPING: 10\n",
            "Train: Epoch 19 Loss 1.7387, ACC 21.85008, F1 20.18529, mF 17.19373\n",
            "Validation: ACC 24.58101, F1 9.70013, mF 6.57698\n",
            "Test: ACC 23.65989, F1 9.05822, mF 6.38086\n",
            "Epoch 19 finished. Elapse 13.1706\n",
            "Epoch 20 start: \n",
            "DEV-ACCURACY: 24.76723 || BEST=ACCURACY: 27.74674\n",
            "CURRENT VALUE OF STOPPING: 11\n",
            "Train: Epoch 20 Loss 1.7583, ACC 24.42159, F1 21.90825, mF 18.30036\n",
            "Validation: ACC 24.76723, F1 10.1213, mF 6.8316\n",
            "Test: ACC 23.22859, F1 9.33939, mF 6.58077\n",
            "Epoch 20 finished. Elapse 14.4158\n",
            "Epoch 21 start: \n",
            "DEV-ACCURACY: 24.58101 || BEST=ACCURACY: 27.74674\n",
            "CURRENT VALUE OF STOPPING: 12\n",
            "Train: Epoch 21 Loss 1.7931, ACC 20.61856, F1 13.37501, mF 9.96708\n",
            "Validation: ACC 24.58101, F1 9.70013, mF 6.57698\n",
            "Test: ACC 23.53666, F1 9.0426, mF 6.36985\n",
            "Epoch 21 finished. Elapse 13.5005\n",
            "Epoch 22 start: \n",
            "DEV-ACCURACY: 27.00186 || BEST=ACCURACY: 27.74674\n",
            "CURRENT VALUE OF STOPPING: 13\n",
            "Train: Epoch 22 Loss 1.6481, ACC 29.69502, F1 21.06405, mF 12.21141\n",
            "Validation: ACC 27.00186, F1 17.75133, mF 11.38296\n",
            "Test: ACC 27.23352, F1 16.96451, mF 11.99257\n",
            "Epoch 22 finished. Elapse 13.2394\n",
            "Epoch 23 start: \n",
            "DEV-ACCURACY: 24.58101 || BEST=ACCURACY: 27.74674\n",
            "CURRENT VALUE OF STOPPING: 14\n",
            "Train: Epoch 23 Loss 1.6071, ACC 28.57143, F1 22.08398, mF 11.8088\n",
            "Validation: ACC 24.58101, F1 9.70013, mF 6.57698\n",
            "Test: ACC 23.65989, F1 9.05371, mF 6.37768\n",
            "Epoch 23 finished. Elapse 13.7702\n",
            "Epoch 24 start: \n",
            "DEV-ACCURACY: 27.74674 || BEST=ACCURACY: 27.74674\n",
            "CURRENT VALUE OF STOPPING: 15\n",
            "Train: Epoch 24 Loss 1.8284, ACC 16.98113, F1 9.98173, mF 8.12477\n",
            "Validation: ACC 27.74674, F1 19.10806, mF 12.05816\n",
            "Test: ACC 26.98706, F1 17.29131, mF 12.22704\n",
            "Epoch 24 finished. Elapse 13.1678\n",
            "Epoch 25 start: \n",
            "DEV-ACCURACY: 28.49162 || BEST=ACCURACY: 27.74674\n",
            "Best Accuracy Till thie Epoch: 28.49162\n",
            "CURRENT VALUE OF STOPPING: 0\n",
            "Train: Epoch 25 Loss 1.5157, ACC 40.19608, F1 25.9668, mF 11.37065\n",
            "Validation: ACC 28.49162, F1 19.03338, mF 11.92217\n",
            "Test: ACC 27.29513, F1 17.1843, mF 12.15536\n",
            "Epoch 25 finished. Elapse 15.4721\n",
            "Epoch 26 start: \n",
            "DEV-ACCURACY: 28.86406 || BEST=ACCURACY: 28.49162\n",
            "Best Accuracy Till thie Epoch: 28.86406\n",
            "CURRENT VALUE OF STOPPING: 0\n",
            "Train: Epoch 26 Loss 1.6034, ACC 38.39416, F1 23.17646, mF 10.85247\n",
            "Validation: ACC 28.86406, F1 18.52167, mF 11.52951\n",
            "Test: ACC 26.49415, F1 15.68177, mF 11.09796\n",
            "Epoch 26 finished. Elapse 15.8181\n",
            "Epoch 27 start: \n",
            "DEV-ACCURACY: 24.58101 || BEST=ACCURACY: 28.86406\n",
            "CURRENT VALUE OF STOPPING: 1\n",
            "Train: Epoch 27 Loss 1.8042, ACC 18.4555, F1 10.36704, mF 7.56625\n",
            "Validation: ACC 24.58101, F1 10.42831, mF 7.0122\n",
            "Test: ACC 24.33765, F1 10.99398, mF 7.75461\n",
            "Epoch 27 finished. Elapse 14.5355\n",
            "Epoch 28 start: \n",
            "DEV-ACCURACY: 25.88454 || BEST=ACCURACY: 28.86406\n",
            "CURRENT VALUE OF STOPPING: 2\n",
            "Train: Epoch 28 Loss 1.736, ACC 19.94261, F1 14.91775, mF 11.47534\n",
            "Validation: ACC 25.88454, F1 12.18601, mF 9.90741\n",
            "Test: ACC 24.52249, F1 10.73265, mF 8.74118\n",
            "Epoch 28 finished. Elapse 14.0148\n",
            "Epoch 29 start: \n",
            "DEV-ACCURACY: 31.47114 || BEST=ACCURACY: 28.86406\n",
            "Best Accuracy Till thie Epoch: 31.47114\n",
            "CURRENT VALUE OF STOPPING: 0\n",
            "Train: Epoch 29 Loss 1.8306, ACC 20.95915, F1 16.15714, mF 13.2452\n",
            "Validation: ACC 31.47114, F1 21.67928, mF 21.3298\n",
            "Test: ACC 30.68392, F1 22.51431, mF 23.75614\n",
            "Epoch 29 finished. Elapse 14.1424\n",
            "Epoch 30 start: \n",
            "DEV-ACCURACY: 25.13966 || BEST=ACCURACY: 31.47114\n",
            "CURRENT VALUE OF STOPPING: 1\n",
            "Train: Epoch 30 Loss 1.7898, ACC 17.38544, F1 13.28049, mF 13.75639\n",
            "Validation: ACC 25.13966, F1 11.49916, mF 8.70521\n",
            "Test: ACC 27.04868, F1 15.49056, mF 14.32627\n",
            "Epoch 30 finished. Elapse 14.1191\n",
            "Epoch 31 start: \n",
            "DEV-ACCURACY: 28.11918 || BEST=ACCURACY: 31.47114\n",
            "CURRENT VALUE OF STOPPING: 2\n",
            "Train: Epoch 31 Loss 1.6979, ACC 25.36657, F1 21.30282, mF 14.90637\n",
            "Validation: ACC 28.11918, F1 19.6353, mF 13.29911\n",
            "Test: ACC 30.93038, F1 20.98384, mF 16.76257\n",
            "Epoch 31 finished. Elapse 13.7224\n",
            "Epoch 32 start: \n",
            "DEV-ACCURACY: 31.65736 || BEST=ACCURACY: 31.47114\n",
            "Best Accuracy Till thie Epoch: 31.65736\n",
            "CURRENT VALUE OF STOPPING: 0\n",
            "Train: Epoch 32 Loss 1.7017, ACC 28.04314, F1 18.68612, mF 14.30721\n",
            "Validation: ACC 31.65736, F1 20.92152, mF 16.66325\n",
            "Test: ACC 27.54159, F1 16.52704, mF 14.28376\n",
            "Epoch 32 finished. Elapse 15.3947\n",
            "Epoch 33 start: \n",
            "DEV-ACCURACY: 27.74674 || BEST=ACCURACY: 31.65736\n",
            "CURRENT VALUE OF STOPPING: 1\n",
            "Train: Epoch 33 Loss 1.6616, ACC 30.4414, F1 21.82553, mF 15.52002\n",
            "Validation: ACC 27.74674, F1 18.55939, mF 11.81803\n",
            "Test: ACC 29.69809, F1 18.58724, mF 13.13864\n",
            "Epoch 33 finished. Elapse 13.6107\n",
            "Epoch 34 start: \n",
            "DEV-ACCURACY: 26.81564 || BEST=ACCURACY: 31.65736\n",
            "CURRENT VALUE OF STOPPING: 2\n",
            "Train: Epoch 34 Loss 1.747, ACC 25.13661, F1 19.13804, mF 15.6945\n",
            "Validation: ACC 26.81564, F1 15.37901, mF 9.99125\n",
            "Test: ACC 26.7406, F1 15.38455, mF 11.01151\n",
            "Epoch 34 finished. Elapse 13.8128\n",
            "Epoch 35 start: \n",
            "DEV-ACCURACY: 30.1676 || BEST=ACCURACY: 31.65736\n",
            "CURRENT VALUE OF STOPPING: 3\n",
            "Train: Epoch 35 Loss 1.5763, ACC 36.91655, F1 32.72276, mF 22.67772\n",
            "Validation: ACC 30.1676, F1 22.61104, mF 17.61471\n",
            "Test: ACC 30.6223, F1 21.08048, mF 17.54476\n",
            "Epoch 35 finished. Elapse 13.6484\n",
            "Epoch 36 start: \n",
            "DEV-ACCURACY: 28.11918 || BEST=ACCURACY: 31.65736\n",
            "CURRENT VALUE OF STOPPING: 4\n",
            "Train: Epoch 36 Loss 1.5414, ACC 39.00293, F1 28.71097, mF 16.59135\n",
            "Validation: ACC 28.11918, F1 19.50308, mF 12.78577\n",
            "Test: ACC 30.56069, F1 20.28993, mF 15.18098\n",
            "Epoch 36 finished. Elapse 13.4858\n",
            "Epoch 37 start: \n",
            "DEV-ACCURACY: 29.42272 || BEST=ACCURACY: 31.65736\n",
            "CURRENT VALUE OF STOPPING: 5\n",
            "Train: Epoch 37 Loss 1.7683, ACC 26.95783, F1 20.08287, mF 14.16165\n",
            "Validation: ACC 29.42272, F1 22.31051, mF 17.6151\n",
            "Test: ACC 32.7788, F1 23.34205, mF 19.90458\n",
            "Epoch 37 finished. Elapse 13.6621\n",
            "Epoch 38 start: \n",
            "DEV-ACCURACY: 29.79516 || BEST=ACCURACY: 31.65736\n",
            "CURRENT VALUE OF STOPPING: 6\n",
            "Train: Epoch 38 Loss 1.6314, ACC 31.90883, F1 25.35577, mF 20.1104\n",
            "Validation: ACC 29.79516, F1 21.32314, mF 14.28313\n",
            "Test: ACC 33.57979, F1 22.6784, mF 17.06121\n",
            "Epoch 38 finished. Elapse 13.8191\n",
            "Epoch 39 start: \n",
            "DEV-ACCURACY: 27.56052 || BEST=ACCURACY: 31.65736\n",
            "CURRENT VALUE OF STOPPING: 7\n",
            "Train: Epoch 39 Loss 1.709, ACC 28.78338, F1 22.05816, mF 17.51249\n",
            "Validation: ACC 27.56052, F1 19.21051, mF 13.17002\n",
            "Test: ACC 27.78805, F1 17.95006, mF 13.13822\n",
            "Epoch 39 finished. Elapse 13.6891\n",
            "Epoch 40 start: \n",
            "DEV-ACCURACY: 28.86406 || BEST=ACCURACY: 31.65736\n",
            "CURRENT VALUE OF STOPPING: 8\n",
            "Train: Epoch 40 Loss 1.5298, ACC 35.55219, F1 23.47814, mF 13.45943\n",
            "Validation: ACC 28.86406, F1 13.86876, mF 8.34268\n",
            "Test: ACC 24.21442, F1 10.79539, mF 7.65407\n",
            "Epoch 40 finished. Elapse 13.5161\n",
            "Epoch 41 start: \n",
            "DEV-ACCURACY: 34.26443 || BEST=ACCURACY: 31.65736\n",
            "Best Accuracy Till thie Epoch: 34.26443\n",
            "CURRENT VALUE OF STOPPING: 0\n",
            "Train: Epoch 41 Loss 1.619, ACC 30.30303, F1 20.22467, mF 16.30226\n",
            "Validation: ACC 34.26443, F1 26.34158, mF 19.57654\n",
            "Test: ACC 36.29082, F1 25.8736, mF 21.21497\n",
            "Epoch 41 finished. Elapse 15.3142\n",
            "Epoch 42 start: \n",
            "DEV-ACCURACY: 43.20298 || BEST=ACCURACY: 34.26443\n",
            "Best Accuracy Till thie Epoch: 43.20298\n",
            "CURRENT VALUE OF STOPPING: 0\n",
            "Train: Epoch 42 Loss 1.4879, ACC 40.24024, F1 36.60431, mF 26.9537\n",
            "Validation: ACC 43.20298, F1 37.40025, mF 35.16843\n",
            "Test: ACC 41.34319, F1 34.74755, mF 29.90844\n",
            "Epoch 42 finished. Elapse 15.3465\n",
            "Epoch 43 start: \n",
            "DEV-ACCURACY: 46.36872 || BEST=ACCURACY: 43.20298\n",
            "Best Accuracy Till thie Epoch: 46.36872\n",
            "CURRENT VALUE OF STOPPING: 0\n",
            "Train: Epoch 43 Loss 1.6491, ACC 29.61957, F1 22.10741, mF 20.29595\n",
            "Validation: ACC 46.36872, F1 39.37103, mF 41.49438\n",
            "Test: ACC 45.16328, F1 41.4863, mF 40.9895\n",
            "Epoch 43 finished. Elapse 15.8481\n",
            "Epoch 44 start: \n",
            "DEV-ACCURACY: 38.36127 || BEST=ACCURACY: 46.36872\n",
            "CURRENT VALUE OF STOPPING: 1\n",
            "Train: Epoch 44 Loss 1.4669, ACC 43.84, F1 40.43991, mF 38.23803\n",
            "Validation: ACC 38.36127, F1 35.81059, mF 29.71766\n",
            "Test: ACC 42.20579, F1 37.34871, mF 32.88979\n",
            "Epoch 44 finished. Elapse 13.1399\n",
            "Epoch 45 start: \n",
            "DEV-ACCURACY: 49.72067 || BEST=ACCURACY: 46.36872\n",
            "Best Accuracy Till thie Epoch: 49.72067\n",
            "CURRENT VALUE OF STOPPING: 0\n",
            "Train: Epoch 45 Loss 1.2915, ACC 51.38282, F1 50.07605, mF 45.23423\n",
            "Validation: ACC 49.72067, F1 44.81378, mF 43.21042\n",
            "Test: ACC 53.85089, F1 51.10952, mF 46.59124\n",
            "Epoch 45 finished. Elapse 15.2015\n",
            "Epoch 46 start: \n",
            "DEV-ACCURACY: 44.50652 || BEST=ACCURACY: 49.72067\n",
            "CURRENT VALUE OF STOPPING: 1\n",
            "Train: Epoch 46 Loss 1.4688, ACC 47.10884, F1 42.41882, mF 40.12345\n",
            "Validation: ACC 44.50652, F1 44.36977, mF 42.14426\n",
            "Test: ACC 51.32471, F1 51.30843, mF 49.85763\n",
            "Epoch 46 finished. Elapse 13.1124\n",
            "Epoch 47 start: \n",
            "DEV-ACCURACY: 37.61639 || BEST=ACCURACY: 49.72067\n",
            "CURRENT VALUE OF STOPPING: 2\n",
            "Train: Epoch 47 Loss 1.3919, ACC 40.0, F1 36.5409, mF 27.90189\n",
            "Validation: ACC 37.61639, F1 34.38732, mF 34.61842\n",
            "Test: ACC 50.27726, F1 46.86983, mF 45.50934\n",
            "Epoch 47 finished. Elapse 14.2664\n",
            "Epoch 48 start: \n",
            "DEV-ACCURACY: 40.78212 || BEST=ACCURACY: 49.72067\n",
            "CURRENT VALUE OF STOPPING: 3\n",
            "Train: Epoch 48 Loss 1.3426, ACC 42.72237, F1 40.59626, mF 37.34989\n",
            "Validation: ACC 40.78212, F1 36.4383, mF 40.84543\n",
            "Test: ACC 50.58534, F1 50.3564, mF 49.51012\n",
            "Epoch 48 finished. Elapse 14.5101\n",
            "Epoch 49 start: \n",
            "DEV-ACCURACY: 47.29981 || BEST=ACCURACY: 49.72067\n",
            "CURRENT VALUE OF STOPPING: 4\n",
            "Train: Epoch 49 Loss 1.2781, ACC 48.48485, F1 48.52188, mF 43.57667\n",
            "Validation: ACC 47.29981, F1 43.75781, mF 42.81907\n",
            "Test: ACC 56.13062, F1 53.64591, mF 49.16206\n",
            "Epoch 49 finished. Elapse 13.9373\n",
            "Epoch 50 start: \n",
            "DEV-ACCURACY: 40.5959 || BEST=ACCURACY: 49.72067\n",
            "CURRENT VALUE OF STOPPING: 5\n",
            "Train: Epoch 50 Loss 1.3639, ACC 44.24779, F1 38.69649, mF 33.25547\n",
            "Validation: ACC 40.5959, F1 31.72692, mF 32.8616\n",
            "Test: ACC 52.98829, F1 46.80756, mF 44.19803\n",
            "Epoch 50 finished. Elapse 13.8236\n",
            "Epoch 51 start: \n",
            "DEV-ACCURACY: 45.62384 || BEST=ACCURACY: 49.72067\n",
            "CURRENT VALUE OF STOPPING: 6\n",
            "Train: Epoch 51 Loss 1.2374, ACC 44.69821, F1 43.13205, mF 29.92974\n",
            "Validation: ACC 45.62384, F1 42.36123, mF 38.5447\n",
            "Test: ACC 46.51879, F1 41.59795, mF 35.05125\n",
            "Epoch 51 finished. Elapse 13.2686\n",
            "Epoch 52 start: \n",
            "DEV-ACCURACY: 48.97579 || BEST=ACCURACY: 49.72067\n",
            "CURRENT VALUE OF STOPPING: 7\n",
            "Train: Epoch 52 Loss 1.5315, ACC 36.17021, F1 30.53722, mF 31.1367\n",
            "Validation: ACC 48.97579, F1 39.67554, mF 38.02089\n",
            "Test: ACC 49.84596, F1 44.56879, mF 39.74923\n",
            "Epoch 52 finished. Elapse 13.7321\n",
            "Epoch 53 start: \n",
            "DEV-ACCURACY: 48.41713 || BEST=ACCURACY: 49.72067\n",
            "CURRENT VALUE OF STOPPING: 8\n",
            "Train: Epoch 53 Loss 1.303, ACC 46.15385, F1 44.41806, mF 41.21666\n",
            "Validation: ACC 48.41713, F1 41.17048, mF 41.69762\n",
            "Test: ACC 52.06408, F1 48.40396, mF 47.45171\n",
            "Epoch 53 finished. Elapse 13.7756\n",
            "Epoch 54 start: \n",
            "DEV-ACCURACY: 42.08566 || BEST=ACCURACY: 49.72067\n",
            "CURRENT VALUE OF STOPPING: 9\n",
            "Train: Epoch 54 Loss 1.2417, ACC 47.58962, F1 46.11406, mF 44.52833\n",
            "Validation: ACC 42.08566, F1 39.67775, mF 40.0494\n",
            "Test: ACC 56.31547, F1 56.03685, mF 54.46024\n",
            "Epoch 54 finished. Elapse 15.0147\n",
            "Epoch 55 start: \n",
            "DEV-ACCURACY: 42.08566 || BEST=ACCURACY: 49.72067\n",
            "CURRENT VALUE OF STOPPING: 10\n",
            "Train: Epoch 55 Loss 1.0613, ACC 56.45864, F1 55.87998, mF 44.80774\n",
            "Validation: ACC 42.08566, F1 38.25538, mF 37.17343\n",
            "Test: ACC 47.62785, F1 42.80918, mF 40.39004\n",
            "Epoch 55 finished. Elapse 13.3495\n",
            "Epoch 56 start: \n",
            "DEV-ACCURACY: 50.27933 || BEST=ACCURACY: 49.72067\n",
            "Best Accuracy Till thie Epoch: 50.27933\n",
            "CURRENT VALUE OF STOPPING: 0\n",
            "Train: Epoch 56 Loss 1.1176, ACC 51.2605, F1 49.3905, mF 41.27218\n",
            "Validation: ACC 50.27933, F1 48.91116, mF 47.46372\n",
            "Test: ACC 56.31547, F1 56.4035, mF 54.58773\n",
            "Epoch 56 finished. Elapse 15.3383\n",
            "Epoch 57 start: \n",
            "DEV-ACCURACY: 42.27188 || BEST=ACCURACY: 50.27933\n",
            "CURRENT VALUE OF STOPPING: 1\n",
            "Train: Epoch 57 Loss 1.0962, ACC 57.22461, F1 55.82996, mF 53.82158\n",
            "Validation: ACC 42.27188, F1 42.00271, mF 38.81682\n",
            "Test: ACC 53.29636, F1 52.4378, mF 49.25294\n",
            "Epoch 57 finished. Elapse 13.7942\n",
            "Epoch 58 start: \n",
            "DEV-ACCURACY: 47.85847 || BEST=ACCURACY: 50.27933\n",
            "CURRENT VALUE OF STOPPING: 2\n",
            "Train: Epoch 58 Loss 1.0283, ACC 58.25688, F1 55.42366, mF 47.33671\n",
            "Validation: ACC 47.85847, F1 46.92328, mF 43.97982\n",
            "Test: ACC 58.59519, F1 57.43822, mF 54.22761\n",
            "Epoch 58 finished. Elapse 13.7294\n",
            "Epoch 59 start: \n",
            "DEV-ACCURACY: 52.70019 || BEST=ACCURACY: 50.27933\n",
            "Best Accuracy Till thie Epoch: 52.70019\n",
            "CURRENT VALUE OF STOPPING: 0\n",
            "Train: Epoch 59 Loss 1.0712, ACC 57.66193, F1 56.43107, mF 49.43022\n",
            "Validation: ACC 52.70019, F1 52.49426, mF 50.46831\n",
            "Test: ACC 60.32039, F1 59.51279, mF 57.04594\n",
            "Epoch 59 finished. Elapse 15.0415\n",
            "Epoch 60 start: \n",
            "DEV-ACCURACY: 52.32775 || BEST=ACCURACY: 52.70019\n",
            "CURRENT VALUE OF STOPPING: 1\n",
            "Train: Epoch 60 Loss 1.0313, ACC 58.34586, F1 57.14238, mF 53.37758\n",
            "Validation: ACC 52.32775, F1 50.2276, mF 47.81665\n",
            "Test: ACC 62.53851, F1 60.85625, mF 57.99525\n",
            "Epoch 60 finished. Elapse 13.6594\n",
            "Epoch 61 start: \n",
            "DEV-ACCURACY: 59.77654 || BEST=ACCURACY: 52.70019\n",
            "Best Accuracy Till thie Epoch: 59.77654\n",
            "CURRENT VALUE OF STOPPING: 0\n",
            "Train: Epoch 61 Loss 1.0306, ACC 58.71157, F1 57.35752, mF 52.7733\n",
            "Validation: ACC 59.77654, F1 59.80241, mF 56.65163\n",
            "Test: ACC 59.14972, F1 58.95546, mF 56.78772\n",
            "Epoch 61 finished. Elapse 15.4531\n",
            "Epoch 62 start: \n",
            "DEV-ACCURACY: 48.78957 || BEST=ACCURACY: 59.77654\n",
            "CURRENT VALUE OF STOPPING: 1\n",
            "Train: Epoch 62 Loss 1.014, ACC 56.34379, F1 52.16791, mF 50.54347\n",
            "Validation: ACC 48.78957, F1 47.09864, mF 44.58567\n",
            "Test: ACC 57.36291, F1 56.28179, mF 53.52103\n",
            "Epoch 62 finished. Elapse 14.1675\n",
            "Epoch 63 start: \n",
            "DEV-ACCURACY: 58.28678 || BEST=ACCURACY: 59.77654\n",
            "CURRENT VALUE OF STOPPING: 2\n",
            "Train: Epoch 63 Loss 1.0073, ACC 56.8254, F1 53.9148, mF 49.15074\n",
            "Validation: ACC 58.28678, F1 56.78707, mF 52.54075\n",
            "Test: ACC 58.22551, F1 55.992, mF 51.63394\n",
            "Epoch 63 finished. Elapse 13.5635\n",
            "Epoch 64 start: \n",
            "DEV-ACCURACY: 58.10056 || BEST=ACCURACY: 59.77654\n",
            "CURRENT VALUE OF STOPPING: 3\n",
            "Train: Epoch 64 Loss 0.8978, ACC 63.15789, F1 60.35718, mF 54.14531\n",
            "Validation: ACC 58.10056, F1 56.17479, mF 52.86726\n",
            "Test: ACC 65.37277, F1 64.23874, mF 61.5133\n",
            "Epoch 64 finished. Elapse 14.2358\n",
            "Epoch 65 start: \n",
            "DEV-ACCURACY: 46.36872 || BEST=ACCURACY: 59.77654\n",
            "CURRENT VALUE OF STOPPING: 4\n",
            "Train: Epoch 65 Loss 0.9327, ACC 57.79123, F1 54.98719, mF 48.5308\n",
            "Validation: ACC 46.36872, F1 46.11324, mF 45.06325\n",
            "Test: ACC 56.80838, F1 56.26719, mF 54.46152\n",
            "Epoch 65 finished. Elapse 13.498\n",
            "Epoch 66 start: \n",
            "DEV-ACCURACY: 47.11359 || BEST=ACCURACY: 59.77654\n",
            "CURRENT VALUE OF STOPPING: 5\n",
            "Train: Epoch 66 Loss 0.8679, ACC 63.23296, F1 60.29989, mF 59.97713\n",
            "Validation: ACC 47.11359, F1 47.45188, mF 47.87129\n",
            "Test: ACC 54.22058, F1 54.58978, mF 52.80613\n",
            "Epoch 66 finished. Elapse 13.5024\n",
            "Epoch 67 start: \n",
            "DEV-ACCURACY: 48.78957 || BEST=ACCURACY: 59.77654\n",
            "CURRENT VALUE OF STOPPING: 6\n",
            "Train: Epoch 67 Loss 1.0334, ACC 58.95954, F1 58.72452, mF 57.86327\n",
            "Validation: ACC 48.78957, F1 45.71668, mF 45.66985\n",
            "Test: ACC 53.91251, F1 50.70391, mF 50.49737\n",
            "Epoch 67 finished. Elapse 14.001\n",
            "Epoch 68 start: \n",
            "DEV-ACCURACY: 57.16946 || BEST=ACCURACY: 59.77654\n",
            "CURRENT VALUE OF STOPPING: 7\n",
            "Train: Epoch 68 Loss 0.9076, ACC 65.07937, F1 61.84612, mF 54.79541\n",
            "Validation: ACC 57.16946, F1 56.24641, mF 52.38811\n",
            "Test: ACC 57.97905, F1 57.04353, mF 53.09445\n",
            "Epoch 68 finished. Elapse 12.815\n",
            "Epoch 69 start: \n",
            "DEV-ACCURACY: 46.36872 || BEST=ACCURACY: 59.77654\n",
            "CURRENT VALUE OF STOPPING: 8\n",
            "Train: Epoch 69 Loss 0.9744, ACC 61.91248, F1 61.1196, mF 59.06361\n",
            "Validation: ACC 46.36872, F1 44.91199, mF 45.29724\n",
            "Test: ACC 55.51448, F1 53.73657, mF 52.55422\n",
            "Epoch 69 finished. Elapse 13.5705\n",
            "Epoch 70 start: \n",
            "DEV-ACCURACY: 59.96276 || BEST=ACCURACY: 59.77654\n",
            "Best Accuracy Till thie Epoch: 59.96276\n",
            "CURRENT VALUE OF STOPPING: 0\n",
            "Train: Epoch 70 Loss 0.9822, ACC 60.24279, F1 58.38586, mF 53.21532\n",
            "Validation: ACC 59.96276, F1 60.12009, mF 58.57408\n",
            "Test: ACC 54.95995, F1 54.14859, mF 52.4589\n",
            "Epoch 70 finished. Elapse 15.0943\n",
            "Epoch 71 start: \n",
            "DEV-ACCURACY: 54.18994 || BEST=ACCURACY: 59.96276\n",
            "CURRENT VALUE OF STOPPING: 1\n",
            "Train: Epoch 71 Loss 0.8778, ACC 63.85542, F1 63.17446, mF 62.61431\n",
            "Validation: ACC 54.18994, F1 51.17377, mF 49.29226\n",
            "Test: ACC 62.66174, F1 61.13542, mF 58.27548\n",
            "Epoch 71 finished. Elapse 14.1756\n",
            "Epoch 72 start: \n",
            "DEV-ACCURACY: 46.92737 || BEST=ACCURACY: 59.96276\n",
            "CURRENT VALUE OF STOPPING: 2\n",
            "Train: Epoch 72 Loss 0.8482, ACC 66.00719, F1 63.39642, mF 60.16241\n",
            "Validation: ACC 46.92737, F1 43.94163, mF 45.1073\n",
            "Test: ACC 55.88417, F1 52.85656, mF 52.16104\n",
            "Epoch 72 finished. Elapse 12.7645\n",
            "Epoch 73 start: \n",
            "DEV-ACCURACY: 60.14898 || BEST=ACCURACY: 59.96276\n",
            "Best Accuracy Till thie Epoch: 60.14898\n",
            "CURRENT VALUE OF STOPPING: 0\n",
            "Train: Epoch 73 Loss 0.9412, ACC 62.16931, F1 62.79317, mF 61.10269\n",
            "Validation: ACC 60.14898, F1 58.01857, mF 53.74208\n",
            "Test: ACC 61.12138, F1 58.94946, mF 56.4321\n",
            "Epoch 73 finished. Elapse 16.0293\n",
            "Epoch 74 start: \n",
            "DEV-ACCURACY: 44.13408 || BEST=ACCURACY: 60.14898\n",
            "CURRENT VALUE OF STOPPING: 1\n",
            "Train: Epoch 74 Loss 0.8552, ACC 67.95252, F1 67.26344, mF 63.46485\n",
            "Validation: ACC 44.13408, F1 39.15344, mF 37.71178\n",
            "Test: ACC 49.41466, F1 45.65165, mF 44.62062\n",
            "Epoch 74 finished. Elapse 13.8288\n",
            "Epoch 75 start: \n",
            "DEV-ACCURACY: 60.70764 || BEST=ACCURACY: 60.14898\n",
            "Best Accuracy Till thie Epoch: 60.70764\n",
            "CURRENT VALUE OF STOPPING: 0\n",
            "Train: Epoch 75 Loss 0.8109, ACC 70.10582, F1 69.52786, mF 70.26542\n",
            "Validation: ACC 60.70764, F1 61.46035, mF 59.19955\n",
            "Test: ACC 62.41528, F1 62.38325, mF 60.28712\n",
            "Epoch 75 finished. Elapse 15.93\n",
            "Epoch 76 start: \n",
            "DEV-ACCURACY: 43.3892 || BEST=ACCURACY: 60.70764\n",
            "CURRENT VALUE OF STOPPING: 1\n",
            "Train: Epoch 76 Loss 0.8585, ACC 64.83357, F1 64.55468, mF 64.08964\n",
            "Validation: ACC 43.3892, F1 39.82827, mF 39.39953\n",
            "Test: ACC 52.86506, F1 49.9598, mF 48.93216\n",
            "Epoch 76 finished. Elapse 14.2107\n",
            "Epoch 77 start: \n",
            "DEV-ACCURACY: 58.10056 || BEST=ACCURACY: 60.70764\n",
            "CURRENT VALUE OF STOPPING: 2\n",
            "Train: Epoch 77 Loss 0.8945, ACC 61.62988, F1 60.51691, mF 61.2056\n",
            "Validation: ACC 58.10056, F1 58.36157, mF 57.13329\n",
            "Test: ACC 60.44362, F1 60.44197, mF 58.96555\n",
            "Epoch 77 finished. Elapse 13.2153\n",
            "Epoch 78 start: \n",
            "DEV-ACCURACY: 52.88641 || BEST=ACCURACY: 60.70764\n",
            "CURRENT VALUE OF STOPPING: 3\n",
            "Train: Epoch 78 Loss 0.7653, ACC 69.9422, F1 69.85945, mF 69.1061\n",
            "Validation: ACC 52.88641, F1 53.23316, mF 53.15214\n",
            "Test: ACC 59.95071, F1 59.76616, mF 57.76004\n",
            "Epoch 78 finished. Elapse 13.978\n",
            "Epoch 79 start: \n",
            "DEV-ACCURACY: 59.59032 || BEST=ACCURACY: 60.70764\n",
            "CURRENT VALUE OF STOPPING: 4\n",
            "Train: Epoch 79 Loss 0.769, ACC 70.16248, F1 69.5071, mF 65.86252\n",
            "Validation: ACC 59.59032, F1 60.46095, mF 57.70685\n",
            "Test: ACC 65.55761, F1 65.67229, mF 63.39862\n",
            "Epoch 79 finished. Elapse 13.5701\n",
            "Epoch 80 start: \n",
            "DEV-ACCURACY: 56.05214 || BEST=ACCURACY: 60.70764\n",
            "CURRENT VALUE OF STOPPING: 5\n",
            "Train: Epoch 80 Loss 0.7403, ACC 71.64557, F1 71.42387, mF 68.9347\n",
            "Validation: ACC 56.05214, F1 56.69029, mF 55.92589\n",
            "Test: ACC 61.42945, F1 61.16606, mF 59.56482\n",
            "Epoch 80 finished. Elapse 14.8978\n",
            "Epoch 81 start: \n",
            "DEV-ACCURACY: 56.23836 || BEST=ACCURACY: 60.70764\n",
            "CURRENT VALUE OF STOPPING: 6\n",
            "Train: Epoch 81 Loss 0.7472, ACC 68.16074, F1 67.4945, mF 65.4303\n",
            "Validation: ACC 56.23836, F1 55.87331, mF 54.97747\n",
            "Test: ACC 57.05484, F1 56.49853, mF 54.30653\n",
            "Epoch 81 finished. Elapse 13.4472\n",
            "Epoch 82 start: \n",
            "DEV-ACCURACY: 64.61825 || BEST=ACCURACY: 60.70764\n",
            "Best Accuracy Till thie Epoch: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 0\n",
            "Train: Epoch 82 Loss 0.7669, ACC 69.15739, F1 67.96947, mF 63.18213\n",
            "Validation: ACC 64.61825, F1 62.19515, mF 57.80548\n",
            "Test: ACC 65.80407, F1 62.63451, mF 57.68564\n",
            "Epoch 82 finished. Elapse 14.8296\n",
            "Epoch 83 start: \n",
            "DEV-ACCURACY: 57.5419 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 1\n",
            "Train: Epoch 83 Loss 0.7676, ACC 70.46205, F1 69.46494, mF 58.87884\n",
            "Validation: ACC 57.5419, F1 55.46838, mF 50.00019\n",
            "Test: ACC 61.61429, F1 58.93748, mF 54.15477\n",
            "Epoch 83 finished. Elapse 13.1025\n",
            "Epoch 84 start: \n",
            "DEV-ACCURACY: 54.18994 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 2\n",
            "Train: Epoch 84 Loss 0.7229, ACC 75.12521, F1 72.68246, mF 68.82584\n",
            "Validation: ACC 54.18994, F1 53.44065, mF 54.53611\n",
            "Test: ACC 58.90327, F1 58.46373, mF 58.48408\n",
            "Epoch 84 finished. Elapse 13.0648\n",
            "Epoch 85 start: \n",
            "DEV-ACCURACY: 47.85847 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 3\n",
            "Train: Epoch 85 Loss 0.5773, ACC 78.75723, F1 78.73975, mF 76.62041\n",
            "Validation: ACC 47.85847, F1 45.95279, mF 46.29965\n",
            "Test: ACC 55.08318, F1 51.64927, mF 51.9302\n",
            "Epoch 85 finished. Elapse 13.6455\n",
            "Epoch 86 start: \n",
            "DEV-ACCURACY: 57.5419 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 4\n",
            "Train: Epoch 86 Loss 0.6255, ACC 72.53731, F1 72.53174, mF 73.05157\n",
            "Validation: ACC 57.5419, F1 56.80879, mF 52.86062\n",
            "Test: ACC 57.85582, F1 56.56685, mF 53.11924\n",
            "Epoch 86 finished. Elapse 13.972\n",
            "Epoch 87 start: \n",
            "DEV-ACCURACY: 55.49348 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 5\n",
            "Train: Epoch 87 Loss 0.628, ACC 74.0638, F1 71.1453, mF 66.87659\n",
            "Validation: ACC 55.49348, F1 54.85871, mF 54.48936\n",
            "Test: ACC 60.69008, F1 60.04523, mF 58.78521\n",
            "Epoch 87 finished. Elapse 14.344\n",
            "Epoch 88 start: \n",
            "DEV-ACCURACY: 52.88641 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 6\n",
            "Train: Epoch 88 Loss 0.7888, ACC 67.97386, F1 67.85295, mF 68.02938\n",
            "Validation: ACC 52.88641, F1 52.79736, mF 52.78198\n",
            "Test: ACC 59.82748, F1 59.02551, mF 57.85344\n",
            "Epoch 88 finished. Elapse 14.7544\n",
            "Epoch 89 start: \n",
            "DEV-ACCURACY: 54.7486 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 7\n",
            "Train: Epoch 89 Loss 0.6499, ACC 75.87302, F1 75.92009, mF 76.65018\n",
            "Validation: ACC 54.7486, F1 55.17271, mF 54.09247\n",
            "Test: ACC 61.79914, F1 61.42423, mF 60.25829\n",
            "Epoch 89 finished. Elapse 13.4126\n",
            "Epoch 90 start: \n",
            "DEV-ACCURACY: 54.00372 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 8\n",
            "Train: Epoch 90 Loss 0.7382, ACC 71.83673, F1 72.04964, mF 69.97907\n",
            "Validation: ACC 54.00372, F1 52.77467, mF 51.3106\n",
            "Test: ACC 58.47197, F1 55.88915, mF 55.35641\n",
            "Epoch 90 finished. Elapse 14.1283\n",
            "Epoch 91 start: \n",
            "DEV-ACCURACY: 56.98324 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 9\n",
            "Train: Epoch 91 Loss 0.7274, ACC 71.65563, F1 71.73174, mF 71.74357\n",
            "Validation: ACC 56.98324, F1 57.99057, mF 57.15913\n",
            "Test: ACC 62.60012, F1 63.42531, mF 61.59624\n",
            "Epoch 91 finished. Elapse 14.3364\n",
            "Epoch 92 start: \n",
            "DEV-ACCURACY: 59.59032 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 10\n",
            "Train: Epoch 92 Loss 0.721, ACC 73.40426, F1 71.11625, mF 65.09718\n",
            "Validation: ACC 59.59032, F1 59.96229, mF 57.96408\n",
            "Test: ACC 63.09304, F1 62.66204, mF 60.99784\n",
            "Epoch 92 finished. Elapse 13.729\n",
            "Epoch 93 start: \n",
            "DEV-ACCURACY: 60.89385 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 11\n",
            "Train: Epoch 93 Loss 0.6264, ACC 76.89133, F1 76.76089, mF 76.58039\n",
            "Validation: ACC 60.89385, F1 61.23043, mF 59.09881\n",
            "Test: ACC 62.41528, F1 62.20518, mF 60.29693\n",
            "Epoch 93 finished. Elapse 14.2996\n",
            "Epoch 94 start: \n",
            "DEV-ACCURACY: 52.14153 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 12\n",
            "Train: Epoch 94 Loss 0.5236, ACC 78.03807, F1 77.35326, mF 73.64527\n",
            "Validation: ACC 52.14153, F1 52.46786, mF 49.93077\n",
            "Test: ACC 61.36784, F1 60.97965, mF 59.39187\n",
            "Epoch 94 finished. Elapse 13.2455\n",
            "Epoch 95 start: \n",
            "DEV-ACCURACY: 61.82495 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 13\n",
            "Train: Epoch 95 Loss 0.7169, ACC 70.86183, F1 70.61847, mF 69.60222\n",
            "Validation: ACC 61.82495, F1 62.43913, mF 60.67989\n",
            "Test: ACC 63.95564, F1 64.08242, mF 62.96931\n",
            "Epoch 95 finished. Elapse 14.4692\n",
            "Epoch 96 start: \n",
            "DEV-ACCURACY: 48.41713 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 14\n",
            "Train: Epoch 96 Loss 0.6558, ACC 75.66434, F1 75.5614, mF 75.99091\n",
            "Validation: ACC 48.41713, F1 46.60239, mF 47.75178\n",
            "Test: ACC 57.67098, F1 56.86254, mF 56.51922\n",
            "Epoch 96 finished. Elapse 14.2475\n",
            "Epoch 97 start: \n",
            "DEV-ACCURACY: 57.91434 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 15\n",
            "Train: Epoch 97 Loss 0.4895, ACC 83.63339, F1 83.88521, mF 80.92826\n",
            "Validation: ACC 57.91434, F1 56.25344, mF 53.99836\n",
            "Test: ACC 58.90327, F1 57.00798, mF 55.19372\n",
            "Epoch 97 finished. Elapse 13.2228\n",
            "Epoch 98 start: \n",
            "DEV-ACCURACY: 55.49348 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 16\n",
            "Train: Epoch 98 Loss 0.6543, ACC 74.40678, F1 73.91999, mF 70.55097\n",
            "Validation: ACC 55.49348, F1 56.83385, mF 55.88926\n",
            "Test: ACC 61.36784, F1 61.845, mF 60.77858\n",
            "Epoch 98 finished. Elapse 12.9708\n",
            "Epoch 99 start: \n",
            "DEV-ACCURACY: 57.91434 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 17\n",
            "Train: Epoch 99 Loss 0.7776, ACC 70.77326, F1 70.64752, mF 68.97236\n",
            "Validation: ACC 57.91434, F1 57.98005, mF 56.2642\n",
            "Test: ACC 61.92237, F1 61.60388, mF 59.84977\n",
            "Epoch 99 finished. Elapse 14.4466\n",
            "Epoch 100 start: \n",
            "DEV-ACCURACY: 55.6797 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 18\n",
            "Train: Epoch 100 Loss 0.5433, ACC 81.41264, F1 80.70115, mF 68.53345\n",
            "Validation: ACC 55.6797, F1 55.99719, mF 54.62313\n",
            "Test: ACC 61.61429, F1 61.1674, mF 60.32075\n",
            "Epoch 100 finished. Elapse 14.6544\n",
            "Epoch 101 start: \n",
            "DEV-ACCURACY: 56.42458 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 19\n",
            "Train: Epoch 101 Loss 0.5858, ACC 78.35218, F1 78.29833, mF 74.4529\n",
            "Validation: ACC 56.42458, F1 56.91448, mF 55.14446\n",
            "Test: ACC 63.03142, F1 63.16877, mF 61.74624\n",
            "Epoch 101 finished. Elapse 13.3263\n",
            "Epoch 102 start: \n",
            "DEV-ACCURACY: 57.5419 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 20\n",
            "Train: Epoch 102 Loss 0.5673, ACC 80.1406, F1 79.82526, mF 80.2487\n",
            "Validation: ACC 57.5419, F1 57.62617, mF 55.05147\n",
            "Test: ACC 62.35367, F1 62.12211, mF 60.75827\n",
            "Epoch 102 finished. Elapse 13.039\n",
            "Epoch 103 start: \n",
            "DEV-ACCURACY: 56.98324 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 21\n",
            "Train: Epoch 103 Loss 0.6726, ACC 74.35897, F1 74.35116, mF 74.90226\n",
            "Validation: ACC 56.98324, F1 57.0194, mF 56.18621\n",
            "Test: ACC 62.04559, F1 61.55399, mF 60.9229\n",
            "Epoch 103 finished. Elapse 13.9342\n",
            "Epoch 104 start: \n",
            "DEV-ACCURACY: 56.98324 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 22\n",
            "Train: Epoch 104 Loss 0.5378, ACC 79.08847, F1 79.07277, mF 76.54549\n",
            "Validation: ACC 56.98324, F1 56.81689, mF 55.63855\n",
            "Test: ACC 61.67591, F1 61.02043, mF 60.33825\n",
            "Epoch 104 finished. Elapse 14.2709\n",
            "Epoch 105 start: \n",
            "DEV-ACCURACY: 58.28678 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 23\n",
            "Train: Epoch 105 Loss 0.4791, ACC 82.81879, F1 83.0529, mF 79.13387\n",
            "Validation: ACC 58.28678, F1 58.29015, mF 56.25338\n",
            "Test: ACC 64.20209, F1 63.81938, mF 61.6983\n",
            "Epoch 105 finished. Elapse 13.8904\n",
            "Epoch 106 start: \n",
            "DEV-ACCURACY: 57.5419 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 24\n",
            "Train: Epoch 106 Loss 0.5106, ACC 80.7377, F1 80.47597, mF 78.88032\n",
            "Validation: ACC 57.5419, F1 57.74145, mF 57.34726\n",
            "Test: ACC 62.60012, F1 62.7137, mF 61.7593\n",
            "Epoch 106 finished. Elapse 14.4298\n",
            "Epoch 107 start: \n",
            "DEV-ACCURACY: 50.46555 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 25\n",
            "Train: Epoch 107 Loss 0.4943, ACC 81.19534, F1 81.72304, mF 77.51337\n",
            "Validation: ACC 50.46555, F1 49.92658, mF 48.58745\n",
            "Test: ACC 58.71842, F1 56.972, mF 56.82475\n",
            "Epoch 107 finished. Elapse 13.9008\n",
            "Epoch 108 start: \n",
            "DEV-ACCURACY: 56.23836 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 26\n",
            "Train: Epoch 108 Loss 0.5458, ACC 79.53846, F1 79.50364, mF 78.22692\n",
            "Validation: ACC 56.23836, F1 56.59884, mF 54.73261\n",
            "Test: ACC 64.07887, F1 63.80616, mF 62.76295\n",
            "Epoch 108 finished. Elapse 13.5406\n",
            "Epoch 109 start: \n",
            "DEV-ACCURACY: 61.63873 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 27\n",
            "Train: Epoch 109 Loss 0.4292, ACC 85.35286, F1 85.2083, mF 83.54316\n",
            "Validation: ACC 61.63873, F1 61.11482, mF 59.77306\n",
            "Test: ACC 62.60012, F1 61.53899, mF 58.74077\n",
            "Epoch 109 finished. Elapse 14.3222\n",
            "Epoch 110 start: \n",
            "DEV-ACCURACY: 59.77654 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 28\n",
            "Train: Epoch 110 Loss 0.4527, ACC 84.5679, F1 84.3285, mF 81.50769\n",
            "Validation: ACC 59.77654, F1 60.19716, mF 57.91995\n",
            "Test: ACC 63.83241, F1 63.33467, mF 61.74517\n",
            "Epoch 110 finished. Elapse 14.8976\n",
            "Epoch 111 start: \n",
            "DEV-ACCURACY: 56.23836 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 29\n",
            "Train: Epoch 111 Loss 0.5437, ACC 79.28483, F1 79.04777, mF 77.98622\n",
            "Validation: ACC 56.23836, F1 56.5441, mF 55.23766\n",
            "Test: ACC 62.35367, F1 62.28636, mF 61.47904\n",
            "Epoch 111 finished. Elapse 14.7642\n",
            "Epoch 112 start: \n",
            "DEV-ACCURACY: 62.75605 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 30\n",
            "Train: Epoch 112 Loss 0.3609, ACC 86.54822, F1 86.483, mF 85.9343\n",
            "Validation: ACC 62.75605, F1 62.46812, mF 59.67279\n",
            "Test: ACC 63.83241, F1 63.21961, mF 60.85537\n",
            "Epoch 112 finished. Elapse 14.5786\n",
            "Epoch 113 start: \n",
            "DEV-ACCURACY: 55.86592 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 31\n",
            "Train: Epoch 113 Loss 0.507, ACC 81.28272, F1 80.55066, mF 76.99133\n",
            "Validation: ACC 55.86592, F1 56.2696, mF 56.03099\n",
            "Test: ACC 60.75169, F1 60.58322, mF 60.1826\n",
            "Epoch 113 finished. Elapse 14.3925\n",
            "Epoch 114 start: \n",
            "DEV-ACCURACY: 60.3352 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 32\n",
            "Train: Epoch 114 Loss 0.4715, ACC 84.09091, F1 84.21469, mF 83.56339\n",
            "Validation: ACC 60.3352, F1 60.4621, mF 59.77228\n",
            "Test: ACC 63.89402, F1 63.89539, mF 62.87453\n",
            "Epoch 114 finished. Elapse 14.3512\n",
            "Epoch 115 start: \n",
            "DEV-ACCURACY: 60.70764 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 33\n",
            "Train: Epoch 115 Loss 0.3157, ACC 89.55224, F1 89.05879, mF 86.18266\n",
            "Validation: ACC 60.70764, F1 60.73393, mF 59.69195\n",
            "Test: ACC 65.00308, F1 64.56452, mF 63.46708\n",
            "Epoch 115 finished. Elapse 13.7851\n",
            "Epoch 116 start: \n",
            "DEV-ACCURACY: 56.05214 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 34\n",
            "Train: Epoch 116 Loss 0.3318, ACC 88.33333, F1 88.31361, mF 84.68314\n",
            "Validation: ACC 56.05214, F1 56.15268, mF 55.99851\n",
            "Test: ACC 61.42945, F1 61.05645, mF 60.55816\n",
            "Epoch 116 finished. Elapse 14.019\n",
            "Epoch 117 start: \n",
            "DEV-ACCURACY: 59.96276 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 35\n",
            "Train: Epoch 117 Loss 0.4882, ACC 81.3278, F1 80.80921, mF 78.281\n",
            "Validation: ACC 59.96276, F1 59.60776, mF 56.48248\n",
            "Test: ACC 65.12631, F1 64.42102, mF 62.34599\n",
            "Epoch 117 finished. Elapse 14.416\n",
            "Epoch 118 start: \n",
            "DEV-ACCURACY: 62.94227 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 36\n",
            "Train: Epoch 118 Loss 0.381, ACC 85.81363, F1 85.82613, mF 86.43661\n",
            "Validation: ACC 62.94227, F1 62.69243, mF 61.52554\n",
            "Test: ACC 61.30622, F1 60.94602, mF 58.99119\n",
            "Epoch 118 finished. Elapse 14.337\n",
            "Epoch 119 start: \n",
            "DEV-ACCURACY: 57.16946 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 37\n",
            "Train: Epoch 119 Loss 0.4458, ACC 84.51444, F1 84.20114, mF 82.36891\n",
            "Validation: ACC 57.16946, F1 57.62237, mF 55.4097\n",
            "Test: ACC 63.77079, F1 63.53481, mF 61.77065\n",
            "Epoch 119 finished. Elapse 14.1442\n",
            "Epoch 120 start: \n",
            "DEV-ACCURACY: 59.4041 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 38\n",
            "Train: Epoch 120 Loss 0.4204, ACC 84.7512, F1 84.63727, mF 83.90488\n",
            "Validation: ACC 59.4041, F1 59.82765, mF 57.89742\n",
            "Test: ACC 61.67591, F1 61.21227, mF 60.4687\n",
            "Epoch 120 finished. Elapse 13.2475\n",
            "Epoch 121 start: \n",
            "DEV-ACCURACY: 58.473 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 39\n",
            "Train: Epoch 121 Loss 0.4029, ACC 86.43579, F1 86.3436, mF 84.81772\n",
            "Validation: ACC 58.473, F1 58.39609, mF 57.50566\n",
            "Test: ACC 62.53851, F1 62.19565, mF 61.06887\n",
            "Epoch 121 finished. Elapse 13.9498\n",
            "Epoch 122 start: \n",
            "DEV-ACCURACY: 51.95531 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 40\n",
            "Train: Epoch 122 Loss 0.3143, ACC 88.64, F1 88.582, mF 86.25047\n",
            "Validation: ACC 51.95531, F1 52.70104, mF 51.30399\n",
            "Test: ACC 59.08811, F1 58.51994, mF 58.33113\n",
            "Epoch 122 finished. Elapse 13.2645\n",
            "Epoch 123 start: \n",
            "DEV-ACCURACY: 55.86592 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 41\n",
            "Train: Epoch 123 Loss 0.4165, ACC 84.09987, F1 84.26318, mF 75.38285\n",
            "Validation: ACC 55.86592, F1 55.17246, mF 55.15535\n",
            "Test: ACC 60.87492, F1 59.38953, mF 59.129\n",
            "Epoch 123 finished. Elapse 14.4684\n",
            "Epoch 124 start: \n",
            "DEV-ACCURACY: 58.65922 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 42\n",
            "Train: Epoch 124 Loss 0.3343, ACC 86.62704, F1 86.77863, mF 83.58329\n",
            "Validation: ACC 58.65922, F1 58.50412, mF 57.20993\n",
            "Test: ACC 65.37277, F1 64.62714, mF 62.28697\n",
            "Epoch 124 finished. Elapse 14.2319\n",
            "Epoch 125 start: \n",
            "DEV-ACCURACY: 57.91434 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 43\n",
            "Train: Epoch 125 Loss 0.4223, ACC 81.9403, F1 81.25605, mF 76.11767\n",
            "Validation: ACC 57.91434, F1 58.15797, mF 56.57803\n",
            "Test: ACC 61.73752, F1 61.28902, mF 59.99377\n",
            "Epoch 125 finished. Elapse 13.9964\n",
            "Epoch 126 start: \n",
            "DEV-ACCURACY: 62.56983 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 44\n",
            "Train: Epoch 126 Loss 0.4907, ACC 83.01887, F1 82.57146, mF 79.00428\n",
            "Validation: ACC 62.56983, F1 62.67825, mF 61.58299\n",
            "Test: ACC 65.00308, F1 64.14006, mF 62.05603\n",
            "Epoch 126 finished. Elapse 13.9053\n",
            "Epoch 127 start: \n",
            "DEV-ACCURACY: 54.00372 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 45\n",
            "Train: Epoch 127 Loss 0.4094, ACC 86.76278, F1 86.71593, mF 86.04517\n",
            "Validation: ACC 54.00372, F1 53.88826, mF 52.87842\n",
            "Test: ACC 61.86075, F1 61.4943, mF 61.17626\n",
            "Epoch 127 finished. Elapse 14.2821\n",
            "Epoch 128 start: \n",
            "DEV-ACCURACY: 63.12849 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 46\n",
            "Train: Epoch 128 Loss 0.436, ACC 84.86172, F1 85.00133, mF 84.54404\n",
            "Validation: ACC 63.12849, F1 62.78166, mF 61.76875\n",
            "Test: ACC 67.71411, F1 67.14401, mF 64.94906\n",
            "Epoch 128 finished. Elapse 13.9614\n",
            "Epoch 129 start: \n",
            "DEV-ACCURACY: 57.35568 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 47\n",
            "Train: Epoch 129 Loss 0.5403, ACC 81.30699, F1 81.66884, mF 74.97357\n",
            "Validation: ACC 57.35568, F1 57.42785, mF 55.59676\n",
            "Test: ACC 62.72335, F1 62.18969, mF 61.63414\n",
            "Epoch 129 finished. Elapse 13.2338\n",
            "Epoch 130 start: \n",
            "DEV-ACCURACY: 61.82495 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 48\n",
            "Train: Epoch 130 Loss 0.4126, ACC 85.53655, F1 85.58662, mF 85.06394\n",
            "Validation: ACC 61.82495, F1 62.06033, mF 61.19857\n",
            "Test: ACC 65.68084, F1 65.40841, mF 63.75225\n",
            "Epoch 130 finished. Elapse 13.5021\n",
            "Epoch 131 start: \n",
            "DEV-ACCURACY: 57.91434 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 49\n",
            "Train: Epoch 131 Loss 0.2972, ACC 89.86667, F1 89.84165, mF 88.15335\n",
            "Validation: ACC 57.91434, F1 58.21546, mF 56.2097\n",
            "Test: ACC 60.75169, F1 59.37826, mF 59.3661\n",
            "Epoch 131 finished. Elapse 14.4863\n",
            "Epoch 132 start: \n",
            "DEV-ACCURACY: 57.91434 || BEST=ACCURACY: 64.61825\n",
            "CURRENT VALUE OF STOPPING: 50\n",
            "Train: Epoch 132 Loss 0.4354, ACC 83.69231, F1 83.92727, mF 83.62537\n",
            "Validation: ACC 57.91434, F1 57.82524, mF 57.42492\n",
            "Test: ACC 63.95564, F1 63.93026, mF 63.07892\n",
            "Epoch 132 finished. Elapse 13.6644\n",
            "----------------------------------------------\n",
            "\n",
            "\n",
            "[DEV] best ACC 64.61825, F1 62.19515, mF 57.80548\n",
            "[TEST] best ACC 65.80407, F1 62.63451, mF 57.68564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### IEMOCAP RESULTS\n",
        "[DEV] best ACC 27.93296, F1 21.48058, mF 14.45441\n",
        "\n",
        "[TEST] best ACC 25.93962, F1 19.25896, mF 14.36226\n",
        "\n",
        "#### NEW IEMOCAP RESULTS AFTER 78 EPOCHS\n",
        "[DEV] best ACC 61.08007, F1 58.82376, mF 55.18324\n",
        "\n",
        "[TEST] best ACC 59.76587, F1 56.94629, mF 52.72917"
      ],
      "metadata": {
        "id": "rEqEcYA1J5dP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [optional] finish the wandb run, necessary in notebooks\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355,
          "referenced_widgets": [
            "c8c260a4e2fd418f91497ae432f79143",
            "bd06f6317edc454481bc5ab9b6a0fad2",
            "c85929ad613d47e4a6baefe9d41b70d7",
            "0a8296450fe84a83a82c0a173c43e126",
            "b729a68ca66046e5a7417e13eeea459c",
            "1a0a44351c0749b2a1c149afb300264c",
            "62d92d4fe8564980989a04deb88e708c",
            "8234959da35143a4b9326c32f58fc388"
          ]
        },
        "id": "cXw-t-bTDW9a",
        "outputId": "26a438f6-79a4-4d26-b534-9a58c1f6d8fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c8c260a4e2fd418f91497ae432f79143"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_dev_fscore</td><td>▁▁▂▂▂▁▂▂▂▂▂▅▄▅▅▆▆▅▇▇▇█▆▇█▇▇▇█▇▇█▇▆▇██▇▇▇</td></tr><tr><td>avg_test_fscore</td><td>▁▁▂▂▁▁▂▂▂▂▁▅▆▅▆▇▆▆▇▇▇▇▆██▇███▇█▇▇▇██████</td></tr><tr><td>avg_train_accuracy</td><td>▂▁▂▂▂▂▁▁▂▃▂▃▄▃▄▅▅▅▅▆▆▆▇▆▆▆▇▇▇▇▇▇▇▇▇▇████</td></tr><tr><td>avg_train_fscore</td><td>▁▁▁▁▁▁▂▁▂▂▂▂▃▄▅▅▅▅▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇███</td></tr><tr><td>avg_train_loss</td><td>███▇▇▇▆█▇▇▇▇▆▅▅▅▄▄▄▃▄▃▃▃▃▂▃▃▂▂▂▂▂▂▁▂▂▁▁▁</td></tr><tr><td>dev_accuracy</td><td>▁▁▁▁▁▁▂▁▂▂▂▄▅▄▄▅▅▆█▅▇▇▆▇▇▆▇▆▇▆██▆██▇▇███</td></tr><tr><td>test_accuracy</td><td>▁▁▁▁▁▁▂▁▁▂▃▄▆▆▇▆▇▇▇▇▇▇▇█▇▇▇▇█▇█▇▇██▇▇███</td></tr><tr><td>train_macro_f1_score</td><td>▁▁▂▁▁▂▁▂▂▂▂▃▄▃▄▅▅▅▅▆▆▆▆▆▆▇▆▇▇▇██▇▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_dev_fscore</td><td>60.10014</td></tr><tr><td>avg_test_fscore</td><td>65.06258</td></tr><tr><td>avg_train_accuracy</td><td>93.26047</td></tr><tr><td>avg_train_fscore</td><td>93.2472</td></tr><tr><td>avg_train_loss</td><td>0.2301</td></tr><tr><td>dev_accuracy</td><td>60.3352</td></tr><tr><td>test_accuracy</td><td>65.43438</td></tr><tr><td>train_macro_f1_score</td><td>92.29695</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">SKAIG-Without-Emotion-Detection-Using-Sound-With-both-encoding</strong> at: <a href='https://wandb.ai/mh_detection/SKAIG/runs/68lkpb4w' target=\"_blank\">https://wandb.ai/mh_detection/SKAIG/runs/68lkpb4w</a><br/> View project at: <a href='https://wandb.ai/mh_detection/SKAIG' target=\"_blank\">https://wandb.ai/mh_detection/SKAIG</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240425_115746-68lkpb4w/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EMPTY GPU MEMORY CACHE, AS THE MODEL IS ALREADY SAVED AS PER model_index"
      ],
      "metadata": {
        "id": "HBLXAA_M11DV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def memory_stats():\n",
        "    print(torch.cuda.memory_allocated()/1024**2)\n",
        "    print(torch.cuda.memory_cached()/1024**2)\n",
        "\n",
        "\n",
        "def allocate():\n",
        "    x = torch.randn(1024*1024, device='cuda')\n",
        "    memory_stats()\n",
        "\n",
        "memory_stats()\n",
        "torch.cuda.empty_cache()\n",
        "memory_stats()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YngSy-PTBnOg",
        "outputId": "7d2aed5f-5a48-4e60-c783-e1618d0d23b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2207.974609375\n",
            "7200.0\n",
            "2207.974609375\n",
            "2604.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DOING THE TRAINING AGAIN WITH TRANSFER LEARNING USING THE MODEL THAT IS TRAINED ON RAVDESS AND TESS DATASET."
      ],
      "metadata": {
        "id": "ydnErvuXDrJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _supplement_train_data_with_spectrograms(uttm:str, label:int):\n",
        "    spectrogram_image_path_for_utterance = \"\"\n",
        "    DATA_ROOT_PATH='/content/gdrive/MyDrive/emotion_detection_using_sound'\n",
        "    IEMOCAP_ROOT_FLDR = f\"{DATA_ROOT_PATH}/data/Processed_Data_Iemocap\"\n",
        "    IEMOCAP_PROCESSED_FLDR = f\"{IEMOCAP_ROOT_FLDR}/iemocap_spectrograms\"\n",
        "    IEMOCAP_TRANSCRIPT_DOC = f\"{IEMOCAP_ROOT_FLDR}/iemocapTrans.csv\"\n",
        "\n",
        "    IEMOCAP_EMOTION_FOLDER_MAPPING = {\n",
        "        \"exc\":\"excited\",\n",
        "        \"ang\":\"angry\",\n",
        "        \"fru\":\"frustrated\",\n",
        "        \"hap\":\"happy\",\n",
        "        \"neu\":\"neutral\",\n",
        "        \"sad\":\"sad\"\n",
        "        }\n",
        "\n",
        "    # ['angry', 'excited', 'frustrated', 'happy', 'neutral', 'sad']\n",
        "    LABEL_EMOTION_MAPPING = {\n",
        "        0:'hap',\n",
        "        1:'sad',\n",
        "        2:'neu',\n",
        "        3:'ang',\n",
        "        4:'exc',\n",
        "        5:'fru'\n",
        "        }\n",
        "    # print(f\"DIALOG: {uttm} | LABEL: {label}\")\n",
        "    # Generate the path of the SPECTROGRAM image\n",
        "    with open(IEMOCAP_TRANSCRIPT_DOC, newline='') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        # print(f\"UTTM: {uttm}\")\n",
        "        for index, row in enumerate(reader):\n",
        "            # print(f\"CSV INDEX: {index} {row['to_translate']} | DIALOG: {uttm}\")\n",
        "            csv_string = (row['to_translate']).strip()\n",
        "            training_data_string = uttm.strip()\n",
        "            if (row['to_translate']).strip() == uttm.strip() and row['emotion'] == LABEL_EMOTION_MAPPING[label.item()]:\n",
        "                # print(f\"CSV VALUES: {row['to_translate']} | DIALOG: {uttm}\")\n",
        "                utt_emotion = LABEL_EMOTION_MAPPING[label.item()]\n",
        "                spectrogram_image_folder = IEMOCAP_EMOTION_FOLDER_MAPPING[utt_emotion]\n",
        "                spectrogram_image_path_for_utterance = f\"{IEMOCAP_PROCESSED_FLDR}/{spectrogram_image_folder}/{row['title']}.wav.jpeg\"\n",
        "                break\n",
        "    if spectrogram_image_path_for_utterance == \"\" or spectrogram_image_path_for_utterance is None:\n",
        "        print(f\"NOT FOUND UTTERANCE: {uttm} for LABEL: {label.item()} and EMOTION: {LABEL_EMOTION_MAPPING[label.item()]}\")\n",
        "        # sys.exit(0)\n",
        "    return spectrogram_image_path_for_utterance\n",
        "\n",
        "def train_with_spectrogram(dataset_name, model, loss_func, trainloader, devloader, testloader,\n",
        "          n_epochs, optimizer, scheduler, training_step, model_path, log_path,\n",
        "          metric_path, use_gpu, window, mode):\n",
        "\n",
        "    model = model.to('cuda:0')\n",
        "    model.train()\n",
        "\n",
        "    f = open(log_path, 'a+', encoding='utf-8')\n",
        "\n",
        "    train_loss_list = []\n",
        "    train_f1_list = []\n",
        "    dev_f1_list = []\n",
        "    test_f1_list = []\n",
        "\n",
        "    best_fscore = 0\n",
        "    best_mf1 = 0\n",
        "    best_accuracy = 0\n",
        "    best_report = None\n",
        "\n",
        "    best_test_fscore = 0\n",
        "    best_test_mf1 = 0\n",
        "    best_test_accuracy = 0\n",
        "    best_test_report = None\n",
        "\n",
        "    step = 0\n",
        "    early_stopping_step = 0\n",
        "\n",
        "    #### TEST CODE FOR FINDING ALL THE INCONSISTENCIES\n",
        "    # from fastai.vision.all import PILImage\n",
        "\n",
        "    # for epoch in range(n_epochs):\n",
        "    #     for data in trainloader:\n",
        "    #         textf, wrdm, label, uttm, spkm, edge_index, edge_attr, _, _, conv = data\n",
        "    #         spectrogram_image_path = []\n",
        "    #         if dataset_name == 'IEMOCAP':\n",
        "    #             zipped_conv_label = zip(conv, label)\n",
        "    #             for each_conv, conv_label in zipped_conv_label:\n",
        "    #                 spectrogram_image_path.append(_supplement_train_data_with_spectrograms(each_conv,conv_label))\n",
        "    #         for each_image_path in spectrogram_image_path:\n",
        "    #             try:\n",
        "    #                 image = PILImage.create(each_image_path)\n",
        "    #             except Exception as e:\n",
        "    #                 print(f\"IMAGE PATH {each_image_path} not found\")\n",
        "    #     for data in devloader:\n",
        "    #         textf, wrdm, label, uttm, spkm, edge_index, edge_attr, _, _, conv = data\n",
        "    #         spectrogram_image_path = []\n",
        "    #         if dataset_name == 'IEMOCAP':\n",
        "    #             zipped_conv_label = zip(conv, label)\n",
        "    #             for each_conv, conv_label in zipped_conv_label:\n",
        "    #                 spectrogram_image_path.append(_supplement_train_data_with_spectrograms(each_conv,conv_label))\n",
        "    #         for each_image_path in spectrogram_image_path:\n",
        "    #             try:\n",
        "    #                 image = PILImage.create(each_image_path)\n",
        "    #             except Exception as e:\n",
        "    #                 print(f\"IMAGE PATH {each_image_path} not found\")\n",
        "    #     for data in testloader:\n",
        "    #         textf, wrdm, label, uttm, spkm, edge_index, edge_attr, _, _, conv = data\n",
        "    #         spectrogram_image_path = []\n",
        "    #         if dataset_name == 'IEMOCAP':\n",
        "    #             zipped_conv_label = zip(conv, label)\n",
        "    #             for each_conv, conv_label in zipped_conv_label:\n",
        "    #                 spectrogram_image_path.append(_supplement_train_data_with_spectrograms(each_conv,conv_label))\n",
        "    #         for each_image_path in spectrogram_image_path:\n",
        "    #             try:\n",
        "    #                 image = PILImage.create(each_image_path)\n",
        "    #             except Exception as e:\n",
        "    #                 print(f\"IMAGE PATH {each_image_path} not found\")\n",
        "\n",
        "    # sys.exit(0)\n",
        "    ####\n",
        "    for epoch in range(n_epochs):\n",
        "        losses = []\n",
        "        preds = []\n",
        "        labels = []\n",
        "        masks = []\n",
        "        num_utt = 0\n",
        "        print('Epoch : {}'.format(epoch + 1))\n",
        "        if step > training_step:\n",
        "            break\n",
        "        start_time = time.time()\n",
        "        for data in trainloader:\n",
        "            # (clen, slen), (clen)\n",
        "            # Each data that is coming our way - But the entire data is encoded here.\n",
        "            textf, wrdm, label, uttm, spkm, edge_index, edge_attr, _, _, conv = data\n",
        "            # print(f\"CONVERSATION: {conv} | LABEL: {label}\")\n",
        "            spectrogram_image_path = []\n",
        "            if dataset_name == 'IEMOCAP':\n",
        "                zipped_conv_label = zip(conv, label)\n",
        "                for each_conv, conv_label in zipped_conv_label:\n",
        "                    spectrogram_image_path.append(_supplement_train_data_with_spectrograms(each_conv,conv_label))\n",
        "                if use_gpu:\n",
        "                    textf = textf.cuda()\n",
        "                    wrdm = wrdm.cuda()\n",
        "                    uttm = uttm.cuda()\n",
        "                    spkm = spkm.cuda()\n",
        "                    edge_index = edge_index.cuda()\n",
        "                    edge_attr = edge_attr.cuda()\n",
        "                logits = model(textf, wrdm, uttm, spkm, window, mode, edge_index, edge_attr, spectrogram_image_path, residual=False)\n",
        "            else:\n",
        "                conv_len = [int(torch.sum(um).item()) for um in uttm]  # torch.sum(uttm, dim=1).numpy().tolist()\n",
        "                if dataset_name == 'DailyDialog':\n",
        "                    logits = model(textf, wrdm, conv_len, uttm, spkm, window, mode, edge_index, edge_attr, use_gpu, residual=False)\n",
        "                else:\n",
        "                    logits = model(textf, wrdm, conv_len, edge_index, edge_attr, use_gpu)\n",
        "                label = torch.cat(label, dim=0)\n",
        "            if use_gpu:\n",
        "                label = label.cuda()\n",
        "            # loss = loss_func(torch.log_softmax(logits, dim=-1), label)\n",
        "            loss = loss_func(logits, label)\n",
        "\n",
        "            model.zero_grad()\n",
        "            loss.backward()\n",
        "            clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            pred_ = torch.argmax(torch.softmax(logits, dim=-1), dim=1)\n",
        "            preds.append(pred_.cpu().numpy())\n",
        "            labels.append(label.data.cpu().numpy())\n",
        "            losses.append(loss.item() * label.size(0))\n",
        "            num_utt += label.size(0)\n",
        "            step += 1\n",
        "            if step > training_step:\n",
        "                break\n",
        "        preds = np.concatenate(preds)\n",
        "        labels = np.concatenate(labels)\n",
        "\n",
        "        avg_loss = np.round(np.sum(losses) / num_utt, 4)\n",
        "        avg_accuracy = round(accuracy_score(labels, preds) * 100, 5)\n",
        "        if dataset_name == 'DailyDialog':\n",
        "            avg_fscore = round(f1_score(labels, preds, labels=[0, 2, 3, 4, 5, 6], average='micro') * 100, 5)\n",
        "        else:\n",
        "            avg_fscore = round(f1_score(labels, preds, average='weighted') * 100, 5)\n",
        "        train_mf1 = round(f1_score(labels, preds, average='macro') * 100, 5)\n",
        "        dev_accuracy, dev_fscore, dev_mf, dev_reports = evaluate_with_spectrogram(dataset_name, model, devloader, use_gpu, window=window, mode=mode)\n",
        "        test_accuracy, test_fscore, test_mf, test_reports = evaluate_with_spectrogram(dataset_name, model, testloader, use_gpu, window=window, mode=mode)\n",
        "\n",
        "        print(f\"DEV-ACCURACY: {dev_accuracy} || BEST=ACCURACY: {best_accuracy}\")\n",
        "        # Log the Avg. Train Accuracy\n",
        "        wandb.log({'avg_train_accuracy':avg_accuracy})\n",
        "        # Log the Train Macro F1 Score\n",
        "        wandb.log({'train_macro_f1_score':train_mf1})\n",
        "        # Log the Dev Accuracy\n",
        "        wandb.log({'dev_accuracy':dev_accuracy})\n",
        "        # Log the Test Accuracy\n",
        "        wandb.log({'test_accuracy':test_accuracy})\n",
        "\n",
        "        if dev_accuracy > best_accuracy:\n",
        "        # if dev_fscore > best_fscore:\n",
        "            best_fscore = dev_fscore\n",
        "            best_mf1 = dev_mf\n",
        "            best_accuracy = dev_accuracy\n",
        "            best_report = dev_reports\n",
        "\n",
        "            best_test_fscore = test_fscore\n",
        "            best_test_mf1 = test_mf\n",
        "            best_test_accuracy = test_accuracy\n",
        "            best_test_report = test_reports\n",
        "\n",
        "            early_stopping_step = 0\n",
        "            print(\"Best Accuracy Till thie Epoch:\", best_accuracy)\n",
        "            # Saving the model\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "        else:\n",
        "            early_stopping_step += 1\n",
        "\n",
        "        print(f\"CURRENT VALUE OF STOPPING: {early_stopping_step}\")\n",
        "        train_loss_list.append(avg_loss)\n",
        "        # Log the Avg. train loss\n",
        "        wandb.log({'avg_train_loss':avg_loss})\n",
        "        train_f1_list.append(avg_fscore)\n",
        "        # Log the Avg. train f1 score\n",
        "        wandb.log({'avg_train_fscore':avg_fscore})\n",
        "        dev_f1_list.append(dev_fscore)\n",
        "        # Log the Avg. dev f1 score\n",
        "        wandb.log({'avg_dev_fscore':dev_fscore})\n",
        "        test_f1_list.append(test_fscore)\n",
        "        # Log the Avg. test f1 score\n",
        "        wandb.log({'avg_test_fscore':test_fscore})\n",
        "\n",
        "        log = 'Train: Epoch {} Loss {}, ACC {}, F1 {}, mF {}'.format(epoch + 1, avg_loss,\n",
        "                                                                     avg_accuracy, avg_fscore, train_mf1)\n",
        "        print(log)\n",
        "        f.write(log + '\\n')\n",
        "        log = 'Validation: ACC {}, F1 {}, mF {}'.format(dev_accuracy, dev_fscore, dev_mf)\n",
        "        print(log)\n",
        "        f.write(log + '\\n')\n",
        "        log = 'Test: ACC {}, F1 {}, mF {}'.format(test_accuracy, test_fscore, test_mf)\n",
        "        print(log)\n",
        "        f.write(log + '\\n')\n",
        "        print('Epoch {} finished. Elapse {}'.format(epoch + 1, round(time.time() - start_time, 4)))\n",
        "        if early_stopping_step == 50:\n",
        "            break\n",
        "    print('----------------------------------------------')\n",
        "    f.write('----------------------------------------------')\n",
        "    log = '\\n\\n[DEV] best ACC {}, F1 {}, mF {}'.format(best_accuracy, best_fscore, best_mf1)\n",
        "    f.write(log + '\\n')\n",
        "    print(log)\n",
        "    f.write(best_report)\n",
        "    log = '[TEST] best ACC {}, F1 {}, mF {}'.format(best_test_accuracy, best_test_fscore, best_test_mf1)\n",
        "    f.write(log + '\\n')\n",
        "    print(log)\n",
        "    f.write(best_test_report)\n",
        "    f.write('----------------------------------------------\\n')\n",
        "    f.close()\n",
        "    dump_data = [train_loss_list, train_f1_list, dev_f1_list, test_f1_list]\n",
        "    pickle.dump(dump_data, open(metric_path, 'wb'))\n",
        "\n",
        "\n",
        "def evaluate_with_spectrogram(dataset_name, model, dataloader, use_gpu, window, mode):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "        for data in dataloader:\n",
        "            textf, wrdm, label, uttm, spkm, edge_index, edge_attr, _, _, conv  = data\n",
        "            # if dataset_name == 'IEMOCAP':\n",
        "            spectrogram_image_path = []\n",
        "            if dataset_name == 'IEMOCAP':\n",
        "                if spectrogram_mode:\n",
        "                    zipped_conv_label = zip(conv, label)\n",
        "                    for each_conv, each_label in zipped_conv_label:\n",
        "                        spectrogram_image_path.append(_supplement_train_data_with_spectrograms(each_conv,each_label))\n",
        "\n",
        "                if use_gpu:\n",
        "                    textf = textf.cuda()\n",
        "                    wrdm = wrdm.cuda()\n",
        "                    uttm = uttm.cuda()\n",
        "                    spkm = spkm.cuda()\n",
        "                    edge_index = edge_index.cuda()\n",
        "                    edge_attr = edge_attr.cuda()\n",
        "                logits = model(textf, wrdm, uttm, spkm, window, mode, edge_index, edge_attr, spectrogram_image_path, residual=False)\n",
        "            else:\n",
        "                conv_len = [int(torch.sum(um).item()) for um in uttm]  # torch.sum(uttm, dim=1).numpy().tolist()\n",
        "                if dataset_name == 'DailyDialog':\n",
        "                    logits = model(textf, wrdm, conv_len, uttm, spkm, window, mode, edge_index, edge_attr, use_gpu, residual=False)\n",
        "                else:\n",
        "                    logits = model(textf, wrdm, conv_len, edge_index, edge_attr, use_gpu)\n",
        "                # logits = model(textf, wrdm, conv_len, edge_index, edge_attr, use_gpu)\n",
        "                label = torch.cat(label, dim=0)\n",
        "            if use_gpu:\n",
        "                label = label.cuda()\n",
        "            pred_ = torch.argmax(torch.softmax(logits, dim=1), dim=1)\n",
        "            preds.append(pred_.cpu().numpy())\n",
        "            # labels.append(label.data.numpy())\n",
        "            labels.append(label.data.cpu().numpy())\n",
        "\n",
        "\n",
        "    preds = np.concatenate(preds)\n",
        "    labels = np.concatenate(labels)\n",
        "\n",
        "    avg_accuracy = round(accuracy_score(labels, preds) * 100, 5)\n",
        "\n",
        "    if dataset_name == 'DailyDialog':\n",
        "        avg_fscore = round(f1_score(labels, preds, labels=[0, 2, 3, 4, 5, 6], average='micro') * 100, 5)\n",
        "        report_classes = classification_report(labels, preds, labels=[0, 2, 3, 4, 5, 6], digits=4)\n",
        "    else:\n",
        "        avg_fscore = round(f1_score(labels, preds, average='weighted') * 100, 5)\n",
        "        report_classes = classification_report(labels, preds, digits=4)\n",
        "    mf1 = round(f1_score(labels, preds, average='macro') * 100, 5)\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    return avg_accuracy, avg_fscore, mf1, report_classes\n"
      ],
      "metadata": {
        "id": "nuPfHfhepBiB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beta=True\n",
        "batch_size=20\n",
        "bias=False\n",
        "dataset_name='IEMOCAP'\n",
        "# dataset_name='DailyDialog'\n",
        "encoder_mode='maxpooling'\n",
        "tr_nhead=6\n",
        "tr_ff_dim=300\n",
        "tr_dropout=0.1\n",
        "attn_mask=True\n",
        "tr_num_layer=6\n",
        "max_len=120\n",
        "bidirectional=True\n",
        "num_block = 3\n",
        "cn_nhead=6\n",
        "# Dimension for feed forward network for Graph Transformer\n",
        "cn_ff_dim=600\n",
        "cn_dropout=0.1\n",
        "edge_dim=300\n",
        "cn_num_layer=5\n",
        "edge_mapping=True\n",
        "root_weight=True\n",
        "# choice='cn'\n",
        "choice='both'\n",
        "valid=0.1\n",
        "warmup_step=1000\n",
        "schedule='linear'\n",
        "training_step=10000\n",
        "seed=7\n",
        "n_epochs=150\n",
        "lr=1e-5\n",
        "# Weight Decay - l2 normalization\n",
        "# l2=0\n",
        "l2=0.05\n",
        "use_gpu=True\n",
        "window=10\n",
        "mode='uso'\n",
        "# Flag for training with spectrogram images\n",
        "spectrogram_mode=True\n",
        "\n",
        "if dataset_name == 'IEMOCAP':\n",
        "    num_class = 6\n",
        "else:\n",
        "    num_class = 7\n",
        "\n",
        "model_index = str(30)\n",
        "model_dir = dataset_name + '_C/model'\n",
        "log_dir = dataset_name + '_C/logs/log'\n",
        "metric_dir = dataset_name + '_C/logs/metric'\n",
        "\n",
        "model_path = model_dir + model_index + '.pth'\n",
        "log_path = log_dir + model_index + '.txt'\n",
        "metric_path = metric_dir + model_index + '.pkl'\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "if dataset_name == 'IEMOCAP':\n",
        "  pretrain='roberta-base'\n",
        "  # Dimension for utterance encoder\n",
        "  sent_dim=300\n",
        "  hip=10\n",
        "  print(f\"The model getting trained is=> DATASET: {dataset_name}, pretrain: {pretrain}\")\n",
        "  # Using different Mental Model detection class: MentalModelWithSpectrogram\n",
        "  model_with_spectrogram = MentalModelWithSpectrogram(encoder_type=pretrain, encoder_mode=encoder_mode, sent_dim=sent_dim, tr_nhead=tr_nhead,\n",
        "                      tr_ff_dim=tr_ff_dim, tr_dropout=tr_dropout, attn_mask=attn_mask, tr_num_layer=tr_num_layer,\n",
        "                      max_len=max_len, num_class=num_class, bidirectional=bidirectional, num_block=num_block,\n",
        "                      cn_nhead=cn_nhead, cn_ff_dim=cn_ff_dim, cn_dropout=cn_dropout, edge_dim=edge_dim, bias=bias,\n",
        "                      cn_num_layer=cn_num_layer, edge_mapping=edge_mapping, beta=beta, root_weight=root_weight, choice=choice)\n",
        "\n",
        "elif dataset_name == 'DailyDialog':\n",
        "  pretrain='roberta-large'\n",
        "  sent_dim=300\n",
        "  hip=2\n",
        "  print(f\"The model getting trained is=> DATASET: {dataset_name}, pretrain: {pretrain}\")\n",
        "  model = BatchMentalModel(pretrain, encoder_mode, sent_dim, tr_nhead,\n",
        "                      tr_ff_dim, tr_dropout, attn_mask, tr_num_layer,\n",
        "                      max_len, num_class, bidirectional, num_block,\n",
        "                      cn_nhead, cn_ff_dim, cn_dropout, edge_dim, bias,\n",
        "                      cn_num_layer, edge_mapping, beta, root_weight, choice)\n",
        "else:\n",
        "  print(f\"The model getting trained is=> DATASET: {dataset_name}, pretrain: {pretrain}\")\n",
        "  model = BatchMentalModelResidual(args.pretrain, args.encoder_mode, args.sent_dim,\n",
        "                                    args.cn_ff_dim, args.cn_nhead, args.cn_dropout,\n",
        "                                    args.edge_dim, num_class, bias, args.cn_num_layer,\n",
        "                                    edge_mapping, beta, root_weight, args.residual_type)"
      ],
      "metadata": {
        "id": "z6MY7dKjDWZp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "694ac23c-52e5-4452-88b5-de5059679b86"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model getting trained is=> DATASET: IEMOCAP, pretrain: roberta-base\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "train_loader, dev_loader, test_loader = get_loaders(dataset_name, hip, batch_size, pretrain, valid, True)\n",
        "loss_func = nn.CrossEntropyLoss(reduction='mean')\n",
        "optimizer = optim.Adam(model_with_spectrogram.parameters(), lr=lr, weight_decay=l2)\n",
        "\n",
        "if schedule == 'linear':\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, warmup_step, training_step)\n",
        "elif schedule == 'warmup':\n",
        "    scheduler = get_constant_schedule_with_warmup(optimizer, warmup_step)\n",
        "else:\n",
        "    scheduler = get_constant_schedule(optimizer)"
      ],
      "metadata": {
        "id": "v2hL_x00RGcB"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### RETRAINING WITH SPECTROGRAM"
      ],
      "metadata": {
        "id": "ArSNHk4iCtJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# start a new wandb run to track this script\n",
        "wandb.init(\n",
        "    # set the wandb project where this run will be logged\n",
        "    project=\"SKAIG\",\n",
        "    name=\"SKAIG-With-Spectrogram-With-Batch-Size-20-FastAI-batch-size-20-l2-0.5\",\n",
        "    # track hyperparameters and run metadata\n",
        "    config={\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"architecture\": \"ROBERTA And Graph Neural\",\n",
        "    \"dataset\": \"IEMOCAP\",\n",
        "    \"epochs\": 150,\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "kqUVHRXoCsud",
        "outputId": "cbbbd2fe-1f98-4c16-fdc8-3500a525fa1f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/gdrive/MyDrive/MTech_Thesis/SKAIG_ERC/SKAIG-ERC/wandb/run-20240510_233528-z859qb41</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mh_detection/SKAIG/runs/z859qb41' target=\"_blank\">SKAIG-With-Spectrogram-With-Batch-Size-20-FastAI-batch-size-20-l2-0.5</a></strong> to <a href='https://wandb.ai/mh_detection/SKAIG' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mh_detection/SKAIG' target=\"_blank\">https://wandb.ai/mh_detection/SKAIG</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mh_detection/SKAIG/runs/z859qb41' target=\"_blank\">https://wandb.ai/mh_detection/SKAIG/runs/z859qb41</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/mh_detection/SKAIG/runs/z859qb41?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7bc6cd6158d0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IEMOCAP\n",
        "train_with_spectrogram(dataset_name, model_with_spectrogram, loss_func, train_loader, dev_loader, test_loader, n_epochs, optimizer, scheduler,\n",
        "            training_step, model_path, log_path, metric_path, use_gpu, window=window, mode=mode)"
      ],
      "metadata": {
        "id": "Qgk91YuVRbDW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f03ea92-521b-42ea-bdb6-e1bc8476ea32"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1\n",
            "DEV-ACCURACY: 27.93296 || BEST=ACCURACY: 0\n",
            "Best Accuracy Till thie Epoch: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 0\n",
            "Train: Epoch 1 Loss 6.2842, ACC 20.0, F1 21.07561, mF 16.47523\n",
            "Validation: ACC 27.93296, F1 18.33238, mF 12.29035\n",
            "Test: ACC 24.95379, F1 16.48024, mF 13.26261\n",
            "Epoch 1 finished. Elapse 162.6464\n",
            "Epoch : 2\n",
            "DEV-ACCURACY: 21.78771 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 1\n",
            "Train: Epoch 2 Loss 6.2628, ACC 19.47115, F1 19.54828, mF 16.69504\n",
            "Validation: ACC 21.78771, F1 18.93124, mF 14.79965\n",
            "Test: ACC 21.38016, F1 18.40257, mF 16.08974\n",
            "Epoch 2 finished. Elapse 176.7882\n",
            "Epoch : 3\n",
            "DEV-ACCURACY: 19.36685 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 2\n",
            "Train: Epoch 3 Loss 6.0949, ACC 19.2053, F1 19.74275, mF 16.69121\n",
            "Validation: ACC 19.36685, F1 18.43713, mF 15.69266\n",
            "Test: ACC 19.71657, F1 18.32209, mF 16.66041\n",
            "Epoch 3 finished. Elapse 156.8611\n",
            "Epoch : 4\n",
            "DEV-ACCURACY: 18.62197 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 3\n",
            "Train: Epoch 4 Loss 6.4262, ACC 17.32026, F1 17.70505, mF 14.67949\n",
            "Validation: ACC 18.62197, F1 18.17536, mF 15.50786\n",
            "Test: ACC 18.17622, F1 17.17, mF 15.80832\n",
            "Epoch 4 finished. Elapse 153.8329\n",
            "Epoch : 5\n",
            "DEV-ACCURACY: 17.31844 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 4\n",
            "Train: Epoch 5 Loss 6.2696, ACC 18.76676, F1 18.499, mF 16.82887\n",
            "Validation: ACC 17.31844, F1 17.14222, mF 14.55975\n",
            "Test: ACC 17.6833, F1 16.77241, mF 15.55324\n",
            "Epoch 5 finished. Elapse 164.7005\n",
            "Epoch : 6\n",
            "DEV-ACCURACY: 16.75978 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 5\n",
            "Train: Epoch 6 Loss 6.1443, ACC 18.76676, F1 18.58741, mF 16.36126\n",
            "Validation: ACC 16.75978, F1 16.65423, mF 14.1014\n",
            "Test: ACC 17.06716, F1 16.29093, mF 15.10603\n",
            "Epoch 6 finished. Elapse 166.731\n",
            "Epoch : 7\n",
            "DEV-ACCURACY: 17.50466 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 6\n",
            "Train: Epoch 7 Loss 5.9975, ACC 21.15656, F1 21.41093, mF 17.38239\n",
            "Validation: ACC 17.50466, F1 17.15009, mF 14.78349\n",
            "Test: ACC 17.252, F1 16.26289, mF 15.06248\n",
            "Epoch 7 finished. Elapse 157.837\n",
            "Epoch : 8\n",
            "DEV-ACCURACY: 17.31844 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 7\n",
            "Train: Epoch 8 Loss 6.3732, ACC 17.09924, F1 18.20048, mF 14.07068\n",
            "Validation: ACC 17.31844, F1 17.1146, mF 14.44194\n",
            "Test: ACC 17.00555, F1 16.1424, mF 15.06022\n",
            "Epoch 8 finished. Elapse 155.7663\n",
            "Epoch : 9\n",
            "DEV-ACCURACY: 17.13222 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 8\n",
            "Train: Epoch 9 Loss 6.1914, ACC 19.04762, F1 18.73556, mF 17.32555\n",
            "Validation: ACC 17.13222, F1 17.13937, mF 14.38233\n",
            "Test: ACC 17.19039, F1 16.32371, mF 15.17066\n",
            "Epoch 9 finished. Elapse 162.1543\n",
            "Epoch : 10\n",
            "DEV-ACCURACY: 18.24953 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 9\n",
            "Train: Epoch 10 Loss 5.7392, ACC 16.71271, F1 16.10993, mF 15.22814\n",
            "Validation: ACC 18.24953, F1 17.80288, mF 14.99424\n",
            "Test: ACC 17.43685, F1 16.41004, mF 15.2309\n",
            "Epoch 10 finished. Elapse 166.1116\n",
            "Epoch : 11\n",
            "DEV-ACCURACY: 17.50466 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 10\n",
            "Train: Epoch 11 Loss 6.1466, ACC 20.29221, F1 21.68284, mF 15.19941\n",
            "Validation: ACC 17.50466, F1 17.32978, mF 14.76514\n",
            "Test: ACC 17.6833, F1 16.70366, mF 15.59126\n",
            "Epoch 11 finished. Elapse 155.963\n",
            "Epoch : 12\n",
            "DEV-ACCURACY: 17.87709 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 11\n",
            "Train: Epoch 12 Loss 6.1142, ACC 17.53425, F1 17.75219, mF 15.29277\n",
            "Validation: ACC 17.87709, F1 17.49121, mF 15.25574\n",
            "Test: ACC 17.80653, F1 16.8533, mF 15.75855\n",
            "Epoch 12 finished. Elapse 168.9915\n",
            "Epoch : 13\n",
            "DEV-ACCURACY: 17.69088 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 12\n",
            "Train: Epoch 13 Loss 5.7924, ACC 18.47042, F1 18.20537, mF 16.74739\n",
            "Validation: ACC 17.69088, F1 17.45628, mF 15.11447\n",
            "Test: ACC 17.19039, F1 16.28164, mF 15.1278\n",
            "Epoch 13 finished. Elapse 162.6181\n",
            "Epoch : 14\n",
            "DEV-ACCURACY: 17.50466 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 13\n",
            "Train: Epoch 14 Loss 5.5692, ACC 20.059, F1 21.21247, mF 16.73971\n",
            "Validation: ACC 17.50466, F1 17.51254, mF 15.36835\n",
            "Test: ACC 17.252, F1 16.56803, mF 15.54827\n",
            "Epoch 14 finished. Elapse 165.4111\n",
            "Epoch : 15\n",
            "DEV-ACCURACY: 17.69088 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 14\n",
            "Train: Epoch 15 Loss 5.5385, ACC 16.64099, F1 16.49141, mF 14.67595\n",
            "Validation: ACC 17.69088, F1 17.53938, mF 15.00612\n",
            "Test: ACC 17.56007, F1 16.80363, mF 15.74687\n",
            "Epoch 15 finished. Elapse 159.6147\n",
            "Epoch : 16\n",
            "DEV-ACCURACY: 20.11173 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 15\n",
            "Train: Epoch 16 Loss 5.7025, ACC 21.24011, F1 22.11738, mF 16.02778\n",
            "Validation: ACC 20.11173, F1 19.04486, mF 16.05431\n",
            "Test: ACC 18.1146, F1 16.98389, mF 15.88968\n",
            "Epoch 16 finished. Elapse 162.8765\n",
            "Epoch : 17\n",
            "DEV-ACCURACY: 19.73929 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 16\n",
            "Train: Epoch 17 Loss 5.9015, ACC 18.9951, F1 18.86225, mF 17.33853\n",
            "Validation: ACC 19.73929, F1 18.79022, mF 16.15109\n",
            "Test: ACC 18.48429, F1 17.30871, mF 16.07655\n",
            "Epoch 17 finished. Elapse 168.5627\n",
            "Epoch : 18\n",
            "DEV-ACCURACY: 18.43575 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 17\n",
            "Train: Epoch 18 Loss 5.8176, ACC 20.21944, F1 19.62272, mF 19.67824\n",
            "Validation: ACC 18.43575, F1 18.13926, mF 15.84837\n",
            "Test: ACC 18.36106, F1 17.36061, mF 16.07108\n",
            "Epoch 18 finished. Elapse 153.398\n",
            "Epoch : 19\n",
            "DEV-ACCURACY: 19.55307 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 18\n",
            "Train: Epoch 19 Loss 5.5459, ACC 20.57416, F1 21.06167, mF 18.80937\n",
            "Validation: ACC 19.55307, F1 19.00125, mF 16.69479\n",
            "Test: ACC 18.36106, F1 17.32244, mF 16.01582\n",
            "Epoch 19 finished. Elapse 154.4214\n",
            "Epoch : 20\n",
            "DEV-ACCURACY: 18.80819 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 19\n",
            "Train: Epoch 20 Loss 5.1018, ACC 22.2365, F1 22.45175, mF 18.94989\n",
            "Validation: ACC 18.80819, F1 18.30361, mF 16.23373\n",
            "Test: ACC 18.60752, F1 17.6083, mF 16.20631\n",
            "Epoch 20 finished. Elapse 165.7359\n",
            "Epoch : 21\n",
            "DEV-ACCURACY: 18.62197 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 20\n",
            "Train: Epoch 21 Loss 5.3249, ACC 16.93667, F1 16.65989, mF 15.26542\n",
            "Validation: ACC 18.62197, F1 18.2332, mF 16.00724\n",
            "Test: ACC 18.73075, F1 17.8131, mF 16.59676\n",
            "Epoch 21 finished. Elapse 161.3385\n",
            "Epoch : 22\n",
            "DEV-ACCURACY: 18.62197 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 21\n",
            "Train: Epoch 22 Loss 5.597, ACC 19.26164, F1 19.93576, mF 15.34844\n",
            "Validation: ACC 18.62197, F1 18.10252, mF 15.64503\n",
            "Test: ACC 17.74492, F1 16.99018, mF 15.70893\n",
            "Epoch 22 finished. Elapse 154.9955\n",
            "Epoch : 23\n",
            "DEV-ACCURACY: 20.11173 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 22\n",
            "Train: Epoch 23 Loss 4.7288, ACC 22.57143, F1 23.96666, mF 17.32965\n",
            "Validation: ACC 20.11173, F1 19.13046, mF 16.05902\n",
            "Test: ACC 19.10043, F1 17.69187, mF 16.1461\n",
            "Epoch 23 finished. Elapse 162.5073\n",
            "Epoch : 24\n",
            "DEV-ACCURACY: 19.55307 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 23\n",
            "Train: Epoch 24 Loss 4.9368, ACC 19.18239, F1 19.40205, mF 16.97023\n",
            "Validation: ACC 19.55307, F1 18.7058, mF 16.2407\n",
            "Test: ACC 18.73075, F1 17.55715, mF 16.20266\n",
            "Epoch 24 finished. Elapse 160.7378\n",
            "Epoch : 25\n",
            "DEV-ACCURACY: 20.29795 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 24\n",
            "Train: Epoch 25 Loss 4.8643, ACC 20.86835, F1 23.05605, mF 14.63286\n",
            "Validation: ACC 20.29795, F1 19.54326, mF 16.93544\n",
            "Test: ACC 19.47012, F1 18.26855, mF 16.74212\n",
            "Epoch 25 finished. Elapse 167.3998\n",
            "Epoch : 26\n",
            "DEV-ACCURACY: 21.04283 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 25\n",
            "Train: Epoch 26 Loss 4.633, ACC 21.75182, F1 22.73179, mF 17.2647\n",
            "Validation: ACC 21.04283, F1 20.05254, mF 17.19452\n",
            "Test: ACC 20.51756, F1 19.01195, mF 17.59525\n",
            "Epoch 26 finished. Elapse 160.3414\n",
            "Epoch : 27\n",
            "DEV-ACCURACY: 23.09125 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 26\n",
            "Train: Epoch 27 Loss 4.4939, ACC 22.25131, F1 22.80132, mF 18.91118\n",
            "Validation: ACC 23.09125, F1 21.84389, mF 18.6503\n",
            "Test: ACC 21.44177, F1 19.66977, mF 17.62276\n",
            "Epoch 27 finished. Elapse 174.2085\n",
            "Epoch : 28\n",
            "DEV-ACCURACY: 21.41527 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 27\n",
            "Train: Epoch 28 Loss 4.8908, ACC 20.37303, F1 20.33066, mF 18.1652\n",
            "Validation: ACC 21.41527, F1 20.72153, mF 17.73204\n",
            "Test: ACC 20.7024, F1 19.29444, mF 17.88151\n",
            "Epoch 28 finished. Elapse 164.5606\n",
            "Epoch : 29\n",
            "DEV-ACCURACY: 21.41527 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 28\n",
            "Train: Epoch 29 Loss 4.6276, ACC 16.87389, F1 17.9462, mF 15.57922\n",
            "Validation: ACC 21.41527, F1 21.31082, mF 18.32551\n",
            "Test: ACC 21.50339, F1 20.74673, mF 19.2414\n",
            "Epoch 29 finished. Elapse 158.2916\n",
            "Epoch : 30\n",
            "DEV-ACCURACY: 22.16015 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 29\n",
            "Train: Epoch 30 Loss 4.3526, ACC 22.91105, F1 23.07653, mF 21.22922\n",
            "Validation: ACC 22.16015, F1 21.47076, mF 18.81315\n",
            "Test: ACC 21.565, F1 20.48224, mF 19.324\n",
            "Epoch 30 finished. Elapse 169.2121\n",
            "Epoch : 31\n",
            "DEV-ACCURACY: 23.46369 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 30\n",
            "Train: Epoch 31 Loss 4.1584, ACC 23.60704, F1 24.66927, mF 20.00981\n",
            "Validation: ACC 23.46369, F1 22.23687, mF 19.6762\n",
            "Test: ACC 22.4276, F1 20.94201, mF 19.60301\n",
            "Epoch 31 finished. Elapse 157.5002\n",
            "Epoch : 32\n",
            "DEV-ACCURACY: 23.09125 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 31\n",
            "Train: Epoch 32 Loss 4.4046, ACC 19.2604, F1 19.84153, mF 17.33408\n",
            "Validation: ACC 23.09125, F1 22.48986, mF 19.36793\n",
            "Test: ACC 22.92052, F1 21.61796, mF 20.22998\n",
            "Epoch 32 finished. Elapse 161.7096\n",
            "Epoch : 33\n",
            "DEV-ACCURACY: 22.53259 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 32\n",
            "Train: Epoch 33 Loss 3.8882, ACC 20.85236, F1 21.44646, mF 17.0063\n",
            "Validation: ACC 22.53259, F1 22.01078, mF 19.28796\n",
            "Test: ACC 21.68823, F1 20.20431, mF 19.04279\n",
            "Epoch 33 finished. Elapse 163.0309\n",
            "Epoch : 34\n",
            "DEV-ACCURACY: 22.53259 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 33\n",
            "Train: Epoch 34 Loss 3.8205, ACC 22.40437, F1 22.1232, mF 20.44309\n",
            "Validation: ACC 22.53259, F1 21.64623, mF 18.5536\n",
            "Test: ACC 22.98213, F1 21.21679, mF 19.90854\n",
            "Epoch 34 finished. Elapse 167.1498\n",
            "Epoch : 35\n",
            "DEV-ACCURACY: 23.27747 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 34\n",
            "Train: Epoch 35 Loss 3.8335, ACC 21.78218, F1 22.88999, mF 17.82087\n",
            "Validation: ACC 23.27747, F1 22.24051, mF 18.97628\n",
            "Test: ACC 23.78312, F1 21.67165, mF 20.37964\n",
            "Epoch 35 finished. Elapse 165.181\n",
            "Epoch : 36\n",
            "DEV-ACCURACY: 24.20857 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 35\n",
            "Train: Epoch 36 Loss 3.4824, ACC 26.39296, F1 27.97402, mF 19.0557\n",
            "Validation: ACC 24.20857, F1 22.71635, mF 19.73364\n",
            "Test: ACC 23.59827, F1 21.54422, mF 20.39836\n",
            "Epoch 36 finished. Elapse 167.263\n",
            "Epoch : 37\n",
            "DEV-ACCURACY: 25.13966 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 36\n",
            "Train: Epoch 37 Loss 3.4738, ACC 23.49398, F1 23.51148, mF 20.18232\n",
            "Validation: ACC 25.13966, F1 24.36499, mF 21.32609\n",
            "Test: ACC 23.84473, F1 22.07239, mF 20.47767\n",
            "Epoch 37 finished. Elapse 162.979\n",
            "Epoch : 38\n",
            "DEV-ACCURACY: 23.46369 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 37\n",
            "Train: Epoch 38 Loss 3.5293, ACC 23.93162, F1 23.65047, mF 20.19562\n",
            "Validation: ACC 23.46369, F1 22.66996, mF 19.34857\n",
            "Test: ACC 24.39926, F1 22.60923, mF 21.14774\n",
            "Epoch 38 finished. Elapse 159.7222\n",
            "Epoch : 39\n",
            "DEV-ACCURACY: 24.95345 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 38\n",
            "Train: Epoch 39 Loss 3.5061, ACC 26.11276, F1 25.28019, mF 23.10026\n",
            "Validation: ACC 24.95345, F1 24.15331, mF 21.47741\n",
            "Test: ACC 23.78312, F1 22.39093, mF 21.07162\n",
            "Epoch 39 finished. Elapse 165.8009\n",
            "Epoch : 40\n",
            "DEV-ACCURACY: 25.13966 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 39\n",
            "Train: Epoch 40 Loss 3.2558, ACC 23.60061, F1 24.94841, mF 18.95082\n",
            "Validation: ACC 25.13966, F1 24.58018, mF 21.34103\n",
            "Test: ACC 24.5841, F1 23.23289, mF 21.66173\n",
            "Epoch 40 finished. Elapse 161.5641\n",
            "Epoch : 41\n",
            "DEV-ACCURACY: 24.58101 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 40\n",
            "Train: Epoch 41 Loss 3.393, ACC 22.07792, F1 21.73525, mF 19.46046\n",
            "Validation: ACC 24.58101, F1 24.06284, mF 21.31373\n",
            "Test: ACC 23.65989, F1 22.41048, mF 21.10353\n",
            "Epoch 41 finished. Elapse 166.3284\n",
            "Epoch : 42\n",
            "DEV-ACCURACY: 26.62942 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 41\n",
            "Train: Epoch 42 Loss 2.9805, ACC 23.27327, F1 23.24287, mF 19.59826\n",
            "Validation: ACC 26.62942, F1 24.94486, mF 21.44753\n",
            "Test: ACC 23.96796, F1 21.92656, mF 20.43708\n",
            "Epoch 42 finished. Elapse 169.3012\n",
            "Epoch : 43\n",
            "DEV-ACCURACY: 26.81564 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 42\n",
            "Train: Epoch 43 Loss 3.5529, ACC 20.1087, F1 19.88975, mF 19.66001\n",
            "Validation: ACC 26.81564, F1 25.60274, mF 22.93013\n",
            "Test: ACC 23.22859, F1 21.62226, mF 20.48407\n",
            "Epoch 43 finished. Elapse 166.1091\n",
            "Epoch : 44\n",
            "DEV-ACCURACY: 23.46369 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 43\n",
            "Train: Epoch 44 Loss 3.0827, ACC 27.04, F1 27.62415, mF 22.64691\n",
            "Validation: ACC 23.46369, F1 22.89374, mF 21.01667\n",
            "Test: ACC 21.68823, F1 21.00562, mF 19.72576\n",
            "Epoch 44 finished. Elapse 155.8505\n",
            "Epoch : 45\n",
            "DEV-ACCURACY: 20.85661 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 44\n",
            "Train: Epoch 45 Loss 3.2657, ACC 19.94178, F1 19.78276, mF 18.07349\n",
            "Validation: ACC 20.85661, F1 20.45011, mF 18.5226\n",
            "Test: ACC 20.88725, F1 20.81908, mF 19.23296\n",
            "Epoch 45 finished. Elapse 162.9019\n",
            "Epoch : 46\n",
            "DEV-ACCURACY: 25.5121 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 45\n",
            "Train: Epoch 46 Loss 3.1262, ACC 21.2585, F1 20.41738, mF 20.91472\n",
            "Validation: ACC 25.5121, F1 24.86355, mF 21.94295\n",
            "Test: ACC 23.47505, F1 22.01332, mF 20.50212\n",
            "Epoch 46 finished. Elapse 157.6944\n",
            "Epoch : 47\n",
            "DEV-ACCURACY: 26.07076 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 46\n",
            "Train: Epoch 47 Loss 2.9452, ACC 25.6338, F1 26.12328, mF 23.00525\n",
            "Validation: ACC 26.07076, F1 25.3922, mF 22.66493\n",
            "Test: ACC 24.09119, F1 22.72385, mF 21.3995\n",
            "Epoch 47 finished. Elapse 163.0604\n",
            "Epoch : 48\n",
            "DEV-ACCURACY: 24.76723 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 47\n",
            "Train: Epoch 48 Loss 2.8895, ACC 24.93261, F1 24.88411, mF 23.30323\n",
            "Validation: ACC 24.76723, F1 23.38087, mF 20.19238\n",
            "Test: ACC 23.47505, F1 22.10897, mF 20.59753\n",
            "Epoch 48 finished. Elapse 168.5605\n",
            "Epoch : 49\n",
            "DEV-ACCURACY: 24.76723 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 48\n",
            "Train: Epoch 49 Loss 3.0267, ACC 23.8292, F1 24.04131, mF 20.7974\n",
            "Validation: ACC 24.76723, F1 24.00917, mF 21.64682\n",
            "Test: ACC 23.2902, F1 22.13292, mF 20.72585\n",
            "Epoch 49 finished. Elapse 169.4059\n",
            "Epoch : 50\n",
            "DEV-ACCURACY: 23.27747 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 49\n",
            "Train: Epoch 50 Loss 2.9824, ACC 22.41888, F1 22.62379, mF 20.69513\n",
            "Validation: ACC 23.27747, F1 23.50758, mF 20.72425\n",
            "Test: ACC 22.48922, F1 21.93764, mF 20.95192\n",
            "Epoch 50 finished. Elapse 166.414\n",
            "Epoch : 51\n",
            "DEV-ACCURACY: 24.76723 || BEST=ACCURACY: 27.93296\n",
            "CURRENT VALUE OF STOPPING: 50\n",
            "Train: Epoch 51 Loss 2.7055, ACC 25.77488, F1 28.22924, mF 20.93297\n",
            "Validation: ACC 24.76723, F1 24.49887, mF 21.79639\n",
            "Test: ACC 23.16697, F1 21.74646, mF 20.46479\n",
            "Epoch 51 finished. Elapse 159.0002\n",
            "----------------------------------------------\n",
            "\n",
            "\n",
            "[DEV] best ACC 27.93296, F1 18.33238, mF 12.29035\n",
            "[TEST] best ACC 24.95379, F1 16.48024, mF 13.26261\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# [optional] finish the wandb run, necessary in notebooks\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "jZEcwG2HERF6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355,
          "referenced_widgets": [
            "f24917236f3b48c592a82055283b62dd",
            "e7942385da3f45c8a6dc8a6547a1ccd1",
            "bad783f389324d969cb76504950cab28",
            "8f40931465d54b0aa893d4ca76a34879",
            "99449b211c95496cbcecead7209133ab",
            "1720c4e46d7f4b53bb7ebda155c3936e",
            "82fe2ff36a39463c9fe43775a8219f95",
            "fa6992b6fd874ebe976a94259e700330"
          ]
        },
        "outputId": "2ec11184-f73d-44a9-f32e-f22f9cbf4735"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f24917236f3b48c592a82055283b62dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_dev_fscore</td><td>▂▃▂▂▁▁▁▁▂▂▂▂▃▃▂▂▂▂▃▃▄▅▅▅▅▅▅▅▆▆▇▇▇█▆▄█▆▇▇</td></tr><tr><td>avg_test_fscore</td><td>▁▃▃▂▁▁▁▁▂▂▁▂▂▂▂▂▃▂▂▃▄▄▆▅▆▅▆▆▆▇▇█▇▆▆▆▇▇▇▇</td></tr><tr><td>avg_train_accuracy</td><td>▃▃▃▁▂▄▁▃▃▂▂▁▄▃▃▅▁▃▃▄▄▅▁▅▆▄▅▄█▆▇▆▅▃█▃▇▇▆▇</td></tr><tr><td>avg_train_fscore</td><td>▄▃▃▂▂▄▂▂▄▂▂▁▄▂▃▅▁▃▃▅▅▅▂▅▆▄▄▅█▅▆▆▅▃█▃▇▆▆█</td></tr><tr><td>avg_train_loss</td><td>██▇█▇▇██▇▇▇▆▇▇▇▆▆▆▅▅▅▄▅▄▄▃▃▃▂▃▃▂▂▃▂▂▁▁▂▁</td></tr><tr><td>dev_accuracy</td><td>█▄▃▂▁▁▁▁▁▂▂▂▃▃▂▂▂▂▃▃▄▅▄▄▅▅▅▅▆▅▆▆▇▇▅▄▇▆▆▆</td></tr><tr><td>test_accuracy</td><td>█▅▃▂▁▁▁▁▂▂▁▁▂▂▂▂▃▂▃▃▄▅▅▅▆▅▆▇▇█▇█▇▆▅▄▇▇▇▆</td></tr><tr><td>train_macro_f1_score</td><td>▃▃▃▁▃▄▁▃▂▂▃▁▂▃▅▅▂▂▃▁▃▅▂▆▆▃▆▄▅▆█▅▅▅█▄██▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_dev_fscore</td><td>24.49887</td></tr><tr><td>avg_test_fscore</td><td>21.74646</td></tr><tr><td>avg_train_accuracy</td><td>25.77488</td></tr><tr><td>avg_train_fscore</td><td>28.22924</td></tr><tr><td>avg_train_loss</td><td>2.7055</td></tr><tr><td>dev_accuracy</td><td>24.76723</td></tr><tr><td>test_accuracy</td><td>23.16697</td></tr><tr><td>train_macro_f1_score</td><td>20.93297</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">SKAIG-With-Spectrogram-With-Batch-Size-20-FastAI-batch-size-20-l2-0.5</strong> at: <a href='https://wandb.ai/mh_detection/SKAIG/runs/z859qb41' target=\"_blank\">https://wandb.ai/mh_detection/SKAIG/runs/z859qb41</a><br/> View project at: <a href='https://wandb.ai/mh_detection/SKAIG' target=\"_blank\">https://wandb.ai/mh_detection/SKAIG</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240510_233528-z859qb41/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WE WILL BE DOING THE PREDICTION PART LATER. BEFORE THAT WE NEED TO INCREASE THE TRAINING ACCURACY USING THE SPECTROGRAM IMAGES(TAKING VOICE INTENSITY INTO ACCOUNT)"
      ],
      "metadata": {
        "id": "0J8PMITsDXgx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TRYING TO DO PREDICTION USING THE SAVED MODEL"
      ],
      "metadata": {
        "id": "uGBD1NEa2O_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"IEMOCAP_C/model_without_spectrogram.pth\"\n",
        "# model_path = \"IEMOCAP_C/model_spectrogram_last_2_layer_learning.pth\"\n",
        "print(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjRlTZzaZ7RS",
        "outputId": "67ff1f6c-ec4f-4147-83b5-07fa65fc5c45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IEMOCAP_C/model_without_spectrogram.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "'''\n",
        "label index mapping = {'hap':0, 'sad':1, 'neu':2, 'ang':3, 'exc':4, 'fru':5}\n",
        "'''\n",
        "\n",
        "# Load the model using torch.load\n",
        "model_state_dict = torch.load(model_path)\n",
        "\n",
        "pretrain='roberta-base'\n",
        "model = AutoModelForSequenceClassification.from_pretrained(pretrain, state_dict=model_state_dict)\n",
        "tokenizer = AutoTokenizer.from_pretrained(pretrain)\n",
        "\n",
        "input_text = \"Look at this, all of the hairs are standing up on my arm.\"\n",
        "tokens = tokenizer(input_text, return_tensors='pt')\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(**tokens)\n",
        "\n",
        "probabilities = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
        "predicted_class = torch.argmax(probabilities).item()\n",
        "\n",
        "print(\"Predicted Emotion:\", predicted_class)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5z5i-_DYbre",
        "outputId": "b88f082f-3cef-4cf9-9a73-8fc264cafc2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Emotion: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"This is totally totally Horrible!\"\n",
        "tokens = tokenizer(input_text, return_tensors='pt')\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(**tokens)\n",
        "\n",
        "probabilities = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
        "predicted_class = torch.argmax(probabilities).item()\n",
        "\n",
        "print(\"Predicted Emotion:\", predicted_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBGXbUppbvno",
        "outputId": "e2c62af6-2498-44de-95f6-9aad6599557f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Emotion: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"What the hell do you think of yourself?\"\n",
        "tokens = tokenizer(input_text, return_tensors='pt')\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(**tokens)\n",
        "\n",
        "probabilities = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
        "predicted_class = torch.argmax(probabilities).item()\n",
        "\n",
        "print(\"Predicted Emotion:\", predicted_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPPYMgvscaAT",
        "outputId": "440ed83e-4abc-4ebf-dc47-278305d25026"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Emotion: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def predict_emotion(input_text, pretrained_model, model_path):\n",
        "#     pretrained_model.load_state_dict(torch.load(model_path))\n",
        "#     pretrained_model.to('cuda:0')\n",
        "#     pretrained_model.eval()\n",
        "\n",
        "#     # tokenizer = AutoTokenizer.from_pretrained(pretrained_model)\n",
        "#     # # Tokenize the input\n",
        "#     # inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "#     # print(inputs)\n",
        "#     # # Make predictions\n",
        "#     with torch.no_grad():\n",
        "#         predictions = pretrained_model(input_text)\n",
        "\n",
        "\n",
        "#     # Interpret predictions\n",
        "#     probabilities = F.softmax(predictions, dim=1)\n",
        "#     predicted_class = torch.argmax(probabilities, dim=1).item()\n",
        "\n",
        "#     print(f\"Predicted class: {predicted_class}\")\n",
        "\n",
        "\n",
        "def preprocess_speaker(speaker_info):\n",
        "    # Your preprocessing logic for speaker information\n",
        "    # ...\n",
        "\n",
        "    # Dummy example: Assuming one-hot encoding for demonstration\n",
        "    speaker_classes = [\"M\", \"F\"]\n",
        "    one_hot_encoded = [int(speaker_info == speaker) for speaker in speaker_classes]\n",
        "\n",
        "    return torch.tensor(one_hot_encoded)\n",
        "\n",
        "def predict_emotion(input_text, speaker_information, dataset_name, model_path):\n",
        "    inputs_tokenized = []\n",
        "    if dataset_name == 'IEMOCAP':\n",
        "        pretrain='roberta-base'\n",
        "        tokenizer = AutoTokenizer.from_pretrained(pretrain)\n",
        "        # Tokenize the input\n",
        "        inputs_tokenized = tokenizer.encode_plus(input_text, add_special_tokens=True, return_tensors=\"pt\", padding='max_length', truncation=True, max_length=512)\n",
        "        print(type(inputs_tokenized), type(inputs_tokenized['input_ids']))\n",
        "        # Adjust tokens based on your model's specific requirements\n",
        "        input_ids = inputs_tokenized['input_ids'].to('cuda:0')\n",
        "        attention_mask = inputs_tokenized['attention_mask'].to('cuda:0')\n",
        "        speaker_input = preprocess_speaker(speaker_information)\n",
        "        # model = MentalModel(encoder_type=pretrain)\n",
        "        # model = AutoModelForSequenceClassification.from_pretrained(pretrain)\n",
        "        model = MentalModel(encoder_type=pretrain, encoder_mode=encoder_mode, sent_dim=sent_dim, tr_nhead=tr_nhead,\n",
        "                        tr_ff_dim=tr_ff_dim, tr_dropout=tr_dropout, attn_mask=attn_mask, tr_num_layer=tr_num_layer,\n",
        "                        max_len=max_len, num_class=num_class, bidirectional=bidirectional, num_block=num_block,\n",
        "                        cn_nhead=cn_nhead, cn_ff_dim=cn_ff_dim, cn_dropout=cn_dropout, edge_dim=edge_dim, bias=bias,\n",
        "                        cn_num_layer=cn_num_layer, edge_mapping=edge_mapping, beta=beta, root_weight=root_weight, choice=choice)\n",
        "\n",
        "    elif dataset_name == 'DailyDialog':\n",
        "        pretrain='roberta-large'\n",
        "        tokenizer = AutoTokenizer.from_pretrained(pretrain)\n",
        "        # Tokenize the input\n",
        "        inputs_tokenized = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "        model = BatchMentalModel()\n",
        "    else:\n",
        "        model = BatchMentalModelResidual()\n",
        "\n",
        "    # print(f\"Loading the Model: {model} from the path:{model_path}!\")\n",
        "    model.load_state_dict(torch.load(model_path), strict=False)\n",
        "\n",
        "    model.eval()\n",
        "    model.to('cuda:0')\n",
        "    # print(inputs)\n",
        "    # # Make predictions\n",
        "    with torch.no_grad():\n",
        "        predictions = model(**inputs_tokenized, mask=None)\n",
        "\n",
        "    print(predictions)\n",
        "\n",
        "    # Interpret predictions\n",
        "    probabilities = F.softmax(predictions, dim=1)\n",
        "    predicted_class = torch.argmax(probabilities, dim=1).item()\n",
        "\n",
        "    labels = ['hap', 'sad', 'neu', 'ang', 'exc', 'fru']\n",
        "    print(f\"Predicted class: {predicted_class}\")\n",
        "\n",
        "    predicted_label = label_names[predicted_class]\n",
        "    print(predicted_label)\n",
        "\n",
        "\n",
        "input_text=\"This is an excellect piece of information! Well Done.\"\n",
        "speaker_information=\"M\"\n",
        "print(model_path, dataset_name)\n",
        "\n",
        "predict_emotion(input_text, speaker_information, dataset_name, model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "hWpOvP1iUZqX",
        "outputId": "54fd53ba-095b-46ea-e73f-e5b5574b24e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IEMOCAP_C/model_without_spectrogram.pth IEMOCAP\n",
            "<class 'transformers.tokenization_utils_base.BatchEncoding'> <class 'torch.Tensor'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "MentalModel.forward() got an unexpected keyword argument 'input_ids'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-64a6a977fd39>\u001b[0m in \u001b[0;36m<cell line: 88>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m \u001b[0mpredict_emotion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspeaker_information\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-26-64a6a977fd39>\u001b[0m in \u001b[0;36mpredict_emotion\u001b[0;34m(input_text, speaker_information, dataset_name, model_path)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# # Make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs_tokenized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: MentalModel.forward() got an unexpected keyword argument 'input_ids'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TRYING TO CREATE KNOWLEDGE GRAPHS FOR SENTENCES"
      ],
      "metadata": {
        "id": "rSr9EHyWoaH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install graph-transformer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFBiN0WUoSSR",
        "outputId": "72368bd6-c9cd-4c08-8947-18e55a613694"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting graph-transformer\n",
            "  Downloading graph-transformer-0.1.tar.gz (3.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from graph-transformer) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.10/dist-packages (from graph-transformer) (1.23.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->graph-transformer) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->graph-transformer) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->graph-transformer) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->graph-transformer) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->graph-transformer) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->graph-transformer) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->graph-transformer) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->graph-transformer) (2.1.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->graph-transformer) (1.3.0)\n",
            "Building wheels for collected packages: graph-transformer\n",
            "  Building wheel for graph-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for graph-transformer: filename=graph_transformer-0.1-py3-none-any.whl size=1388 sha256=0777bcd37e6a88864922a3bb706fbc9c462e079fad7bfeae139b34cfd1dda3ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/ac/14/356ad0100b08277a93aaa48afd2ee90fc82297740daa89fd08\n",
            "Successfully built graph-transformer\n",
            "Installing collected packages: graph-transformer\n",
            "Successfully installed graph-transformer-0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install graph-transformer-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsALZwvuiuH_",
        "outputId": "198cb6ce-0e63-457a-8028-dbf6361b8302"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting graph-transformer-pytorch\n",
            "  Downloading graph_transformer_pytorch-0.1.1-py3-none-any.whl (4.3 kB)\n",
            "Collecting einops>=0.3 (from graph-transformer-pytorch)\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rotary-embedding-torch (from graph-transformer-pytorch)\n",
            "  Downloading rotary_embedding_torch-0.5.3-py3-none-any.whl (5.3 kB)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from graph-transformer-pytorch) (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->graph-transformer-pytorch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->graph-transformer-pytorch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->graph-transformer-pytorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->graph-transformer-pytorch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->graph-transformer-pytorch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->graph-transformer-pytorch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->graph-transformer-pytorch) (2.1.0)\n",
            "Collecting beartype (from rotary-embedding-torch->graph-transformer-pytorch)\n",
            "  Downloading beartype-0.17.0-py3-none-any.whl (866 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m866.1/866.1 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->graph-transformer-pytorch) (2.1.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->graph-transformer-pytorch) (1.3.0)\n",
            "Installing collected packages: einops, beartype, rotary-embedding-torch, graph-transformer-pytorch\n",
            "Successfully installed beartype-0.17.0 einops-0.7.0 graph-transformer-pytorch-0.1.1 rotary-embedding-torch-0.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from graph-transformer import GraphTransformerModel\n",
        "\n",
        "model = GraphTransformerModel(\n",
        "        node_dim = 512,\n",
        "        edge_dim = 512,\n",
        "        num_blocks = 3, # number of graph transformer blocks\n",
        "        num_heads = 8,\n",
        "        last_average=True, # whether to average or concatenation at the last block\n",
        "        model_dim=None # if None, node_dim will be used as the dimension of the graph transformer block\n",
        ")\n",
        "\n",
        "nodes = torch.randn(1, 128, 512)\n",
        "edges = torch.randn(1, 128, 128, 512)\n",
        "adjacency = torch.ones(1, 128, 128)\n",
        "\n",
        "nodes = model(nodes, edges, adjacency)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "AmBUz5hlo901",
        "outputId": "1583a43d-9d0e-4e5a-cc6f-f906d128ad0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-20-b94fd3780d16>, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-b94fd3780d16>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    from graph-transformer import GraphTransformerModel\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "# with open('bert_data/IEMOCAP/IEMOCAP_graph_hip7_new.pkl', 'rb') as f:\n",
        "#     data = pickle.load(f)\n",
        "\n",
        "pickled_df = pd.DataFrame(pd.read_pickle(\"bert_data/IEMOCAP/IEMOCAP_graph_hip7_new.pkl\"))\n",
        "pickled_df"
      ],
      "metadata": {
        "id": "cnPPE6hgoNHa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "outputId": "72fe0743-9157-4283-e18b-3d6135384c53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     train  \\\n",
              "0  [[Hey, Isabella., Hey, how's it going, Joe?, I'm all right., Uh-, So I got some good news., Yep., You're not pregnant or anything., I know you've been trying to have a baby, right?, I have some better news than that., Yes, What would you want more than anything in this world?, How about maybe for me to possibly stay in L.A.?, Which one?, I got--U.S.C.. I got- Yeah, I got the acceptance letter., Yes, me, I got in. Thank you very much., Good for you., Yeah, I know, my mom called me. I was with my girlfriend in Boston, and uh- she got the letter and she called me, she said I don't know, do yo...   \n",
              "1  [[2, 0, 2, 0, 0, 2, 2, 0, 0, 0, 4, 4, 4, 4, 4, 4, 2, 0, 4, 0, 4, 4, 4, 2, 0, 4, 0, 0, 4, 4, 0, 2, 4, 4, 4, 2, 0, 0, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 0, 0, 4, 2, 0, 0, 0, 0], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 4, 0, 4, 4, 0, 0, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 0, 0, 0, 0, 4, 4, 0], [5, 5, 2, 5, 5, 2, 2, 2, 5, 2, 2, 5, 5, 5, 2, 5, 2, 5, 2, 5, 5, 2, 5, 2, 5, 5, 2, 5, 2, 5, 2, 5, 5, 2, 2, 2, 2, 2, 2], [0, 2, 4, 5, 5, 5, 5, 5, 4, 2, 0, 3, 5, 3, 5, 5, 2, 5, 5, 5, 3, 5, 4, 3, 5, 4, 3, 5, 5, 5, 4, 5, 3, 3, 5, 5, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 3, 3], [2, 4, 4, 4, 4, 4, 4...   \n",
              "2  [[M, F, M, F, F, M, M, F, F, F, M, F, F, M, F, F, M, F, M, F, M, F, M, F, M, F, F, F, M, F, M, M, F, M, F, M, F, F, M, F, F, M, F, F, M, M, M, F, F, M, M, M, F, M, F, M], [M, F, M, F, F, F, M, F, F, F, M, M, F, M, M, F, M, F, F, M, M, M, F, M, F, M, F, M, F, M, F, M, F, M, F, M, F, M, M, F, F, M, F, M], [M, M, F, M, M, F, F, M, M, F, F, M, M, M, F, M, F, M, F, M, M, F, M, F, M, M, F, M, F, M, F, M, M, M, F, M, F, M, F], [M, F, M, M, M, F, M, M, M, M, M, F, M, F, M, F, M, F, M, F, F, M, M, F, M, M, F, M, F, M, M, M, F, F, M, M, F, M, M, M, M, M, M, M, M, M, M, F, F, F], [M, M, F, M, F, M, F...   \n",
              "3  {'edge_index': [[[ 0  0  0 ... 55 55 55], [ 0  1  2 ... 51 53 55]], [[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  1  1  1  1\n",
              "  1  1  1  1  1  1  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  3  3\n",
              "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  4  4  4  4  4  4  4  4  4  4\n",
              "  4  4  4  4  4  4  4  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
              "  5  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  7  7  7  7  7  7\n",
              "  7  7  7  7  7  7  7  7  7  7  7  7  7  8  8  8  8  8  8  8  8  8  8  8\n",
              "  8  8  8  8  8  8  8  8  8  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n",
              "  9  9  9  9  9 ...   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      test  \n",
              "0  [[Why does that bother you?, Well, maybe maybe he just wanted to see her again., Nobody comes seven hundred miles just to see., What are you talking about?  He grew up next to the girl his whole life, why wouldn't he want to see her again?  Don't look at me like that.  He hasn't told me anything he didn't told you., Why do you think he's even thinking that?, He's got that about it., Well, so what?, What's going on here, Joe?, Now listen., How do you know why she's waited?, Look, it's a beautiful day outside, why are we arguing?, Well, what do you want me to do about it?  What do you want?,...  \n",
              "1  [[2, 2, 2, 5, 2, 2, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 3, 3, 3], [2, 1, 1, 1, 1, 3, 3, 5, 1, 5, 1, 1, 3, 1, 1, 5, 3, 5, 3, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 5, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 2, 5, 2, 5, 2, 5, 2, 2, 5, 2, 5, 2, 5, 2, 5, 2, 5, 2, 2], [2, 2, 2, 2, 2, 5, 5, 3, 2, 5, 5, 5, 5, 2, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 3, 5], [2, 2, 2, 2, 2, 2, 5, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 5, 2, 2, 5, 5, 2, 5, 5, 5, 2, 5, 2, 2, 2, 5, 2, 3, 2, 5, 5, 2, 2, 3...  \n",
              "2  [[M, M, F, M, M, F, M, F, M, M, M, M, F, M, F, M, M, F, M, F, M, F, M], [M, F, F, F, F, M, M, M, F, M, F, F, M, F, F, F, M, F, M, M, F, F, F, F, M, M, F, M, F, F, F, M, F, F, M, F, M, M, M, F, M, F, M, F, F, F, F, M, F], [M, F, M, F, M, F, M, F, M, F, M, F, M, F, M, F, M, F, M, F, F, M, F, F, M, F, M, F, M, F, F, M, F, M, F, M, F, M, F, M, F, M], [F, F, F, F, F, M, F, M, F, M, F, M, F, F, F, M, F, F, M, F, M, F, F, M, F, M, F, F, M, F, M, F, M, F, M, M, F, M, F, M], [F, M, F, M, F, M, F, M, F, F, M, M, F, M, M, F, M, F, M, F, M, F, M, F, M, F, M, F, M, F, M, M, M, F, M, F, M, M, M, M, M, F...  \n",
              "3  {'edge_index': [[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  1  1  1  1\n",
              "  1  1  1  1  1  1  1  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  3  3\n",
              "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  4  4  4  4  4  4  4  4  4\n",
              "  4  4  4  4  4  4  4  4  4  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
              "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  7  7  7  7  7  7\n",
              "  7  7  7  7  7  7  7  7  7  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8\n",
              "  8  8  8  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9 10 10\n",
              " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 11 11 11 11 1...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f4ad4ca3-0cd0-4724-b2dc-ef10553e9fc6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train</th>\n",
              "      <th>test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[Hey, Isabella., Hey, how's it going, Joe?, I'm all right., Uh-, So I got some good news., Yep., You're not pregnant or anything., I know you've been trying to have a baby, right?, I have some better news than that., Yes, What would you want more than anything in this world?, How about maybe for me to possibly stay in L.A.?, Which one?, I got--U.S.C.. I got- Yeah, I got the acceptance letter., Yes, me, I got in. Thank you very much., Good for you., Yeah, I know, my mom called me. I was with my girlfriend in Boston, and uh- she got the letter and she called me, she said I don't know, do yo...</td>\n",
              "      <td>[[Why does that bother you?, Well, maybe maybe he just wanted to see her again., Nobody comes seven hundred miles just to see., What are you talking about?  He grew up next to the girl his whole life, why wouldn't he want to see her again?  Don't look at me like that.  He hasn't told me anything he didn't told you., Why do you think he's even thinking that?, He's got that about it., Well, so what?, What's going on here, Joe?, Now listen., How do you know why she's waited?, Look, it's a beautiful day outside, why are we arguing?, Well, what do you want me to do about it?  What do you want?,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[2, 0, 2, 0, 0, 2, 2, 0, 0, 0, 4, 4, 4, 4, 4, 4, 2, 0, 4, 0, 4, 4, 4, 2, 0, 4, 0, 0, 4, 4, 0, 2, 4, 4, 4, 2, 0, 0, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 0, 0, 4, 2, 0, 0, 0, 0], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 4, 0, 4, 4, 0, 0, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 0, 0, 0, 0, 4, 4, 0], [5, 5, 2, 5, 5, 2, 2, 2, 5, 2, 2, 5, 5, 5, 2, 5, 2, 5, 2, 5, 5, 2, 5, 2, 5, 5, 2, 5, 2, 5, 2, 5, 5, 2, 2, 2, 2, 2, 2], [0, 2, 4, 5, 5, 5, 5, 5, 4, 2, 0, 3, 5, 3, 5, 5, 2, 5, 5, 5, 3, 5, 4, 3, 5, 4, 3, 5, 5, 5, 4, 5, 3, 3, 5, 5, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 3, 3], [2, 4, 4, 4, 4, 4, 4...</td>\n",
              "      <td>[[2, 2, 2, 5, 2, 2, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 3, 3, 3], [2, 1, 1, 1, 1, 3, 3, 5, 1, 5, 1, 1, 3, 1, 1, 5, 3, 5, 3, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 5, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 2, 5, 2, 5, 2, 5, 2, 2, 5, 2, 5, 2, 5, 2, 5, 2, 5, 2, 2], [2, 2, 2, 2, 2, 5, 5, 3, 2, 5, 5, 5, 5, 2, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 3, 5], [2, 2, 2, 2, 2, 2, 5, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 5, 2, 2, 5, 5, 2, 5, 5, 5, 2, 5, 2, 2, 2, 5, 2, 3, 2, 5, 5, 2, 2, 3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[M, F, M, F, F, M, M, F, F, F, M, F, F, M, F, F, M, F, M, F, M, F, M, F, M, F, F, F, M, F, M, M, F, M, F, M, F, F, M, F, F, M, F, F, M, M, M, F, F, M, M, M, F, M, F, M], [M, F, M, F, F, F, M, F, F, F, M, M, F, M, M, F, M, F, F, M, M, M, F, M, F, M, F, M, F, M, F, M, F, M, F, M, F, M, M, F, F, M, F, M], [M, M, F, M, M, F, F, M, M, F, F, M, M, M, F, M, F, M, F, M, M, F, M, F, M, M, F, M, F, M, F, M, M, M, F, M, F, M, F], [M, F, M, M, M, F, M, M, M, M, M, F, M, F, M, F, M, F, M, F, F, M, M, F, M, M, F, M, F, M, M, M, F, F, M, M, F, M, M, M, M, M, M, M, M, M, M, F, F, F], [M, M, F, M, F, M, F...</td>\n",
              "      <td>[[M, M, F, M, M, F, M, F, M, M, M, M, F, M, F, M, M, F, M, F, M, F, M], [M, F, F, F, F, M, M, M, F, M, F, F, M, F, F, F, M, F, M, M, F, F, F, F, M, M, F, M, F, F, F, M, F, F, M, F, M, M, M, F, M, F, M, F, F, F, F, M, F], [M, F, M, F, M, F, M, F, M, F, M, F, M, F, M, F, M, F, M, F, F, M, F, F, M, F, M, F, M, F, F, M, F, M, F, M, F, M, F, M, F, M], [F, F, F, F, F, M, F, M, F, M, F, M, F, F, F, M, F, F, M, F, M, F, F, M, F, M, F, F, M, F, M, F, M, F, M, M, F, M, F, M], [F, M, F, M, F, M, F, M, F, F, M, M, F, M, M, F, M, F, M, F, M, F, M, F, M, F, M, F, M, F, M, M, M, F, M, F, M, M, M, M, M, F...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'edge_index': [[[ 0  0  0 ... 55 55 55], [ 0  1  2 ... 51 53 55]], [[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  1  1  1  1\n",
              "  1  1  1  1  1  1  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  3  3\n",
              "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  4  4  4  4  4  4  4  4  4  4\n",
              "  4  4  4  4  4  4  4  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
              "  5  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  7  7  7  7  7  7\n",
              "  7  7  7  7  7  7  7  7  7  7  7  7  7  8  8  8  8  8  8  8  8  8  8  8\n",
              "  8  8  8  8  8  8  8  8  8  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n",
              "  9  9  9  9  9 ...</td>\n",
              "      <td>{'edge_index': [[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  1  1  1  1\n",
              "  1  1  1  1  1  1  1  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  3  3\n",
              "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  4  4  4  4  4  4  4  4  4\n",
              "  4  4  4  4  4  4  4  4  4  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
              "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  7  7  7  7  7  7\n",
              "  7  7  7  7  7  7  7  7  7  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8\n",
              "  8  8  8  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9 10 10\n",
              " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 11 11 11 11 1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4ad4ca3-0cd0-4724-b2dc-ef10553e9fc6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f4ad4ca3-0cd0-4724-b2dc-ef10553e9fc6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f4ad4ca3-0cd0-4724-b2dc-ef10553e9fc6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-da505cc3-b7c8-437c-9f25-baeaf69ef6ea\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-da505cc3-b7c8-437c-9f25-baeaf69ef6ea')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-da505cc3-b7c8-437c-9f25-baeaf69ef6ea button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "pickled_df",
              "summary": "{\n  \"name\": \"pickled_df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"train\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "73M1J_MJkaeB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}